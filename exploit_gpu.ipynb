{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 15 17:28:37 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:00:0A.0 Off |                  N/A |\n",
      "| 27%   31C    P8               1W / 260W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to run code on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/work/vogtlab/Group/vstrozzi/working-MT2024/compute_prs.py\", line 10, in <module>\n",
      "    from utils.factory import create_model_and_transforms, get_tokenizer\n",
      "  File \"/cluster/work/vogtlab/Group/vstrozzi/working-MT2024/utils/__init__.py\", line 2, in <module>\n",
      "    from utils.factory import create_model, create_model_and_transforms, create_model_from_pretrained, get_tokenizer, create_loss\n",
      "  File \"/cluster/work/vogtlab/Group/vstrozzi/working-MT2024/utils/factory.py\", line 9, in <module>\n",
      "    import timm\n",
      "  File \"/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/__init__.py\", line 2, in <module>\n",
      "    from .layers import is_scriptable, is_exportable, set_scriptable, set_exportable\n",
      "  File \"/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/layers/__init__.py\", line 8, in <module>\n",
      "    from .classifier import create_classifier, ClassifierHead, NormMlpClassifierHead, ClNormMlpClassifierHead\n",
      "  File \"/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/layers/classifier.py\", line 15, in <module>\n",
      "    from .create_norm import get_norm_layer\n",
      "  File \"/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/layers/create_norm.py\", line 14, in <module>\n",
      "    from torchvision.ops.misc import FrozenBatchNorm2d\n",
      "  File \"/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/torchvision/models/__init__.py\", line 17, in <module>\n",
      "    from . import detection, optical_flow, quantization, segmentation, video\n",
      "  File \"/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/torchvision/models/video/__init__.py\", line 4, in <module>\n",
      "    from .swin_transformer import *\n",
      "  File \"/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/torchvision/models/video/swin_transformer.py\", line 543, in <module>\n"
     ]
    }
   ],
   "source": [
    "!python compute_prs.py --dataset imagenet --device cuda:0 --model ViT-B-32 --pretrained laion2b_s34b_b79k --data_path datasets/imagenet --cache_dir \"../cache/\" --samples_per_class 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Using local files\n",
      "/cluster/work/vogtlab/Group/vstrozzi/working-MT2024/utils/factory.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=map_location)\n",
      "Model parameters: 151,277,313\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "/cluster/work/vogtlab/Group/vstrozzi/working-MT2024/compute_text_projection.py:69: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast():\n",
      "100%|███████████████████████████████████████| 1000/1000 [00:39<00:00, 25.48it/s]\n"
     ]
    }
   ],
   "source": [
    "!python compute_text_projection.py  --dataset imagenet --device cuda:0 --model ViT-B-32 --pretrained laion2b_s34b_b79k --cache_dir \"../cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Using local files\n",
      "/cluster/work/vogtlab/Group/vstrozzi/working-MT2024/utils/factory.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=map_location)\n",
      "Model parameters: 151,277,313\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "/cluster/work/vogtlab/Group/vstrozzi/working-MT2024/compute_text_set_projection.py:64: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast():\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:07<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "!python compute_text_set_projection.py --device cuda:0 --model ViT-B-32 --pretrained laion2b_s34b_b79k --cache_dir \"../cache/\" --data_path text_descriptions/mscoco.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test complete text set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Number of layers: 12\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 32.61it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s][3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.060335\n",
      "Epoch [40/1500], Loss: 1.363378\n",
      "Epoch [60/1500], Loss: 0.879052\n",
      "Epoch [80/1500], Loss: 0.540339\n",
      "Epoch [100/1500], Loss: 0.310504\n",
      "Epoch [120/1500], Loss: 0.171811\n",
      "Epoch [140/1500], Loss: 0.092677\n",
      "Epoch [160/1500], Loss: 0.050686\n",
      "Epoch [180/1500], Loss: 0.027356\n",
      "Epoch [200/1500], Loss: 0.014978\n",
      "Epoch [220/1500], Loss: 0.008589\n",
      "Epoch [240/1500], Loss: 0.004211\n",
      "Epoch [260/1500], Loss: 0.003089\n",
      "Epoch [280/1500], Loss: 0.003224\n",
      "Epoch [300/1500], Loss: 0.001741\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001904\n",
      "Epoch [340/1500], Loss: 0.004035\n",
      "Epoch [360/1500], Loss: 0.001696\n",
      "Epoch [380/1500], Loss: 0.002342\n",
      "Epoch [400/1500], Loss: 0.001572\n",
      "Epoch [420/1500], Loss: 0.002188\n",
      "Epoch [440/1500], Loss: 0.004038\n",
      "Epoch [460/1500], Loss: 0.001780\n",
      "Epoch [480/1500], Loss: 0.004113\n",
      "Epoch [500/1500], Loss: 0.001943\n",
      "Epoch [520/1500], Loss: 0.004230\n",
      "Epoch [540/1500], Loss: 0.001964\n",
      "Epoch [560/1500], Loss: 0.001757\n",
      "Epoch [580/1500], Loss: 0.002312\n",
      "Epoch [600/1500], Loss: 0.001505\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001918\n",
      "Epoch [640/1500], Loss: 0.001259\n",
      "Epoch [660/1500], Loss: 0.001539\n",
      "Epoch [680/1500], Loss: 0.002282\n",
      "Epoch [700/1500], Loss: 0.001473\n",
      "Epoch [720/1500], Loss: 0.001632\n",
      "Epoch [740/1500], Loss: 0.001464\n",
      "Epoch [760/1500], Loss: 0.001375\n",
      "Epoch [780/1500], Loss: 0.001540\n",
      "Epoch [800/1500], Loss: 0.001439\n",
      "Epoch [820/1500], Loss: 0.001598\n",
      "Epoch [840/1500], Loss: 0.001235\n",
      "Epoch [860/1500], Loss: 0.001772\n",
      "Epoch [880/1500], Loss: 0.001337\n",
      "Epoch [900/1500], Loss: 0.002057\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001169\n",
      "Epoch [940/1500], Loss: 0.001150\n",
      "Epoch [960/1500], Loss: 0.001306\n",
      "Epoch [980/1500], Loss: 0.001119\n",
      "Epoch [1000/1500], Loss: 0.001219\n",
      "Epoch [1020/1500], Loss: 0.001120\n",
      "Epoch [1040/1500], Loss: 0.001240\n",
      "Epoch [1060/1500], Loss: 0.001114\n",
      "Epoch [1080/1500], Loss: 0.001214\n",
      "Epoch [1100/1500], Loss: 0.001092\n",
      "Epoch [1120/1500], Loss: 0.001240\n",
      "Epoch [1140/1500], Loss: 0.001109\n",
      "Epoch [1160/1500], Loss: 0.001256\n",
      "Epoch [1180/1500], Loss: 0.001128\n",
      "Epoch [1200/1500], Loss: 0.001227\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001346\n",
      "Epoch [1240/1500], Loss: 0.001330\n",
      "Epoch [1260/1500], Loss: 0.001329\n",
      "Epoch [1280/1500], Loss: 0.001329\n",
      "Epoch [1300/1500], Loss: 0.001329\n",
      "Epoch [1320/1500], Loss: 0.001329\n",
      "Epoch [1340/1500], Loss: 0.001329\n",
      "Epoch [1360/1500], Loss: 0.001329\n",
      "Epoch [1380/1500], Loss: 0.001329\n",
      "Epoch [1400/1500], Loss: 0.001329\n",
      "Epoch [1420/1500], Loss: 0.001329\n",
      "Epoch [1440/1500], Loss: 0.001329\n",
      "Epoch [1460/1500], Loss: 0.001329\n",
      "Epoch [1480/1500], Loss: 0.001329\n",
      "Epoch [1500/1500], Loss: 0.001329\n",
      "tensor(0.0174, device='cuda:0')\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.125649 for selected strength\n",
      "We have a total strength of 0.125649 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.054088\n",
      "Epoch [40/1500], Loss: 1.346121\n",
      "Epoch [60/1500], Loss: 0.851101\n",
      "Epoch [80/1500], Loss: 0.508715\n",
      "Epoch [100/1500], Loss: 0.282880\n",
      "Epoch [120/1500], Loss: 0.152407\n",
      "Epoch [140/1500], Loss: 0.083378\n",
      "Epoch [160/1500], Loss: 0.044665\n",
      "Epoch [180/1500], Loss: 0.024156\n",
      "Epoch [200/1500], Loss: 0.013789\n",
      "Epoch [220/1500], Loss: 0.008670\n",
      "Epoch [240/1500], Loss: 0.003840\n",
      "Epoch [260/1500], Loss: 0.003819\n",
      "Epoch [280/1500], Loss: 0.004966\n",
      "Epoch [300/1500], Loss: 0.002055\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002313\n",
      "Epoch [340/1500], Loss: 0.001182\n",
      "Epoch [360/1500], Loss: 0.001797\n",
      "Epoch [380/1500], Loss: 0.001100\n",
      "Epoch [400/1500], Loss: 0.001457\n",
      "Epoch [420/1500], Loss: 0.003463\n",
      "Epoch [440/1500], Loss: 0.001729\n",
      "Epoch [460/1500], Loss: 0.002765\n",
      "Epoch [480/1500], Loss: 0.001325\n",
      "Epoch [500/1500], Loss: 0.001246\n",
      "Epoch [520/1500], Loss: 0.001448\n",
      "Epoch [540/1500], Loss: 0.001285\n",
      "Epoch [560/1500], Loss: 0.001962\n",
      "Epoch [580/1500], Loss: 0.001251\n",
      "Epoch [600/1500], Loss: 0.002173\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001331\n",
      "Epoch [640/1500], Loss: 0.000949\n",
      "Epoch [660/1500], Loss: 0.001541\n",
      "Epoch [680/1500], Loss: 0.000941\n",
      "Epoch [700/1500], Loss: 0.001736\n",
      "Epoch [720/1500], Loss: 0.001064\n",
      "Epoch [740/1500], Loss: 0.001927\n",
      "Epoch [760/1500], Loss: 0.001512\n",
      "Epoch [780/1500], Loss: 0.000973\n",
      "Epoch [800/1500], Loss: 0.002013\n",
      "Epoch [820/1500], Loss: 0.001240\n",
      "Epoch [840/1500], Loss: 0.001174\n",
      "Epoch [860/1500], Loss: 0.001356\n",
      "Epoch [880/1500], Loss: 0.000960\n",
      "Epoch [900/1500], Loss: 0.002289\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.000885\n",
      "Epoch [940/1500], Loss: 0.001164\n",
      "Epoch [960/1500], Loss: 0.000734\n",
      "Epoch [980/1500], Loss: 0.000863\n",
      "Epoch [1000/1500], Loss: 0.000744\n",
      "Epoch [1020/1500], Loss: 0.000816\n",
      "Epoch [1040/1500], Loss: 0.000764\n",
      "Epoch [1060/1500], Loss: 0.000866\n",
      "Epoch [1080/1500], Loss: 0.000708\n",
      "Epoch [1100/1500], Loss: 0.000776\n",
      "Epoch [1120/1500], Loss: 0.000712\n",
      "Epoch [1140/1500], Loss: 0.000897\n",
      "Epoch [1160/1500], Loss: 0.000735\n",
      "Epoch [1180/1500], Loss: 0.000800\n",
      "Epoch [1200/1500], Loss: 0.000770\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.000726\n",
      "Epoch [1240/1500], Loss: 0.000716\n",
      "Epoch [1260/1500], Loss: 0.000716\n",
      "Epoch [1280/1500], Loss: 0.000716\n",
      "Epoch [1300/1500], Loss: 0.000716\n",
      "Epoch [1320/1500], Loss: 0.000716\n",
      "Epoch [1340/1500], Loss: 0.000716\n",
      "Epoch [1360/1500], Loss: 0.000716\n",
      "Epoch [1380/1500], Loss: 0.000716\n",
      "Epoch [1400/1500], Loss: 0.000716\n",
      "Epoch [1420/1500], Loss: 0.000716\n",
      "Epoch [1440/1500], Loss: 0.000716\n",
      "Epoch [1460/1500], Loss: 0.000716\n",
      "Epoch [1480/1500], Loss: 0.000716\n",
      "Epoch [1500/1500], Loss: 0.000716\n",
      "tensor(0.0141, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.051375 for selected strength\n",
      "We have a total strength of 0.051375 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.042282\n",
      "Epoch [40/1500], Loss: 1.340096\n",
      "Epoch [60/1500], Loss: 0.860246\n",
      "Epoch [80/1500], Loss: 0.522699\n",
      "Epoch [100/1500], Loss: 0.294814\n",
      "Epoch [120/1500], Loss: 0.159997\n",
      "Epoch [140/1500], Loss: 0.085340\n",
      "Epoch [160/1500], Loss: 0.045245\n",
      "Epoch [180/1500], Loss: 0.023559\n",
      "Epoch [200/1500], Loss: 0.011843\n",
      "Epoch [220/1500], Loss: 0.006444\n",
      "Epoch [240/1500], Loss: 0.004696\n",
      "Epoch [260/1500], Loss: 0.002643\n",
      "Epoch [280/1500], Loss: 0.002110\n",
      "Epoch [300/1500], Loss: 0.002673\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001374\n",
      "Epoch [340/1500], Loss: 0.001994\n",
      "Epoch [360/1500], Loss: 0.002618\n",
      "Epoch [380/1500], Loss: 0.002001\n",
      "Epoch [400/1500], Loss: 0.003867\n",
      "Epoch [420/1500], Loss: 0.001783\n",
      "Epoch [440/1500], Loss: 0.003496\n",
      "Epoch [460/1500], Loss: 0.001987\n",
      "Epoch [480/1500], Loss: 0.002591\n",
      "Epoch [500/1500], Loss: 0.001969\n",
      "Epoch [520/1500], Loss: 0.001852\n",
      "Epoch [540/1500], Loss: 0.002027\n",
      "Epoch [560/1500], Loss: 0.001381\n",
      "Epoch [580/1500], Loss: 0.002151\n",
      "Epoch [600/1500], Loss: 0.001454\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001350\n",
      "Epoch [640/1500], Loss: 0.001475\n",
      "Epoch [660/1500], Loss: 0.001118\n",
      "Epoch [680/1500], Loss: 0.001378\n",
      "Epoch [700/1500], Loss: 0.001052\n",
      "Epoch [720/1500], Loss: 0.001391\n",
      "Epoch [740/1500], Loss: 0.001189\n",
      "Epoch [760/1500], Loss: 0.001209\n",
      "Epoch [780/1500], Loss: 0.001332\n",
      "Epoch [800/1500], Loss: 0.001108\n",
      "Epoch [820/1500], Loss: 0.001555\n",
      "Epoch [840/1500], Loss: 0.001117\n",
      "Epoch [860/1500], Loss: 0.001604\n",
      "Epoch [880/1500], Loss: 0.001109\n",
      "Epoch [900/1500], Loss: 0.001529\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.000970\n",
      "Epoch [940/1500], Loss: 0.000961\n",
      "Epoch [960/1500], Loss: 0.000963\n",
      "Epoch [980/1500], Loss: 0.000955\n",
      "Epoch [1000/1500], Loss: 0.000944\n",
      "Epoch [1020/1500], Loss: 0.000954\n",
      "Epoch [1040/1500], Loss: 0.000951\n",
      "Epoch [1060/1500], Loss: 0.000949\n",
      "Epoch [1080/1500], Loss: 0.000945\n",
      "Epoch [1100/1500], Loss: 0.000958\n",
      "Epoch [1120/1500], Loss: 0.000935\n",
      "Epoch [1140/1500], Loss: 0.000969\n",
      "Epoch [1160/1500], Loss: 0.000952\n",
      "Epoch [1180/1500], Loss: 0.000961\n",
      "Epoch [1200/1500], Loss: 0.000951\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001038\n",
      "Epoch [1240/1500], Loss: 0.001036\n",
      "Epoch [1260/1500], Loss: 0.001036\n",
      "Epoch [1280/1500], Loss: 0.001036\n",
      "Epoch [1300/1500], Loss: 0.001036\n",
      "Epoch [1320/1500], Loss: 0.001036\n",
      "Epoch [1340/1500], Loss: 0.001036\n",
      "Epoch [1360/1500], Loss: 0.001036\n",
      "Epoch [1380/1500], Loss: 0.001036\n",
      "Epoch [1400/1500], Loss: 0.001036\n",
      "Epoch [1420/1500], Loss: 0.001036\n",
      "Epoch [1440/1500], Loss: 0.001036\n",
      "Epoch [1460/1500], Loss: 0.001036\n",
      "Epoch [1480/1500], Loss: 0.001036\n",
      "Epoch [1500/1500], Loss: 0.001036\n",
      "tensor(0.0109, device='cuda:0')\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.080522 for selected strength\n",
      "We have a total strength of 0.080522 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.050649\n",
      "Epoch [40/1500], Loss: 1.345278\n",
      "Epoch [60/1500], Loss: 0.858374\n",
      "Epoch [80/1500], Loss: 0.519167\n",
      "Epoch [100/1500], Loss: 0.291955\n",
      "Epoch [120/1500], Loss: 0.159068\n",
      "Epoch [140/1500], Loss: 0.086342\n",
      "Epoch [160/1500], Loss: 0.047643\n",
      "Epoch [180/1500], Loss: 0.025668\n",
      "Epoch [200/1500], Loss: 0.014861\n",
      "Epoch [220/1500], Loss: 0.006895\n",
      "Epoch [240/1500], Loss: 0.004070\n",
      "Epoch [260/1500], Loss: 0.003705\n",
      "Epoch [280/1500], Loss: 0.001973\n",
      "Epoch [300/1500], Loss: 0.003643\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001597\n",
      "Epoch [340/1500], Loss: 0.002521\n",
      "Epoch [360/1500], Loss: 0.001849\n",
      "Epoch [380/1500], Loss: 0.002786\n",
      "Epoch [400/1500], Loss: 0.001570\n",
      "Epoch [420/1500], Loss: 0.004287\n",
      "Epoch [440/1500], Loss: 0.001927\n",
      "Epoch [460/1500], Loss: 0.001037\n",
      "Epoch [480/1500], Loss: 0.001907\n",
      "Epoch [500/1500], Loss: 0.001563\n",
      "Epoch [520/1500], Loss: 0.003720\n",
      "Epoch [540/1500], Loss: 0.001882\n",
      "Epoch [560/1500], Loss: 0.001444\n",
      "Epoch [580/1500], Loss: 0.003139\n",
      "Epoch [600/1500], Loss: 0.001857\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001287\n",
      "Epoch [640/1500], Loss: 0.002423\n",
      "Epoch [660/1500], Loss: 0.001328\n",
      "Epoch [680/1500], Loss: 0.000974\n",
      "Epoch [700/1500], Loss: 0.002258\n",
      "Epoch [720/1500], Loss: 0.001578\n",
      "Epoch [740/1500], Loss: 0.001128\n",
      "Epoch [760/1500], Loss: 0.001795\n",
      "Epoch [780/1500], Loss: 0.001225\n",
      "Epoch [800/1500], Loss: 0.001862\n",
      "Epoch [820/1500], Loss: 0.001641\n",
      "Epoch [840/1500], Loss: 0.001216\n",
      "Epoch [860/1500], Loss: 0.001852\n",
      "Epoch [880/1500], Loss: 0.001955\n",
      "Epoch [900/1500], Loss: 0.001229\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.000877\n",
      "Epoch [940/1500], Loss: 0.000952\n",
      "Epoch [960/1500], Loss: 0.000696\n",
      "Epoch [980/1500], Loss: 0.000772\n",
      "Epoch [1000/1500], Loss: 0.000867\n",
      "Epoch [1020/1500], Loss: 0.000751\n",
      "Epoch [1040/1500], Loss: 0.000729\n",
      "Epoch [1060/1500], Loss: 0.000847\n",
      "Epoch [1080/1500], Loss: 0.000686\n",
      "Epoch [1100/1500], Loss: 0.000789\n",
      "Epoch [1120/1500], Loss: 0.000821\n",
      "Epoch [1140/1500], Loss: 0.000737\n",
      "Epoch [1160/1500], Loss: 0.000852\n",
      "Epoch [1180/1500], Loss: 0.000725\n",
      "Epoch [1200/1500], Loss: 0.000794\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.000760\n",
      "Epoch [1240/1500], Loss: 0.000751\n",
      "Epoch [1260/1500], Loss: 0.000750\n",
      "Epoch [1280/1500], Loss: 0.000750\n",
      "Epoch [1300/1500], Loss: 0.000750\n",
      "Epoch [1320/1500], Loss: 0.000750\n",
      "Epoch [1340/1500], Loss: 0.000750\n",
      "Epoch [1360/1500], Loss: 0.000750\n",
      "Epoch [1380/1500], Loss: 0.000750\n",
      "Epoch [1400/1500], Loss: 0.000750\n",
      "Epoch [1420/1500], Loss: 0.000750\n",
      "Epoch [1440/1500], Loss: 0.000750\n",
      "Epoch [1460/1500], Loss: 0.000751\n",
      "Epoch [1480/1500], Loss: 0.000751\n",
      "Epoch [1500/1500], Loss: 0.000751\n",
      "tensor(0.0127, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.062514 for selected strength\n",
      "We have a total strength of 0.062514 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.044546\n",
      "Epoch [40/1500], Loss: 1.339978\n",
      "Epoch [60/1500], Loss: 0.848023\n",
      "Epoch [80/1500], Loss: 0.503179\n",
      "Epoch [100/1500], Loss: 0.275070\n",
      "Epoch [120/1500], Loss: 0.145941\n",
      "Epoch [140/1500], Loss: 0.077603\n",
      "Epoch [160/1500], Loss: 0.042494\n",
      "Epoch [180/1500], Loss: 0.022672\n",
      "Epoch [200/1500], Loss: 0.012859\n",
      "Epoch [220/1500], Loss: 0.007045\n",
      "Epoch [240/1500], Loss: 0.003598\n",
      "Epoch [260/1500], Loss: 0.003824\n",
      "Epoch [280/1500], Loss: 0.001705\n",
      "Epoch [300/1500], Loss: 0.003505\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001297\n",
      "Epoch [340/1500], Loss: 0.002599\n",
      "Epoch [360/1500], Loss: 0.001256\n",
      "Epoch [380/1500], Loss: 0.002089\n",
      "Epoch [400/1500], Loss: 0.001287\n",
      "Epoch [420/1500], Loss: 0.002868\n",
      "Epoch [440/1500], Loss: 0.001859\n",
      "Epoch [460/1500], Loss: 0.002942\n",
      "Epoch [480/1500], Loss: 0.002625\n",
      "Epoch [500/1500], Loss: 0.001733\n",
      "Epoch [520/1500], Loss: 0.002312\n",
      "Epoch [540/1500], Loss: 0.002376\n",
      "Epoch [560/1500], Loss: 0.001454\n",
      "Epoch [580/1500], Loss: 0.002613\n",
      "Epoch [600/1500], Loss: 0.002341\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001538\n",
      "Epoch [640/1500], Loss: 0.000869\n",
      "Epoch [660/1500], Loss: 0.000983\n",
      "Epoch [680/1500], Loss: 0.001194\n",
      "Epoch [700/1500], Loss: 0.000876\n",
      "Epoch [720/1500], Loss: 0.000948\n",
      "Epoch [740/1500], Loss: 0.001118\n",
      "Epoch [760/1500], Loss: 0.000937\n",
      "Epoch [780/1500], Loss: 0.001163\n",
      "Epoch [800/1500], Loss: 0.000815\n",
      "Epoch [820/1500], Loss: 0.001069\n",
      "Epoch [840/1500], Loss: 0.000849\n",
      "Epoch [860/1500], Loss: 0.001039\n",
      "Epoch [880/1500], Loss: 0.001038\n",
      "Epoch [900/1500], Loss: 0.001003\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.000708\n",
      "Epoch [940/1500], Loss: 0.000676\n",
      "Epoch [960/1500], Loss: 0.000661\n",
      "Epoch [980/1500], Loss: 0.000653\n",
      "Epoch [1000/1500], Loss: 0.000713\n",
      "Epoch [1020/1500], Loss: 0.000694\n",
      "Epoch [1040/1500], Loss: 0.000694\n",
      "Epoch [1060/1500], Loss: 0.000715\n",
      "Epoch [1080/1500], Loss: 0.000745\n",
      "Epoch [1100/1500], Loss: 0.000648\n",
      "Epoch [1120/1500], Loss: 0.000659\n",
      "Epoch [1140/1500], Loss: 0.000699\n",
      "Epoch [1160/1500], Loss: 0.000750\n",
      "Epoch [1180/1500], Loss: 0.000665\n",
      "Epoch [1200/1500], Loss: 0.000639\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.000703\n",
      "Epoch [1240/1500], Loss: 0.000701\n",
      "Epoch [1260/1500], Loss: 0.000701\n",
      "Epoch [1280/1500], Loss: 0.000701\n",
      "Epoch [1300/1500], Loss: 0.000701\n",
      "Epoch [1320/1500], Loss: 0.000701\n",
      "Epoch [1340/1500], Loss: 0.000701\n",
      "Epoch [1360/1500], Loss: 0.000701\n",
      "Epoch [1380/1500], Loss: 0.000702\n",
      "Epoch [1400/1500], Loss: 0.000702\n",
      "Epoch [1420/1500], Loss: 0.000702\n",
      "Epoch [1440/1500], Loss: 0.000702\n",
      "Epoch [1460/1500], Loss: 0.000702\n",
      "Epoch [1480/1500], Loss: 0.000702\n",
      "Epoch [1500/1500], Loss: 0.000702\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.053984 for selected strength\n",
      "We have a total strength of 0.053984 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.079499\n",
      "Epoch [40/1500], Loss: 1.387830\n",
      "Epoch [60/1500], Loss: 0.905761\n",
      "Epoch [80/1500], Loss: 0.564195\n",
      "Epoch [100/1500], Loss: 0.328308\n",
      "Epoch [120/1500], Loss: 0.180591\n",
      "Epoch [140/1500], Loss: 0.095644\n",
      "Epoch [160/1500], Loss: 0.048782\n",
      "Epoch [180/1500], Loss: 0.024112\n",
      "Epoch [200/1500], Loss: 0.011760\n",
      "Epoch [220/1500], Loss: 0.006074\n",
      "Epoch [240/1500], Loss: 0.003747\n",
      "Epoch [260/1500], Loss: 0.002958\n",
      "Epoch [280/1500], Loss: 0.003637\n",
      "Epoch [300/1500], Loss: 0.001946\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002196\n",
      "Epoch [340/1500], Loss: 0.002647\n",
      "Epoch [360/1500], Loss: 0.001978\n",
      "Epoch [380/1500], Loss: 0.001925\n",
      "Epoch [400/1500], Loss: 0.002551\n",
      "Epoch [420/1500], Loss: 0.001970\n",
      "Epoch [440/1500], Loss: 0.002038\n",
      "Epoch [460/1500], Loss: 0.002479\n",
      "Epoch [480/1500], Loss: 0.001729\n",
      "Epoch [500/1500], Loss: 0.002463\n",
      "Epoch [520/1500], Loss: 0.002697\n",
      "Epoch [540/1500], Loss: 0.002230\n",
      "Epoch [560/1500], Loss: 0.002178\n",
      "Epoch [580/1500], Loss: 0.002155\n",
      "Epoch [600/1500], Loss: 0.002069\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002268\n",
      "Epoch [640/1500], Loss: 0.001617\n",
      "Epoch [660/1500], Loss: 0.002142\n",
      "Epoch [680/1500], Loss: 0.001636\n",
      "Epoch [700/1500], Loss: 0.002455\n",
      "Epoch [720/1500], Loss: 0.001711\n",
      "Epoch [740/1500], Loss: 0.002442\n",
      "Epoch [760/1500], Loss: 0.001750\n",
      "Epoch [780/1500], Loss: 0.001805\n",
      "Epoch [800/1500], Loss: 0.001887\n",
      "Epoch [820/1500], Loss: 0.001579\n",
      "Epoch [840/1500], Loss: 0.002245\n",
      "Epoch [860/1500], Loss: 0.001654\n",
      "Epoch [880/1500], Loss: 0.002043\n",
      "Epoch [900/1500], Loss: 0.001842\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001549\n",
      "Epoch [940/1500], Loss: 0.001510\n",
      "Epoch [960/1500], Loss: 0.001456\n",
      "Epoch [980/1500], Loss: 0.001496\n",
      "Epoch [1000/1500], Loss: 0.001460\n",
      "Epoch [1020/1500], Loss: 0.001438\n",
      "Epoch [1040/1500], Loss: 0.001453\n",
      "Epoch [1060/1500], Loss: 0.001476\n",
      "Epoch [1080/1500], Loss: 0.001434\n",
      "Epoch [1100/1500], Loss: 0.001492\n",
      "Epoch [1120/1500], Loss: 0.001414\n",
      "Epoch [1140/1500], Loss: 0.001454\n",
      "Epoch [1160/1500], Loss: 0.001411\n",
      "Epoch [1180/1500], Loss: 0.001444\n",
      "Epoch [1200/1500], Loss: 0.001411\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001749\n",
      "Epoch [1240/1500], Loss: 0.001742\n",
      "Epoch [1260/1500], Loss: 0.001741\n",
      "Epoch [1280/1500], Loss: 0.001741\n",
      "Epoch [1300/1500], Loss: 0.001741\n",
      "Epoch [1320/1500], Loss: 0.001741\n",
      "Epoch [1340/1500], Loss: 0.001741\n",
      "Epoch [1360/1500], Loss: 0.001741\n",
      "Epoch [1380/1500], Loss: 0.001741\n",
      "Epoch [1400/1500], Loss: 0.001741\n",
      "Epoch [1420/1500], Loss: 0.001741\n",
      "Epoch [1440/1500], Loss: 0.001741\n",
      "Epoch [1460/1500], Loss: 0.001741\n",
      "Epoch [1480/1500], Loss: 0.001741\n",
      "Epoch [1500/1500], Loss: 0.001741\n",
      "tensor(0.0197, device='cuda:0')\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.188588 for selected strength\n",
      "We have a total strength of 0.188588 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.081049\n",
      "Epoch [40/1500], Loss: 1.396623\n",
      "Epoch [60/1500], Loss: 0.915016\n",
      "Epoch [80/1500], Loss: 0.573934\n",
      "Epoch [100/1500], Loss: 0.340245\n",
      "Epoch [120/1500], Loss: 0.195140\n",
      "Epoch [140/1500], Loss: 0.111010\n",
      "Epoch [160/1500], Loss: 0.062076\n",
      "Epoch [180/1500], Loss: 0.034118\n",
      "Epoch [200/1500], Loss: 0.018749\n",
      "Epoch [220/1500], Loss: 0.010796\n",
      "Epoch [240/1500], Loss: 0.005910\n",
      "Epoch [260/1500], Loss: 0.003257\n",
      "Epoch [280/1500], Loss: 0.002851\n",
      "Epoch [300/1500], Loss: 0.003188\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003681\n",
      "Epoch [340/1500], Loss: 0.001691\n",
      "Epoch [360/1500], Loss: 0.002025\n",
      "Epoch [380/1500], Loss: 0.001462\n",
      "Epoch [400/1500], Loss: 0.001862\n",
      "Epoch [420/1500], Loss: 0.002563\n",
      "Epoch [440/1500], Loss: 0.001459\n",
      "Epoch [460/1500], Loss: 0.002162\n",
      "Epoch [480/1500], Loss: 0.001436\n",
      "Epoch [500/1500], Loss: 0.002023\n",
      "Epoch [520/1500], Loss: 0.001528\n",
      "Epoch [540/1500], Loss: 0.002272\n",
      "Epoch [560/1500], Loss: 0.001551\n",
      "Epoch [580/1500], Loss: 0.002739\n",
      "Epoch [600/1500], Loss: 0.001577\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001420\n",
      "Epoch [640/1500], Loss: 0.001416\n",
      "Epoch [660/1500], Loss: 0.001669\n",
      "Epoch [680/1500], Loss: 0.001206\n",
      "Epoch [700/1500], Loss: 0.001360\n",
      "Epoch [720/1500], Loss: 0.001423\n",
      "Epoch [740/1500], Loss: 0.001292\n",
      "Epoch [760/1500], Loss: 0.001545\n",
      "Epoch [780/1500], Loss: 0.001229\n",
      "Epoch [800/1500], Loss: 0.001366\n",
      "Epoch [820/1500], Loss: 0.001313\n",
      "Epoch [840/1500], Loss: 0.001285\n",
      "Epoch [860/1500], Loss: 0.001359\n",
      "Epoch [880/1500], Loss: 0.001227\n",
      "Epoch [900/1500], Loss: 0.001584\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001067\n",
      "Epoch [940/1500], Loss: 0.001076\n",
      "Epoch [960/1500], Loss: 0.001192\n",
      "Epoch [980/1500], Loss: 0.001021\n",
      "Epoch [1000/1500], Loss: 0.001073\n",
      "Epoch [1020/1500], Loss: 0.001161\n",
      "Epoch [1040/1500], Loss: 0.001015\n",
      "Epoch [1060/1500], Loss: 0.001122\n",
      "Epoch [1080/1500], Loss: 0.001183\n",
      "Epoch [1100/1500], Loss: 0.001029\n",
      "Epoch [1120/1500], Loss: 0.001158\n",
      "Epoch [1140/1500], Loss: 0.001026\n",
      "Epoch [1160/1500], Loss: 0.001155\n",
      "Epoch [1180/1500], Loss: 0.001124\n",
      "Epoch [1200/1500], Loss: 0.001056\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001241\n",
      "Epoch [1240/1500], Loss: 0.001232\n",
      "Epoch [1260/1500], Loss: 0.001232\n",
      "Epoch [1280/1500], Loss: 0.001231\n",
      "Epoch [1300/1500], Loss: 0.001231\n",
      "Epoch [1320/1500], Loss: 0.001232\n",
      "Epoch [1340/1500], Loss: 0.001232\n",
      "Epoch [1360/1500], Loss: 0.001232\n",
      "Epoch [1380/1500], Loss: 0.001232\n",
      "Epoch [1400/1500], Loss: 0.001232\n",
      "Epoch [1420/1500], Loss: 0.001232\n",
      "Epoch [1440/1500], Loss: 0.001232\n",
      "Epoch [1460/1500], Loss: 0.001232\n",
      "Epoch [1480/1500], Loss: 0.001232\n",
      "Epoch [1500/1500], Loss: 0.001232\n",
      "tensor(0.0239, device='cuda:0')\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.136751 for selected strength\n",
      "We have a total strength of 0.136751 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.086008\n",
      "Epoch [40/1500], Loss: 1.399520\n",
      "Epoch [60/1500], Loss: 0.908000\n",
      "Epoch [80/1500], Loss: 0.565813\n",
      "Epoch [100/1500], Loss: 0.332204\n",
      "Epoch [120/1500], Loss: 0.188592\n",
      "Epoch [140/1500], Loss: 0.107357\n",
      "Epoch [160/1500], Loss: 0.061339\n",
      "Epoch [180/1500], Loss: 0.035598\n",
      "Epoch [200/1500], Loss: 0.021337\n",
      "Epoch [220/1500], Loss: 0.013590\n",
      "Epoch [240/1500], Loss: 0.007052\n",
      "Epoch [260/1500], Loss: 0.004840\n",
      "Epoch [280/1500], Loss: 0.005642\n",
      "Epoch [300/1500], Loss: 0.002680\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002734\n",
      "Epoch [340/1500], Loss: 0.001643\n",
      "Epoch [360/1500], Loss: 0.002765\n",
      "Epoch [380/1500], Loss: 0.001354\n",
      "Epoch [400/1500], Loss: 0.001971\n",
      "Epoch [420/1500], Loss: 0.001388\n",
      "Epoch [440/1500], Loss: 0.002633\n",
      "Epoch [460/1500], Loss: 0.001734\n",
      "Epoch [480/1500], Loss: 0.001958\n",
      "Epoch [500/1500], Loss: 0.002013\n",
      "Epoch [520/1500], Loss: 0.001275\n",
      "Epoch [540/1500], Loss: 0.002485\n",
      "Epoch [560/1500], Loss: 0.001381\n",
      "Epoch [580/1500], Loss: 0.001476\n",
      "Epoch [600/1500], Loss: 0.002321\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001096\n",
      "Epoch [640/1500], Loss: 0.001447\n",
      "Epoch [660/1500], Loss: 0.000905\n",
      "Epoch [680/1500], Loss: 0.001700\n",
      "Epoch [700/1500], Loss: 0.001019\n",
      "Epoch [720/1500], Loss: 0.001647\n",
      "Epoch [740/1500], Loss: 0.001098\n",
      "Epoch [760/1500], Loss: 0.001154\n",
      "Epoch [780/1500], Loss: 0.001422\n",
      "Epoch [800/1500], Loss: 0.001018\n",
      "Epoch [820/1500], Loss: 0.001676\n",
      "Epoch [840/1500], Loss: 0.001244\n",
      "Epoch [860/1500], Loss: 0.001385\n",
      "Epoch [880/1500], Loss: 0.001481\n",
      "Epoch [900/1500], Loss: 0.001115\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.000825\n",
      "Epoch [940/1500], Loss: 0.001110\n",
      "Epoch [960/1500], Loss: 0.000904\n",
      "Epoch [980/1500], Loss: 0.000842\n",
      "Epoch [1000/1500], Loss: 0.000808\n",
      "Epoch [1020/1500], Loss: 0.000791\n",
      "Epoch [1040/1500], Loss: 0.000796\n",
      "Epoch [1060/1500], Loss: 0.000803\n",
      "Epoch [1080/1500], Loss: 0.000838\n",
      "Epoch [1100/1500], Loss: 0.000843\n",
      "Epoch [1120/1500], Loss: 0.000868\n",
      "Epoch [1140/1500], Loss: 0.000896\n",
      "Epoch [1160/1500], Loss: 0.000969\n",
      "Epoch [1180/1500], Loss: 0.000884\n",
      "Epoch [1200/1500], Loss: 0.000782\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.000866\n",
      "Epoch [1240/1500], Loss: 0.000865\n",
      "Epoch [1260/1500], Loss: 0.000865\n",
      "Epoch [1280/1500], Loss: 0.000865\n",
      "Epoch [1300/1500], Loss: 0.000865\n",
      "Epoch [1320/1500], Loss: 0.000865\n",
      "Epoch [1340/1500], Loss: 0.000865\n",
      "Epoch [1360/1500], Loss: 0.000865\n",
      "Epoch [1380/1500], Loss: 0.000865\n",
      "Epoch [1400/1500], Loss: 0.000865\n",
      "Epoch [1420/1500], Loss: 0.000865\n",
      "Epoch [1440/1500], Loss: 0.000865\n",
      "Epoch [1460/1500], Loss: 0.000865\n",
      "Epoch [1480/1500], Loss: 0.000865\n",
      "Epoch [1500/1500], Loss: 0.000865\n",
      "tensor(0.0097, device='cuda:0')\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.061908 for selected strength\n",
      "We have a total strength of 0.061908 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.056751\n",
      "Epoch [40/1500], Loss: 1.361292\n",
      "Epoch [60/1500], Loss: 0.883184\n",
      "Epoch [80/1500], Loss: 0.546116\n",
      "Epoch [100/1500], Loss: 0.314934\n",
      "Epoch [120/1500], Loss: 0.172392\n",
      "Epoch [140/1500], Loss: 0.089449\n",
      "Epoch [160/1500], Loss: 0.045115\n",
      "Epoch [180/1500], Loss: 0.023007\n",
      "Epoch [200/1500], Loss: 0.012494\n",
      "Epoch [220/1500], Loss: 0.006849\n",
      "Epoch [240/1500], Loss: 0.003594\n",
      "Epoch [260/1500], Loss: 0.002307\n",
      "Epoch [280/1500], Loss: 0.002307\n",
      "Epoch [300/1500], Loss: 0.002665\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002402\n",
      "Epoch [340/1500], Loss: 0.001846\n",
      "Epoch [360/1500], Loss: 0.001765\n",
      "Epoch [380/1500], Loss: 0.002144\n",
      "Epoch [400/1500], Loss: 0.002242\n",
      "Epoch [420/1500], Loss: 0.001647\n",
      "Epoch [440/1500], Loss: 0.002228\n",
      "Epoch [460/1500], Loss: 0.001833\n",
      "Epoch [480/1500], Loss: 0.001927\n",
      "Epoch [500/1500], Loss: 0.002872\n",
      "Epoch [520/1500], Loss: 0.001649\n",
      "Epoch [540/1500], Loss: 0.002417\n",
      "Epoch [560/1500], Loss: 0.001711\n",
      "Epoch [580/1500], Loss: 0.002476\n",
      "Epoch [600/1500], Loss: 0.001775\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001637\n",
      "Epoch [640/1500], Loss: 0.001777\n",
      "Epoch [660/1500], Loss: 0.001577\n",
      "Epoch [680/1500], Loss: 0.001532\n",
      "Epoch [700/1500], Loss: 0.001681\n",
      "Epoch [720/1500], Loss: 0.001548\n",
      "Epoch [740/1500], Loss: 0.001521\n",
      "Epoch [760/1500], Loss: 0.001743\n",
      "Epoch [780/1500], Loss: 0.001457\n",
      "Epoch [800/1500], Loss: 0.001581\n",
      "Epoch [820/1500], Loss: 0.001534\n",
      "Epoch [840/1500], Loss: 0.001542\n",
      "Epoch [860/1500], Loss: 0.001722\n",
      "Epoch [880/1500], Loss: 0.001572\n",
      "Epoch [900/1500], Loss: 0.001711\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001339\n",
      "Epoch [940/1500], Loss: 0.001499\n",
      "Epoch [960/1500], Loss: 0.001314\n",
      "Epoch [980/1500], Loss: 0.001451\n",
      "Epoch [1000/1500], Loss: 0.001328\n",
      "Epoch [1020/1500], Loss: 0.001327\n",
      "Epoch [1040/1500], Loss: 0.001627\n",
      "Epoch [1060/1500], Loss: 0.001301\n",
      "Epoch [1080/1500], Loss: 0.001454\n",
      "Epoch [1100/1500], Loss: 0.001297\n",
      "Epoch [1120/1500], Loss: 0.001409\n",
      "Epoch [1140/1500], Loss: 0.001291\n",
      "Epoch [1160/1500], Loss: 0.001402\n",
      "Epoch [1180/1500], Loss: 0.001433\n",
      "Epoch [1200/1500], Loss: 0.001360\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001603\n",
      "Epoch [1240/1500], Loss: 0.001596\n",
      "Epoch [1260/1500], Loss: 0.001595\n",
      "Epoch [1280/1500], Loss: 0.001595\n",
      "Epoch [1300/1500], Loss: 0.001595\n",
      "Epoch [1320/1500], Loss: 0.001595\n",
      "Epoch [1340/1500], Loss: 0.001595\n",
      "Epoch [1360/1500], Loss: 0.001595\n",
      "Epoch [1380/1500], Loss: 0.001595\n",
      "Epoch [1400/1500], Loss: 0.001595\n",
      "Epoch [1420/1500], Loss: 0.001595\n",
      "Epoch [1440/1500], Loss: 0.001595\n",
      "Epoch [1460/1500], Loss: 0.001595\n",
      "Epoch [1480/1500], Loss: 0.001595\n",
      "Epoch [1500/1500], Loss: 0.001595\n",
      "tensor(0.0177, device='cuda:0')\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.181922 for selected strength\n",
      "We have a total strength of 0.181922 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.054142\n",
      "Epoch [40/1500], Loss: 1.344738\n",
      "Epoch [60/1500], Loss: 0.852539\n",
      "Epoch [80/1500], Loss: 0.510431\n",
      "Epoch [100/1500], Loss: 0.282368\n",
      "Epoch [120/1500], Loss: 0.149313\n",
      "Epoch [140/1500], Loss: 0.079114\n",
      "Epoch [160/1500], Loss: 0.041204\n",
      "Epoch [180/1500], Loss: 0.021453\n",
      "Epoch [200/1500], Loss: 0.011592\n",
      "Epoch [220/1500], Loss: 0.006716\n",
      "Epoch [240/1500], Loss: 0.003019\n",
      "Epoch [260/1500], Loss: 0.002950\n",
      "Epoch [280/1500], Loss: 0.001767\n",
      "Epoch [300/1500], Loss: 0.001843\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002063\n",
      "Epoch [340/1500], Loss: 0.001692\n",
      "Epoch [360/1500], Loss: 0.002413\n",
      "Epoch [380/1500], Loss: 0.001399\n",
      "Epoch [400/1500], Loss: 0.002346\n",
      "Epoch [420/1500], Loss: 0.001401\n",
      "Epoch [440/1500], Loss: 0.002198\n",
      "Epoch [460/1500], Loss: 0.001650\n",
      "Epoch [480/1500], Loss: 0.002858\n",
      "Epoch [500/1500], Loss: 0.001589\n",
      "Epoch [520/1500], Loss: 0.001200\n",
      "Epoch [540/1500], Loss: 0.001808\n",
      "Epoch [560/1500], Loss: 0.001462\n",
      "Epoch [580/1500], Loss: 0.002590\n",
      "Epoch [600/1500], Loss: 0.001864\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002164\n",
      "Epoch [640/1500], Loss: 0.001047\n",
      "Epoch [660/1500], Loss: 0.001258\n",
      "Epoch [680/1500], Loss: 0.001468\n",
      "Epoch [700/1500], Loss: 0.000996\n",
      "Epoch [720/1500], Loss: 0.001381\n",
      "Epoch [740/1500], Loss: 0.000969\n",
      "Epoch [760/1500], Loss: 0.001380\n",
      "Epoch [780/1500], Loss: 0.000990\n",
      "Epoch [800/1500], Loss: 0.001266\n",
      "Epoch [820/1500], Loss: 0.000949\n",
      "Epoch [840/1500], Loss: 0.001340\n",
      "Epoch [860/1500], Loss: 0.000972\n",
      "Epoch [880/1500], Loss: 0.001344\n",
      "Epoch [900/1500], Loss: 0.001012\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.000880\n",
      "Epoch [940/1500], Loss: 0.000889\n",
      "Epoch [960/1500], Loss: 0.001049\n",
      "Epoch [980/1500], Loss: 0.001220\n",
      "Epoch [1000/1500], Loss: 0.000842\n",
      "Epoch [1020/1500], Loss: 0.000838\n",
      "Epoch [1040/1500], Loss: 0.000944\n",
      "Epoch [1060/1500], Loss: 0.000918\n",
      "Epoch [1080/1500], Loss: 0.000791\n",
      "Epoch [1100/1500], Loss: 0.000903\n",
      "Epoch [1120/1500], Loss: 0.000918\n",
      "Epoch [1140/1500], Loss: 0.000799\n",
      "Epoch [1160/1500], Loss: 0.001052\n",
      "Epoch [1180/1500], Loss: 0.000791\n",
      "Epoch [1200/1500], Loss: 0.000832\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.000823\n",
      "Epoch [1240/1500], Loss: 0.000820\n",
      "Epoch [1260/1500], Loss: 0.000819\n",
      "Epoch [1280/1500], Loss: 0.000819\n",
      "Epoch [1300/1500], Loss: 0.000819\n",
      "Epoch [1320/1500], Loss: 0.000820\n",
      "Epoch [1340/1500], Loss: 0.000820\n",
      "Epoch [1360/1500], Loss: 0.000820\n",
      "Epoch [1380/1500], Loss: 0.000820\n",
      "Epoch [1400/1500], Loss: 0.000820\n",
      "Epoch [1420/1500], Loss: 0.000820\n",
      "Epoch [1440/1500], Loss: 0.000820\n",
      "Epoch [1460/1500], Loss: 0.000820\n",
      "Epoch [1480/1500], Loss: 0.000820\n",
      "Epoch [1500/1500], Loss: 0.000820\n",
      "tensor(0.0101, device='cuda:0')\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.066666 for selected strength\n",
      "We have a total strength of 0.066666 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.051752\n",
      "Epoch [40/1500], Loss: 1.348372\n",
      "Epoch [60/1500], Loss: 0.863450\n",
      "Epoch [80/1500], Loss: 0.525249\n",
      "Epoch [100/1500], Loss: 0.298968\n",
      "Epoch [120/1500], Loss: 0.166353\n",
      "Epoch [140/1500], Loss: 0.092927\n",
      "Epoch [160/1500], Loss: 0.051514\n",
      "Epoch [180/1500], Loss: 0.028613\n",
      "Epoch [200/1500], Loss: 0.016397\n",
      "Epoch [220/1500], Loss: 0.009484\n",
      "Epoch [240/1500], Loss: 0.004594\n",
      "Epoch [260/1500], Loss: 0.004259\n",
      "Epoch [280/1500], Loss: 0.002015\n",
      "Epoch [300/1500], Loss: 0.002030\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001513\n",
      "Epoch [340/1500], Loss: 0.002034\n",
      "Epoch [360/1500], Loss: 0.001363\n",
      "Epoch [380/1500], Loss: 0.002393\n",
      "Epoch [400/1500], Loss: 0.001336\n",
      "Epoch [420/1500], Loss: 0.003189\n",
      "Epoch [440/1500], Loss: 0.002176\n",
      "Epoch [460/1500], Loss: 0.001056\n",
      "Epoch [480/1500], Loss: 0.001334\n",
      "Epoch [500/1500], Loss: 0.002435\n",
      "Epoch [520/1500], Loss: 0.001806\n",
      "Epoch [540/1500], Loss: 0.001671\n",
      "Epoch [560/1500], Loss: 0.003404\n",
      "Epoch [580/1500], Loss: 0.001331\n",
      "Epoch [600/1500], Loss: 0.001137\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.003786\n",
      "Epoch [640/1500], Loss: 0.001916\n",
      "Epoch [660/1500], Loss: 0.001190\n",
      "Epoch [680/1500], Loss: 0.002013\n",
      "Epoch [700/1500], Loss: 0.001869\n",
      "Epoch [720/1500], Loss: 0.001265\n",
      "Epoch [740/1500], Loss: 0.003486\n",
      "Epoch [760/1500], Loss: 0.001813\n",
      "Epoch [780/1500], Loss: 0.001350\n",
      "Epoch [800/1500], Loss: 0.001430\n",
      "Epoch [820/1500], Loss: 0.001896\n",
      "Epoch [840/1500], Loss: 0.001784\n",
      "Epoch [860/1500], Loss: 0.001297\n",
      "Epoch [880/1500], Loss: 0.001848\n",
      "Epoch [900/1500], Loss: 0.001765\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001053\n",
      "Epoch [940/1500], Loss: 0.000978\n",
      "Epoch [960/1500], Loss: 0.001358\n",
      "Epoch [980/1500], Loss: 0.001002\n",
      "Epoch [1000/1500], Loss: 0.001725\n",
      "Epoch [1020/1500], Loss: 0.001264\n",
      "Epoch [1040/1500], Loss: 0.000992\n",
      "Epoch [1060/1500], Loss: 0.000828\n",
      "Epoch [1080/1500], Loss: 0.001713\n",
      "Epoch [1100/1500], Loss: 0.000984\n",
      "Epoch [1120/1500], Loss: 0.000854\n",
      "Epoch [1140/1500], Loss: 0.001497\n",
      "Epoch [1160/1500], Loss: 0.001045\n",
      "Epoch [1180/1500], Loss: 0.000808\n",
      "Epoch [1200/1500], Loss: 0.000861\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.000731\n",
      "Epoch [1240/1500], Loss: 0.000693\n",
      "Epoch [1260/1500], Loss: 0.000690\n",
      "Epoch [1280/1500], Loss: 0.000690\n",
      "Epoch [1300/1500], Loss: 0.000690\n",
      "Epoch [1320/1500], Loss: 0.000690\n",
      "Epoch [1340/1500], Loss: 0.000690\n",
      "Epoch [1360/1500], Loss: 0.000690\n",
      "Epoch [1380/1500], Loss: 0.000690\n",
      "Epoch [1400/1500], Loss: 0.000690\n",
      "Epoch [1420/1500], Loss: 0.000691\n",
      "Epoch [1440/1500], Loss: 0.000691\n",
      "Epoch [1460/1500], Loss: 0.000691\n",
      "Epoch [1480/1500], Loss: 0.000691\n",
      "Epoch [1500/1500], Loss: 0.000691\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.061777 for selected strength\n",
      "We have a total strength of 0.061777 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.074176\n",
      "Epoch [40/1500], Loss: 1.393092\n",
      "Epoch [60/1500], Loss: 0.920283\n",
      "Epoch [80/1500], Loss: 0.583173\n",
      "Epoch [100/1500], Loss: 0.348357\n",
      "Epoch [120/1500], Loss: 0.199813\n",
      "Epoch [140/1500], Loss: 0.110242\n",
      "Epoch [160/1500], Loss: 0.060387\n",
      "Epoch [180/1500], Loss: 0.032531\n",
      "Epoch [200/1500], Loss: 0.017464\n",
      "Epoch [220/1500], Loss: 0.009299\n",
      "Epoch [240/1500], Loss: 0.005297\n",
      "Epoch [260/1500], Loss: 0.003698\n",
      "Epoch [280/1500], Loss: 0.003117\n",
      "Epoch [300/1500], Loss: 0.003565\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001758\n",
      "Epoch [340/1500], Loss: 0.002153\n",
      "Epoch [360/1500], Loss: 0.002654\n",
      "Epoch [380/1500], Loss: 0.001838\n",
      "Epoch [400/1500], Loss: 0.002186\n",
      "Epoch [420/1500], Loss: 0.003964\n",
      "Epoch [440/1500], Loss: 0.001975\n",
      "Epoch [460/1500], Loss: 0.002654\n",
      "Epoch [480/1500], Loss: 0.001823\n",
      "Epoch [500/1500], Loss: 0.003242\n",
      "Epoch [520/1500], Loss: 0.001694\n",
      "Epoch [540/1500], Loss: 0.002412\n",
      "Epoch [560/1500], Loss: 0.001717\n",
      "Epoch [580/1500], Loss: 0.002393\n",
      "Epoch [600/1500], Loss: 0.002006\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001645\n",
      "Epoch [640/1500], Loss: 0.001787\n",
      "Epoch [660/1500], Loss: 0.001453\n",
      "Epoch [680/1500], Loss: 0.001758\n",
      "Epoch [700/1500], Loss: 0.001469\n",
      "Epoch [720/1500], Loss: 0.001627\n",
      "Epoch [740/1500], Loss: 0.001569\n",
      "Epoch [760/1500], Loss: 0.001585\n",
      "Epoch [780/1500], Loss: 0.001890\n",
      "Epoch [800/1500], Loss: 0.001459\n",
      "Epoch [820/1500], Loss: 0.001805\n",
      "Epoch [840/1500], Loss: 0.001504\n",
      "Epoch [860/1500], Loss: 0.001776\n",
      "Epoch [880/1500], Loss: 0.001569\n",
      "Epoch [900/1500], Loss: 0.001702\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001317\n",
      "Epoch [940/1500], Loss: 0.001645\n",
      "Epoch [960/1500], Loss: 0.001294\n",
      "Epoch [980/1500], Loss: 0.001465\n",
      "Epoch [1000/1500], Loss: 0.001299\n",
      "Epoch [1020/1500], Loss: 0.001359\n",
      "Epoch [1040/1500], Loss: 0.001579\n",
      "Epoch [1060/1500], Loss: 0.001291\n",
      "Epoch [1080/1500], Loss: 0.001632\n",
      "Epoch [1100/1500], Loss: 0.001289\n",
      "Epoch [1120/1500], Loss: 0.001553\n",
      "Epoch [1140/1500], Loss: 0.001292\n",
      "Epoch [1160/1500], Loss: 0.001551\n",
      "Epoch [1180/1500], Loss: 0.001268\n",
      "Epoch [1200/1500], Loss: 0.001474\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001570\n",
      "Epoch [1240/1500], Loss: 0.001562\n",
      "Epoch [1260/1500], Loss: 0.001561\n",
      "Epoch [1280/1500], Loss: 0.001561\n",
      "Epoch [1300/1500], Loss: 0.001561\n",
      "Epoch [1320/1500], Loss: 0.001561\n",
      "Epoch [1340/1500], Loss: 0.001562\n",
      "Epoch [1360/1500], Loss: 0.001562\n",
      "Epoch [1380/1500], Loss: 0.001562\n",
      "Epoch [1400/1500], Loss: 0.001562\n",
      "Epoch [1420/1500], Loss: 0.001562\n",
      "Epoch [1440/1500], Loss: 0.001562\n",
      "Epoch [1460/1500], Loss: 0.001562\n",
      "Epoch [1480/1500], Loss: 0.001562\n",
      "Epoch [1500/1500], Loss: 0.001562\n",
      "tensor(0.0150, device='cuda:0')\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.159264 for selected strength\n",
      "We have a total strength of 0.159264 for all the columns\n",
      " 25%|███████████                                 | 1/4 [02:25<07:16, 145.35s/it][3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.041862\n",
      "Epoch [40/1500], Loss: 1.337338\n",
      "Epoch [60/1500], Loss: 0.852196\n",
      "Epoch [80/1500], Loss: 0.514284\n",
      "Epoch [100/1500], Loss: 0.288089\n",
      "Epoch [120/1500], Loss: 0.154792\n",
      "Epoch [140/1500], Loss: 0.081764\n",
      "Epoch [160/1500], Loss: 0.042405\n",
      "Epoch [180/1500], Loss: 0.021999\n",
      "Epoch [200/1500], Loss: 0.010885\n",
      "Epoch [220/1500], Loss: 0.005078\n",
      "Epoch [240/1500], Loss: 0.003270\n",
      "Epoch [260/1500], Loss: 0.003701\n",
      "Epoch [280/1500], Loss: 0.001830\n",
      "Epoch [300/1500], Loss: 0.001894\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001858\n",
      "Epoch [340/1500], Loss: 0.002482\n",
      "Epoch [360/1500], Loss: 0.001379\n",
      "Epoch [380/1500], Loss: 0.001680\n",
      "Epoch [400/1500], Loss: 0.002185\n",
      "Epoch [420/1500], Loss: 0.001468\n",
      "Epoch [440/1500], Loss: 0.001860\n",
      "Epoch [460/1500], Loss: 0.001891\n",
      "Epoch [480/1500], Loss: 0.001501\n",
      "Epoch [500/1500], Loss: 0.002166\n",
      "Epoch [520/1500], Loss: 0.001397\n",
      "Epoch [540/1500], Loss: 0.002003\n",
      "Epoch [560/1500], Loss: 0.001464\n",
      "Epoch [580/1500], Loss: 0.002110\n",
      "Epoch [600/1500], Loss: 0.001492\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001305\n",
      "Epoch [640/1500], Loss: 0.001463\n",
      "Epoch [660/1500], Loss: 0.001614\n",
      "Epoch [680/1500], Loss: 0.001237\n",
      "Epoch [700/1500], Loss: 0.001500\n",
      "Epoch [720/1500], Loss: 0.001175\n",
      "Epoch [740/1500], Loss: 0.001277\n",
      "Epoch [760/1500], Loss: 0.001461\n",
      "Epoch [780/1500], Loss: 0.001198\n",
      "Epoch [800/1500], Loss: 0.001356\n",
      "Epoch [820/1500], Loss: 0.001162\n",
      "Epoch [840/1500], Loss: 0.001300\n",
      "Epoch [860/1500], Loss: 0.001344\n",
      "Epoch [880/1500], Loss: 0.001365\n",
      "Epoch [900/1500], Loss: 0.001604\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001063\n",
      "Epoch [940/1500], Loss: 0.001084\n",
      "Epoch [960/1500], Loss: 0.001433\n",
      "Epoch [980/1500], Loss: 0.001056\n",
      "Epoch [1000/1500], Loss: 0.001163\n",
      "Epoch [1020/1500], Loss: 0.001125\n",
      "Epoch [1040/1500], Loss: 0.001085\n",
      "Epoch [1060/1500], Loss: 0.001413\n",
      "Epoch [1080/1500], Loss: 0.001043\n",
      "Epoch [1100/1500], Loss: 0.001200\n",
      "Epoch [1120/1500], Loss: 0.001041\n",
      "Epoch [1140/1500], Loss: 0.001106\n",
      "Epoch [1160/1500], Loss: 0.001042\n",
      "Epoch [1180/1500], Loss: 0.001220\n",
      "Epoch [1200/1500], Loss: 0.001055\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001256\n",
      "Epoch [1240/1500], Loss: 0.001247\n",
      "Epoch [1260/1500], Loss: 0.001246\n",
      "Epoch [1280/1500], Loss: 0.001246\n",
      "Epoch [1300/1500], Loss: 0.001246\n",
      "Epoch [1320/1500], Loss: 0.001246\n",
      "Epoch [1340/1500], Loss: 0.001246\n",
      "Epoch [1360/1500], Loss: 0.001246\n",
      "Epoch [1380/1500], Loss: 0.001246\n",
      "Epoch [1400/1500], Loss: 0.001246\n",
      "Epoch [1420/1500], Loss: 0.001247\n",
      "Epoch [1440/1500], Loss: 0.001247\n",
      "Epoch [1460/1500], Loss: 0.001247\n",
      "Epoch [1480/1500], Loss: 0.001247\n",
      "Epoch [1500/1500], Loss: 0.001247\n",
      "tensor(0.0216, device='cuda:0')\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.092166 for selected strength\n",
      "We have a total strength of 0.092166 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.077282\n",
      "Epoch [40/1500], Loss: 1.387668\n",
      "Epoch [60/1500], Loss: 0.907264\n",
      "Epoch [80/1500], Loss: 0.570626\n",
      "Epoch [100/1500], Loss: 0.339871\n",
      "Epoch [120/1500], Loss: 0.197242\n",
      "Epoch [140/1500], Loss: 0.111751\n",
      "Epoch [160/1500], Loss: 0.063678\n",
      "Epoch [180/1500], Loss: 0.035988\n",
      "Epoch [200/1500], Loss: 0.019940\n",
      "Epoch [220/1500], Loss: 0.010714\n",
      "Epoch [240/1500], Loss: 0.006224\n",
      "Epoch [260/1500], Loss: 0.004066\n",
      "Epoch [280/1500], Loss: 0.003398\n",
      "Epoch [300/1500], Loss: 0.003710\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002887\n",
      "Epoch [340/1500], Loss: 0.001885\n",
      "Epoch [360/1500], Loss: 0.002137\n",
      "Epoch [380/1500], Loss: 0.003651\n",
      "Epoch [400/1500], Loss: 0.001786\n",
      "Epoch [420/1500], Loss: 0.002405\n",
      "Epoch [440/1500], Loss: 0.003056\n",
      "Epoch [460/1500], Loss: 0.001994\n",
      "Epoch [480/1500], Loss: 0.002455\n",
      "Epoch [500/1500], Loss: 0.001858\n",
      "Epoch [520/1500], Loss: 0.002352\n",
      "Epoch [540/1500], Loss: 0.001992\n",
      "Epoch [560/1500], Loss: 0.002372\n",
      "Epoch [580/1500], Loss: 0.001779\n",
      "Epoch [600/1500], Loss: 0.002714\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002115\n",
      "Epoch [640/1500], Loss: 0.001622\n",
      "Epoch [660/1500], Loss: 0.001924\n",
      "Epoch [680/1500], Loss: 0.001628\n",
      "Epoch [700/1500], Loss: 0.001940\n",
      "Epoch [720/1500], Loss: 0.001536\n",
      "Epoch [740/1500], Loss: 0.001786\n",
      "Epoch [760/1500], Loss: 0.001772\n",
      "Epoch [780/1500], Loss: 0.001815\n",
      "Epoch [800/1500], Loss: 0.001878\n",
      "Epoch [820/1500], Loss: 0.001803\n",
      "Epoch [840/1500], Loss: 0.001607\n",
      "Epoch [860/1500], Loss: 0.001783\n",
      "Epoch [880/1500], Loss: 0.001553\n",
      "Epoch [900/1500], Loss: 0.001957\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001570\n",
      "Epoch [940/1500], Loss: 0.001466\n",
      "Epoch [960/1500], Loss: 0.001506\n",
      "Epoch [980/1500], Loss: 0.001584\n",
      "Epoch [1000/1500], Loss: 0.001464\n",
      "Epoch [1020/1500], Loss: 0.001652\n",
      "Epoch [1040/1500], Loss: 0.001474\n",
      "Epoch [1060/1500], Loss: 0.001609\n",
      "Epoch [1080/1500], Loss: 0.001516\n",
      "Epoch [1100/1500], Loss: 0.001486\n",
      "Epoch [1120/1500], Loss: 0.001529\n",
      "Epoch [1140/1500], Loss: 0.001485\n",
      "Epoch [1160/1500], Loss: 0.001544\n",
      "Epoch [1180/1500], Loss: 0.001465\n",
      "Epoch [1200/1500], Loss: 0.001549\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001871\n",
      "Epoch [1240/1500], Loss: 0.001854\n",
      "Epoch [1260/1500], Loss: 0.001852\n",
      "Epoch [1280/1500], Loss: 0.001852\n",
      "Epoch [1300/1500], Loss: 0.001852\n",
      "Epoch [1320/1500], Loss: 0.001852\n",
      "Epoch [1340/1500], Loss: 0.001852\n",
      "Epoch [1360/1500], Loss: 0.001852\n",
      "Epoch [1380/1500], Loss: 0.001852\n",
      "Epoch [1400/1500], Loss: 0.001852\n",
      "Epoch [1420/1500], Loss: 0.001852\n",
      "Epoch [1440/1500], Loss: 0.001852\n",
      "Epoch [1460/1500], Loss: 0.001852\n",
      "Epoch [1480/1500], Loss: 0.001852\n",
      "Epoch [1500/1500], Loss: 0.001852\n",
      "tensor(0.0389, device='cuda:0')\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.212524 for selected strength\n",
      "We have a total strength of 0.212524 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.075146\n",
      "Epoch [40/1500], Loss: 1.386703\n",
      "Epoch [60/1500], Loss: 0.911832\n",
      "Epoch [80/1500], Loss: 0.575427\n",
      "Epoch [100/1500], Loss: 0.343585\n",
      "Epoch [120/1500], Loss: 0.198582\n",
      "Epoch [140/1500], Loss: 0.113400\n",
      "Epoch [160/1500], Loss: 0.063901\n",
      "Epoch [180/1500], Loss: 0.035625\n",
      "Epoch [200/1500], Loss: 0.019719\n",
      "Epoch [220/1500], Loss: 0.011059\n",
      "Epoch [240/1500], Loss: 0.006967\n",
      "Epoch [260/1500], Loss: 0.005592\n",
      "Epoch [280/1500], Loss: 0.002870\n",
      "Epoch [300/1500], Loss: 0.002586\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002459\n",
      "Epoch [340/1500], Loss: 0.003482\n",
      "Epoch [360/1500], Loss: 0.001990\n",
      "Epoch [380/1500], Loss: 0.002327\n",
      "Epoch [400/1500], Loss: 0.002186\n",
      "Epoch [420/1500], Loss: 0.002178\n",
      "Epoch [440/1500], Loss: 0.003391\n",
      "Epoch [460/1500], Loss: 0.001977\n",
      "Epoch [480/1500], Loss: 0.002580\n",
      "Epoch [500/1500], Loss: 0.001934\n",
      "Epoch [520/1500], Loss: 0.002443\n",
      "Epoch [540/1500], Loss: 0.001999\n",
      "Epoch [560/1500], Loss: 0.002561\n",
      "Epoch [580/1500], Loss: 0.001946\n",
      "Epoch [600/1500], Loss: 0.002531\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002030\n",
      "Epoch [640/1500], Loss: 0.001870\n",
      "Epoch [660/1500], Loss: 0.001979\n",
      "Epoch [680/1500], Loss: 0.001743\n",
      "Epoch [700/1500], Loss: 0.002064\n",
      "Epoch [720/1500], Loss: 0.001740\n",
      "Epoch [740/1500], Loss: 0.002115\n",
      "Epoch [760/1500], Loss: 0.001675\n",
      "Epoch [780/1500], Loss: 0.002068\n",
      "Epoch [800/1500], Loss: 0.001675\n",
      "Epoch [820/1500], Loss: 0.002109\n",
      "Epoch [840/1500], Loss: 0.001666\n",
      "Epoch [860/1500], Loss: 0.002087\n",
      "Epoch [880/1500], Loss: 0.001649\n",
      "Epoch [900/1500], Loss: 0.001949\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001699\n",
      "Epoch [940/1500], Loss: 0.001626\n",
      "Epoch [960/1500], Loss: 0.001578\n",
      "Epoch [980/1500], Loss: 0.001639\n",
      "Epoch [1000/1500], Loss: 0.001597\n",
      "Epoch [1020/1500], Loss: 0.001588\n",
      "Epoch [1040/1500], Loss: 0.001661\n",
      "Epoch [1060/1500], Loss: 0.001600\n",
      "Epoch [1080/1500], Loss: 0.001581\n",
      "Epoch [1100/1500], Loss: 0.001663\n",
      "Epoch [1120/1500], Loss: 0.001603\n",
      "Epoch [1140/1500], Loss: 0.001582\n",
      "Epoch [1160/1500], Loss: 0.001671\n",
      "Epoch [1180/1500], Loss: 0.001653\n",
      "Epoch [1200/1500], Loss: 0.001578\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.002050\n",
      "Epoch [1240/1500], Loss: 0.002032\n",
      "Epoch [1260/1500], Loss: 0.002031\n",
      "Epoch [1280/1500], Loss: 0.002030\n",
      "Epoch [1300/1500], Loss: 0.002030\n",
      "Epoch [1320/1500], Loss: 0.002030\n",
      "Epoch [1340/1500], Loss: 0.002030\n",
      "Epoch [1360/1500], Loss: 0.002030\n",
      "Epoch [1380/1500], Loss: 0.002030\n",
      "Epoch [1400/1500], Loss: 0.002031\n",
      "Epoch [1420/1500], Loss: 0.002031\n",
      "Epoch [1440/1500], Loss: 0.002031\n",
      "Epoch [1460/1500], Loss: 0.002031\n",
      "Epoch [1480/1500], Loss: 0.002031\n",
      "Epoch [1500/1500], Loss: 0.002031\n",
      "tensor(0.0404, device='cuda:0')\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.168984 for selected strength\n",
      "We have a total strength of 0.168984 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.033645\n",
      "Epoch [40/1500], Loss: 1.321895\n",
      "Epoch [60/1500], Loss: 0.824325\n",
      "Epoch [80/1500], Loss: 0.480928\n",
      "Epoch [100/1500], Loss: 0.256227\n",
      "Epoch [120/1500], Loss: 0.130790\n",
      "Epoch [140/1500], Loss: 0.066464\n",
      "Epoch [160/1500], Loss: 0.034605\n",
      "Epoch [180/1500], Loss: 0.018362\n",
      "Epoch [200/1500], Loss: 0.009489\n",
      "Epoch [220/1500], Loss: 0.006590\n",
      "Epoch [240/1500], Loss: 0.002852\n",
      "Epoch [260/1500], Loss: 0.002460\n",
      "Epoch [280/1500], Loss: 0.002515\n",
      "Epoch [300/1500], Loss: 0.002814\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001545\n",
      "Epoch [340/1500], Loss: 0.001925\n",
      "Epoch [360/1500], Loss: 0.001874\n",
      "Epoch [380/1500], Loss: 0.001435\n",
      "Epoch [400/1500], Loss: 0.001898\n",
      "Epoch [420/1500], Loss: 0.001390\n",
      "Epoch [440/1500], Loss: 0.001739\n",
      "Epoch [460/1500], Loss: 0.002214\n",
      "Epoch [480/1500], Loss: 0.001498\n",
      "Epoch [500/1500], Loss: 0.002032\n",
      "Epoch [520/1500], Loss: 0.001334\n",
      "Epoch [540/1500], Loss: 0.001880\n",
      "Epoch [560/1500], Loss: 0.002116\n",
      "Epoch [580/1500], Loss: 0.001755\n",
      "Epoch [600/1500], Loss: 0.001474\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001732\n",
      "Epoch [640/1500], Loss: 0.001305\n",
      "Epoch [660/1500], Loss: 0.001721\n",
      "Epoch [680/1500], Loss: 0.001190\n",
      "Epoch [700/1500], Loss: 0.001592\n",
      "Epoch [720/1500], Loss: 0.001220\n",
      "Epoch [740/1500], Loss: 0.001700\n",
      "Epoch [760/1500], Loss: 0.001251\n",
      "Epoch [780/1500], Loss: 0.001925\n",
      "Epoch [800/1500], Loss: 0.001355\n",
      "Epoch [820/1500], Loss: 0.001894\n",
      "Epoch [840/1500], Loss: 0.001332\n",
      "Epoch [860/1500], Loss: 0.002652\n",
      "Epoch [880/1500], Loss: 0.001569\n",
      "Epoch [900/1500], Loss: 0.001222\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001138\n",
      "Epoch [940/1500], Loss: 0.001081\n",
      "Epoch [960/1500], Loss: 0.001097\n",
      "Epoch [980/1500], Loss: 0.001217\n",
      "Epoch [1000/1500], Loss: 0.001070\n",
      "Epoch [1020/1500], Loss: 0.001195\n",
      "Epoch [1040/1500], Loss: 0.001067\n",
      "Epoch [1060/1500], Loss: 0.001136\n",
      "Epoch [1080/1500], Loss: 0.001080\n",
      "Epoch [1100/1500], Loss: 0.001106\n",
      "Epoch [1120/1500], Loss: 0.001078\n",
      "Epoch [1140/1500], Loss: 0.001122\n",
      "Epoch [1160/1500], Loss: 0.001096\n",
      "Epoch [1180/1500], Loss: 0.001092\n",
      "Epoch [1200/1500], Loss: 0.001183\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001263\n",
      "Epoch [1240/1500], Loss: 0.001255\n",
      "Epoch [1260/1500], Loss: 0.001254\n",
      "Epoch [1280/1500], Loss: 0.001254\n",
      "Epoch [1300/1500], Loss: 0.001254\n",
      "Epoch [1320/1500], Loss: 0.001254\n",
      "Epoch [1340/1500], Loss: 0.001254\n",
      "Epoch [1360/1500], Loss: 0.001254\n",
      "Epoch [1380/1500], Loss: 0.001254\n",
      "Epoch [1400/1500], Loss: 0.001254\n",
      "Epoch [1420/1500], Loss: 0.001254\n",
      "Epoch [1440/1500], Loss: 0.001254\n",
      "Epoch [1460/1500], Loss: 0.001254\n",
      "Epoch [1480/1500], Loss: 0.001254\n",
      "Epoch [1500/1500], Loss: 0.001254\n",
      "tensor(0.0145, device='cuda:0')\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.094572 for selected strength\n",
      "We have a total strength of 0.094572 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.037876\n",
      "Epoch [40/1500], Loss: 1.324897\n",
      "Epoch [60/1500], Loss: 0.837023\n",
      "Epoch [80/1500], Loss: 0.495937\n",
      "Epoch [100/1500], Loss: 0.269958\n",
      "Epoch [120/1500], Loss: 0.140134\n",
      "Epoch [140/1500], Loss: 0.072793\n",
      "Epoch [160/1500], Loss: 0.037161\n",
      "Epoch [180/1500], Loss: 0.018834\n",
      "Epoch [200/1500], Loss: 0.009681\n",
      "Epoch [220/1500], Loss: 0.006211\n",
      "Epoch [240/1500], Loss: 0.003961\n",
      "Epoch [260/1500], Loss: 0.002160\n",
      "Epoch [280/1500], Loss: 0.002323\n",
      "Epoch [300/1500], Loss: 0.003733\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001479\n",
      "Epoch [340/1500], Loss: 0.002027\n",
      "Epoch [360/1500], Loss: 0.001948\n",
      "Epoch [380/1500], Loss: 0.001552\n",
      "Epoch [400/1500], Loss: 0.002228\n",
      "Epoch [420/1500], Loss: 0.001416\n",
      "Epoch [440/1500], Loss: 0.002122\n",
      "Epoch [460/1500], Loss: 0.001661\n",
      "Epoch [480/1500], Loss: 0.001706\n",
      "Epoch [500/1500], Loss: 0.002392\n",
      "Epoch [520/1500], Loss: 0.001509\n",
      "Epoch [540/1500], Loss: 0.002601\n",
      "Epoch [560/1500], Loss: 0.001462\n",
      "Epoch [580/1500], Loss: 0.002299\n",
      "Epoch [600/1500], Loss: 0.001361\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001425\n",
      "Epoch [640/1500], Loss: 0.001315\n",
      "Epoch [660/1500], Loss: 0.001164\n",
      "Epoch [680/1500], Loss: 0.001477\n",
      "Epoch [700/1500], Loss: 0.001152\n",
      "Epoch [720/1500], Loss: 0.001452\n",
      "Epoch [740/1500], Loss: 0.001180\n",
      "Epoch [760/1500], Loss: 0.001244\n",
      "Epoch [780/1500], Loss: 0.001535\n",
      "Epoch [800/1500], Loss: 0.001203\n",
      "Epoch [820/1500], Loss: 0.001758\n",
      "Epoch [840/1500], Loss: 0.001286\n",
      "Epoch [860/1500], Loss: 0.001561\n",
      "Epoch [880/1500], Loss: 0.001387\n",
      "Epoch [900/1500], Loss: 0.001156\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001119\n",
      "Epoch [940/1500], Loss: 0.001137\n",
      "Epoch [960/1500], Loss: 0.001060\n",
      "Epoch [980/1500], Loss: 0.001049\n",
      "Epoch [1000/1500], Loss: 0.001293\n",
      "Epoch [1020/1500], Loss: 0.001070\n",
      "Epoch [1040/1500], Loss: 0.001047\n",
      "Epoch [1060/1500], Loss: 0.001150\n",
      "Epoch [1080/1500], Loss: 0.001200\n",
      "Epoch [1100/1500], Loss: 0.001052\n",
      "Epoch [1120/1500], Loss: 0.001079\n",
      "Epoch [1140/1500], Loss: 0.001122\n",
      "Epoch [1160/1500], Loss: 0.001051\n",
      "Epoch [1180/1500], Loss: 0.001172\n",
      "Epoch [1200/1500], Loss: 0.001119\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001190\n",
      "Epoch [1240/1500], Loss: 0.001188\n",
      "Epoch [1260/1500], Loss: 0.001188\n",
      "Epoch [1280/1500], Loss: 0.001188\n",
      "Epoch [1300/1500], Loss: 0.001188\n",
      "Epoch [1320/1500], Loss: 0.001188\n",
      "Epoch [1340/1500], Loss: 0.001188\n",
      "Epoch [1360/1500], Loss: 0.001188\n",
      "Epoch [1380/1500], Loss: 0.001188\n",
      "Epoch [1400/1500], Loss: 0.001188\n",
      "Epoch [1420/1500], Loss: 0.001188\n",
      "Epoch [1440/1500], Loss: 0.001188\n",
      "Epoch [1460/1500], Loss: 0.001188\n",
      "Epoch [1480/1500], Loss: 0.001188\n",
      "Epoch [1500/1500], Loss: 0.001188\n",
      "tensor(0.0207, device='cuda:0')\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.082736 for selected strength\n",
      "We have a total strength of 0.082736 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.058351\n",
      "Epoch [40/1500], Loss: 1.345993\n",
      "Epoch [60/1500], Loss: 0.850290\n",
      "Epoch [80/1500], Loss: 0.504876\n",
      "Epoch [100/1500], Loss: 0.273943\n",
      "Epoch [120/1500], Loss: 0.140027\n",
      "Epoch [140/1500], Loss: 0.069305\n",
      "Epoch [160/1500], Loss: 0.034701\n",
      "Epoch [180/1500], Loss: 0.016856\n",
      "Epoch [200/1500], Loss: 0.007664\n",
      "Epoch [220/1500], Loss: 0.004005\n",
      "Epoch [240/1500], Loss: 0.002829\n",
      "Epoch [260/1500], Loss: 0.003137\n",
      "Epoch [280/1500], Loss: 0.002338\n",
      "Epoch [300/1500], Loss: 0.002024\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002107\n",
      "Epoch [340/1500], Loss: 0.002169\n",
      "Epoch [360/1500], Loss: 0.001694\n",
      "Epoch [380/1500], Loss: 0.001984\n",
      "Epoch [400/1500], Loss: 0.002690\n",
      "Epoch [420/1500], Loss: 0.001664\n",
      "Epoch [440/1500], Loss: 0.002007\n",
      "Epoch [460/1500], Loss: 0.001635\n",
      "Epoch [480/1500], Loss: 0.001976\n",
      "Epoch [500/1500], Loss: 0.002243\n",
      "Epoch [520/1500], Loss: 0.001743\n",
      "Epoch [540/1500], Loss: 0.002247\n",
      "Epoch [560/1500], Loss: 0.001575\n",
      "Epoch [580/1500], Loss: 0.002181\n",
      "Epoch [600/1500], Loss: 0.001604\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001515\n",
      "Epoch [640/1500], Loss: 0.001699\n",
      "Epoch [660/1500], Loss: 0.001529\n",
      "Epoch [680/1500], Loss: 0.001443\n",
      "Epoch [700/1500], Loss: 0.001641\n",
      "Epoch [720/1500], Loss: 0.001473\n",
      "Epoch [740/1500], Loss: 0.001537\n",
      "Epoch [760/1500], Loss: 0.001443\n",
      "Epoch [780/1500], Loss: 0.001551\n",
      "Epoch [800/1500], Loss: 0.001463\n",
      "Epoch [820/1500], Loss: 0.001707\n",
      "Epoch [840/1500], Loss: 0.001446\n",
      "Epoch [860/1500], Loss: 0.001716\n",
      "Epoch [880/1500], Loss: 0.001461\n",
      "Epoch [900/1500], Loss: 0.001508\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001443\n",
      "Epoch [940/1500], Loss: 0.001313\n",
      "Epoch [960/1500], Loss: 0.001312\n",
      "Epoch [980/1500], Loss: 0.001509\n",
      "Epoch [1000/1500], Loss: 0.001324\n",
      "Epoch [1020/1500], Loss: 0.001312\n",
      "Epoch [1040/1500], Loss: 0.001489\n",
      "Epoch [1060/1500], Loss: 0.001330\n",
      "Epoch [1080/1500], Loss: 0.001309\n",
      "Epoch [1100/1500], Loss: 0.001408\n",
      "Epoch [1120/1500], Loss: 0.001379\n",
      "Epoch [1140/1500], Loss: 0.001312\n",
      "Epoch [1160/1500], Loss: 0.001376\n",
      "Epoch [1180/1500], Loss: 0.001436\n",
      "Epoch [1200/1500], Loss: 0.001324\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001568\n",
      "Epoch [1240/1500], Loss: 0.001550\n",
      "Epoch [1260/1500], Loss: 0.001548\n",
      "Epoch [1280/1500], Loss: 0.001548\n",
      "Epoch [1300/1500], Loss: 0.001548\n",
      "Epoch [1320/1500], Loss: 0.001548\n",
      "Epoch [1340/1500], Loss: 0.001548\n",
      "Epoch [1360/1500], Loss: 0.001548\n",
      "Epoch [1380/1500], Loss: 0.001548\n",
      "Epoch [1400/1500], Loss: 0.001548\n",
      "Epoch [1420/1500], Loss: 0.001548\n",
      "Epoch [1440/1500], Loss: 0.001548\n",
      "Epoch [1460/1500], Loss: 0.001548\n",
      "Epoch [1480/1500], Loss: 0.001548\n",
      "Epoch [1500/1500], Loss: 0.001548\n",
      "tensor(0.0496, device='cuda:0')\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.190322 for selected strength\n",
      "We have a total strength of 0.190322 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.052696\n",
      "Epoch [40/1500], Loss: 1.346684\n",
      "Epoch [60/1500], Loss: 0.850669\n",
      "Epoch [80/1500], Loss: 0.500342\n",
      "Epoch [100/1500], Loss: 0.266055\n",
      "Epoch [120/1500], Loss: 0.130655\n",
      "Epoch [140/1500], Loss: 0.062606\n",
      "Epoch [160/1500], Loss: 0.029520\n",
      "Epoch [180/1500], Loss: 0.014086\n",
      "Epoch [200/1500], Loss: 0.007141\n",
      "Epoch [220/1500], Loss: 0.004115\n",
      "Epoch [240/1500], Loss: 0.002862\n",
      "Epoch [260/1500], Loss: 0.002691\n",
      "Epoch [280/1500], Loss: 0.003861\n",
      "Epoch [300/1500], Loss: 0.001851\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001848\n",
      "Epoch [340/1500], Loss: 0.002100\n",
      "Epoch [360/1500], Loss: 0.003607\n",
      "Epoch [380/1500], Loss: 0.001680\n",
      "Epoch [400/1500], Loss: 0.002176\n",
      "Epoch [420/1500], Loss: 0.003440\n",
      "Epoch [440/1500], Loss: 0.001662\n",
      "Epoch [460/1500], Loss: 0.002159\n",
      "Epoch [480/1500], Loss: 0.001614\n",
      "Epoch [500/1500], Loss: 0.002025\n",
      "Epoch [520/1500], Loss: 0.002529\n",
      "Epoch [540/1500], Loss: 0.001906\n",
      "Epoch [560/1500], Loss: 0.003500\n",
      "Epoch [580/1500], Loss: 0.001831\n",
      "Epoch [600/1500], Loss: 0.002565\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001860\n",
      "Epoch [640/1500], Loss: 0.001481\n",
      "Epoch [660/1500], Loss: 0.001597\n",
      "Epoch [680/1500], Loss: 0.001823\n",
      "Epoch [700/1500], Loss: 0.001504\n",
      "Epoch [720/1500], Loss: 0.001544\n",
      "Epoch [740/1500], Loss: 0.001818\n",
      "Epoch [760/1500], Loss: 0.001453\n",
      "Epoch [780/1500], Loss: 0.001637\n",
      "Epoch [800/1500], Loss: 0.001406\n",
      "Epoch [820/1500], Loss: 0.001562\n",
      "Epoch [840/1500], Loss: 0.001575\n",
      "Epoch [860/1500], Loss: 0.001536\n",
      "Epoch [880/1500], Loss: 0.001845\n",
      "Epoch [900/1500], Loss: 0.001507\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001395\n",
      "Epoch [940/1500], Loss: 0.001393\n",
      "Epoch [960/1500], Loss: 0.001416\n",
      "Epoch [980/1500], Loss: 0.001379\n",
      "Epoch [1000/1500], Loss: 0.001391\n",
      "Epoch [1020/1500], Loss: 0.001391\n",
      "Epoch [1040/1500], Loss: 0.001381\n",
      "Epoch [1060/1500], Loss: 0.001405\n",
      "Epoch [1080/1500], Loss: 0.001390\n",
      "Epoch [1100/1500], Loss: 0.001386\n",
      "Epoch [1120/1500], Loss: 0.001378\n",
      "Epoch [1140/1500], Loss: 0.001394\n",
      "Epoch [1160/1500], Loss: 0.001396\n",
      "Epoch [1180/1500], Loss: 0.001377\n",
      "Epoch [1200/1500], Loss: 0.001383\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001695\n",
      "Epoch [1240/1500], Loss: 0.001689\n",
      "Epoch [1260/1500], Loss: 0.001689\n",
      "Epoch [1280/1500], Loss: 0.001689\n",
      "Epoch [1300/1500], Loss: 0.001689\n",
      "Epoch [1320/1500], Loss: 0.001689\n",
      "Epoch [1340/1500], Loss: 0.001689\n",
      "Epoch [1360/1500], Loss: 0.001689\n",
      "Epoch [1380/1500], Loss: 0.001689\n",
      "Epoch [1400/1500], Loss: 0.001689\n",
      "Epoch [1420/1500], Loss: 0.001689\n",
      "Epoch [1440/1500], Loss: 0.001689\n",
      "Epoch [1460/1500], Loss: 0.001689\n",
      "Epoch [1480/1500], Loss: 0.001689\n",
      "Epoch [1500/1500], Loss: 0.001689\n",
      "tensor(0.0214, device='cuda:0')\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.121399 for selected strength\n",
      "We have a total strength of 0.121399 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.036772\n",
      "Epoch [40/1500], Loss: 1.335758\n",
      "Epoch [60/1500], Loss: 0.850593\n",
      "Epoch [80/1500], Loss: 0.508767\n",
      "Epoch [100/1500], Loss: 0.279716\n",
      "Epoch [120/1500], Loss: 0.146166\n",
      "Epoch [140/1500], Loss: 0.075810\n",
      "Epoch [160/1500], Loss: 0.038050\n",
      "Epoch [180/1500], Loss: 0.018765\n",
      "Epoch [200/1500], Loss: 0.009332\n",
      "Epoch [220/1500], Loss: 0.004968\n",
      "Epoch [240/1500], Loss: 0.003056\n",
      "Epoch [260/1500], Loss: 0.002522\n",
      "Epoch [280/1500], Loss: 0.002408\n",
      "Epoch [300/1500], Loss: 0.002763\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002442\n",
      "Epoch [340/1500], Loss: 0.001966\n",
      "Epoch [360/1500], Loss: 0.001976\n",
      "Epoch [380/1500], Loss: 0.002164\n",
      "Epoch [400/1500], Loss: 0.002013\n",
      "Epoch [420/1500], Loss: 0.001913\n",
      "Epoch [440/1500], Loss: 0.002082\n",
      "Epoch [460/1500], Loss: 0.002102\n",
      "Epoch [480/1500], Loss: 0.001876\n",
      "Epoch [500/1500], Loss: 0.002394\n",
      "Epoch [520/1500], Loss: 0.001800\n",
      "Epoch [540/1500], Loss: 0.002113\n",
      "Epoch [560/1500], Loss: 0.001838\n",
      "Epoch [580/1500], Loss: 0.001981\n",
      "Epoch [600/1500], Loss: 0.002424\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001630\n",
      "Epoch [640/1500], Loss: 0.001756\n",
      "Epoch [660/1500], Loss: 0.002281\n",
      "Epoch [680/1500], Loss: 0.001676\n",
      "Epoch [700/1500], Loss: 0.001837\n",
      "Epoch [720/1500], Loss: 0.001822\n",
      "Epoch [740/1500], Loss: 0.001801\n",
      "Epoch [760/1500], Loss: 0.001698\n",
      "Epoch [780/1500], Loss: 0.001757\n",
      "Epoch [800/1500], Loss: 0.002356\n",
      "Epoch [820/1500], Loss: 0.001712\n",
      "Epoch [840/1500], Loss: 0.002209\n",
      "Epoch [860/1500], Loss: 0.001708\n",
      "Epoch [880/1500], Loss: 0.002063\n",
      "Epoch [900/1500], Loss: 0.001748\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001617\n",
      "Epoch [940/1500], Loss: 0.001631\n",
      "Epoch [960/1500], Loss: 0.001624\n",
      "Epoch [980/1500], Loss: 0.001621\n",
      "Epoch [1000/1500], Loss: 0.001600\n",
      "Epoch [1020/1500], Loss: 0.001623\n",
      "Epoch [1040/1500], Loss: 0.001616\n",
      "Epoch [1060/1500], Loss: 0.001593\n",
      "Epoch [1080/1500], Loss: 0.001639\n",
      "Epoch [1100/1500], Loss: 0.001608\n",
      "Epoch [1120/1500], Loss: 0.001633\n",
      "Epoch [1140/1500], Loss: 0.001611\n",
      "Epoch [1160/1500], Loss: 0.001601\n",
      "Epoch [1180/1500], Loss: 0.001601\n",
      "Epoch [1200/1500], Loss: 0.001619\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001981\n",
      "Epoch [1240/1500], Loss: 0.001973\n",
      "Epoch [1260/1500], Loss: 0.001972\n",
      "Epoch [1280/1500], Loss: 0.001972\n",
      "Epoch [1300/1500], Loss: 0.001972\n",
      "Epoch [1320/1500], Loss: 0.001972\n",
      "Epoch [1340/1500], Loss: 0.001972\n",
      "Epoch [1360/1500], Loss: 0.001972\n",
      "Epoch [1380/1500], Loss: 0.001972\n",
      "Epoch [1400/1500], Loss: 0.001972\n",
      "Epoch [1420/1500], Loss: 0.001972\n",
      "Epoch [1440/1500], Loss: 0.001972\n",
      "Epoch [1460/1500], Loss: 0.001972\n",
      "Epoch [1480/1500], Loss: 0.001972\n",
      "Epoch [1500/1500], Loss: 0.001972\n",
      "tensor(0.0226, device='cuda:0')\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.194240 for selected strength\n",
      "We have a total strength of 0.194240 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.034444\n",
      "Epoch [40/1500], Loss: 1.322155\n",
      "Epoch [60/1500], Loss: 0.831123\n",
      "Epoch [80/1500], Loss: 0.488509\n",
      "Epoch [100/1500], Loss: 0.262644\n",
      "Epoch [120/1500], Loss: 0.135058\n",
      "Epoch [140/1500], Loss: 0.068527\n",
      "Epoch [160/1500], Loss: 0.034569\n",
      "Epoch [180/1500], Loss: 0.017384\n",
      "Epoch [200/1500], Loss: 0.008775\n",
      "Epoch [220/1500], Loss: 0.004758\n",
      "Epoch [240/1500], Loss: 0.002993\n",
      "Epoch [260/1500], Loss: 0.002485\n",
      "Epoch [280/1500], Loss: 0.003055\n",
      "Epoch [300/1500], Loss: 0.002056\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001731\n",
      "Epoch [340/1500], Loss: 0.001998\n",
      "Epoch [360/1500], Loss: 0.003395\n",
      "Epoch [380/1500], Loss: 0.001500\n",
      "Epoch [400/1500], Loss: 0.001919\n",
      "Epoch [420/1500], Loss: 0.002608\n",
      "Epoch [440/1500], Loss: 0.001729\n",
      "Epoch [460/1500], Loss: 0.002321\n",
      "Epoch [480/1500], Loss: 0.001545\n",
      "Epoch [500/1500], Loss: 0.001998\n",
      "Epoch [520/1500], Loss: 0.001674\n",
      "Epoch [540/1500], Loss: 0.001907\n",
      "Epoch [560/1500], Loss: 0.001721\n",
      "Epoch [580/1500], Loss: 0.001747\n",
      "Epoch [600/1500], Loss: 0.002382\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001912\n",
      "Epoch [640/1500], Loss: 0.001396\n",
      "Epoch [660/1500], Loss: 0.001597\n",
      "Epoch [680/1500], Loss: 0.001489\n",
      "Epoch [700/1500], Loss: 0.001430\n",
      "Epoch [720/1500], Loss: 0.001923\n",
      "Epoch [740/1500], Loss: 0.001359\n",
      "Epoch [760/1500], Loss: 0.001788\n",
      "Epoch [780/1500], Loss: 0.001340\n",
      "Epoch [800/1500], Loss: 0.001897\n",
      "Epoch [820/1500], Loss: 0.001324\n",
      "Epoch [840/1500], Loss: 0.001518\n",
      "Epoch [860/1500], Loss: 0.001320\n",
      "Epoch [880/1500], Loss: 0.001763\n",
      "Epoch [900/1500], Loss: 0.001317\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001262\n",
      "Epoch [940/1500], Loss: 0.001240\n",
      "Epoch [960/1500], Loss: 0.001220\n",
      "Epoch [980/1500], Loss: 0.001227\n",
      "Epoch [1000/1500], Loss: 0.001233\n",
      "Epoch [1020/1500], Loss: 0.001194\n",
      "Epoch [1040/1500], Loss: 0.001222\n",
      "Epoch [1060/1500], Loss: 0.001240\n",
      "Epoch [1080/1500], Loss: 0.001218\n",
      "Epoch [1100/1500], Loss: 0.001220\n",
      "Epoch [1120/1500], Loss: 0.001241\n",
      "Epoch [1140/1500], Loss: 0.001241\n",
      "Epoch [1160/1500], Loss: 0.001257\n",
      "Epoch [1180/1500], Loss: 0.001201\n",
      "Epoch [1200/1500], Loss: 0.001268\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001436\n",
      "Epoch [1240/1500], Loss: 0.001429\n",
      "Epoch [1260/1500], Loss: 0.001429\n",
      "Epoch [1280/1500], Loss: 0.001429\n",
      "Epoch [1300/1500], Loss: 0.001429\n",
      "Epoch [1320/1500], Loss: 0.001429\n",
      "Epoch [1340/1500], Loss: 0.001429\n",
      "Epoch [1360/1500], Loss: 0.001429\n",
      "Epoch [1380/1500], Loss: 0.001429\n",
      "Epoch [1400/1500], Loss: 0.001429\n",
      "Epoch [1420/1500], Loss: 0.001429\n",
      "Epoch [1440/1500], Loss: 0.001429\n",
      "Epoch [1460/1500], Loss: 0.001429\n",
      "Epoch [1480/1500], Loss: 0.001429\n",
      "Epoch [1500/1500], Loss: 0.001429\n",
      "tensor(0.0320, device='cuda:0')\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.127294 for selected strength\n",
      "We have a total strength of 0.127294 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.073771\n",
      "Epoch [40/1500], Loss: 1.374016\n",
      "Epoch [60/1500], Loss: 0.866772\n",
      "Epoch [80/1500], Loss: 0.512647\n",
      "Epoch [100/1500], Loss: 0.278082\n",
      "Epoch [120/1500], Loss: 0.142270\n",
      "Epoch [140/1500], Loss: 0.073423\n",
      "Epoch [160/1500], Loss: 0.038488\n",
      "Epoch [180/1500], Loss: 0.020975\n",
      "Epoch [200/1500], Loss: 0.011693\n",
      "Epoch [220/1500], Loss: 0.007031\n",
      "Epoch [240/1500], Loss: 0.004673\n",
      "Epoch [260/1500], Loss: 0.003677\n",
      "Epoch [280/1500], Loss: 0.003467\n",
      "Epoch [300/1500], Loss: 0.003679\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002183\n",
      "Epoch [340/1500], Loss: 0.002336\n",
      "Epoch [360/1500], Loss: 0.002772\n",
      "Epoch [380/1500], Loss: 0.001830\n",
      "Epoch [400/1500], Loss: 0.002163\n",
      "Epoch [420/1500], Loss: 0.002741\n",
      "Epoch [440/1500], Loss: 0.001931\n",
      "Epoch [460/1500], Loss: 0.002397\n",
      "Epoch [480/1500], Loss: 0.001828\n",
      "Epoch [500/1500], Loss: 0.002361\n",
      "Epoch [520/1500], Loss: 0.002037\n",
      "Epoch [540/1500], Loss: 0.002347\n",
      "Epoch [560/1500], Loss: 0.003328\n",
      "Epoch [580/1500], Loss: 0.002093\n",
      "Epoch [600/1500], Loss: 0.002810\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001661\n",
      "Epoch [640/1500], Loss: 0.001767\n",
      "Epoch [660/1500], Loss: 0.002066\n",
      "Epoch [680/1500], Loss: 0.001652\n",
      "Epoch [700/1500], Loss: 0.002043\n",
      "Epoch [720/1500], Loss: 0.001664\n",
      "Epoch [740/1500], Loss: 0.001804\n",
      "Epoch [760/1500], Loss: 0.001621\n",
      "Epoch [780/1500], Loss: 0.001756\n",
      "Epoch [800/1500], Loss: 0.002136\n",
      "Epoch [820/1500], Loss: 0.001622\n",
      "Epoch [840/1500], Loss: 0.001930\n",
      "Epoch [860/1500], Loss: 0.001652\n",
      "Epoch [880/1500], Loss: 0.001784\n",
      "Epoch [900/1500], Loss: 0.001605\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001727\n",
      "Epoch [940/1500], Loss: 0.001569\n",
      "Epoch [960/1500], Loss: 0.001748\n",
      "Epoch [980/1500], Loss: 0.001576\n",
      "Epoch [1000/1500], Loss: 0.001937\n",
      "Epoch [1020/1500], Loss: 0.001579\n",
      "Epoch [1040/1500], Loss: 0.001924\n",
      "Epoch [1060/1500], Loss: 0.001577\n",
      "Epoch [1080/1500], Loss: 0.001907\n",
      "Epoch [1100/1500], Loss: 0.001585\n",
      "Epoch [1120/1500], Loss: 0.001665\n",
      "Epoch [1140/1500], Loss: 0.001610\n",
      "Epoch [1160/1500], Loss: 0.001576\n",
      "Epoch [1180/1500], Loss: 0.001660\n",
      "Epoch [1200/1500], Loss: 0.001569\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001965\n",
      "Epoch [1240/1500], Loss: 0.001953\n",
      "Epoch [1260/1500], Loss: 0.001952\n",
      "Epoch [1280/1500], Loss: 0.001952\n",
      "Epoch [1300/1500], Loss: 0.001952\n",
      "Epoch [1320/1500], Loss: 0.001952\n",
      "Epoch [1340/1500], Loss: 0.001952\n",
      "Epoch [1360/1500], Loss: 0.001952\n",
      "Epoch [1380/1500], Loss: 0.001952\n",
      "Epoch [1400/1500], Loss: 0.001952\n",
      "Epoch [1420/1500], Loss: 0.001952\n",
      "Epoch [1440/1500], Loss: 0.001952\n",
      "Epoch [1460/1500], Loss: 0.001952\n",
      "Epoch [1480/1500], Loss: 0.001952\n",
      "Epoch [1500/1500], Loss: 0.001952\n",
      "tensor(0.0214, device='cuda:0')\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.187086 for selected strength\n",
      "We have a total strength of 0.187086 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.051651\n",
      "Epoch [40/1500], Loss: 1.357457\n",
      "Epoch [60/1500], Loss: 0.880250\n",
      "Epoch [80/1500], Loss: 0.542623\n",
      "Epoch [100/1500], Loss: 0.312178\n",
      "Epoch [120/1500], Loss: 0.171765\n",
      "Epoch [140/1500], Loss: 0.093246\n",
      "Epoch [160/1500], Loss: 0.049217\n",
      "Epoch [180/1500], Loss: 0.025512\n",
      "Epoch [200/1500], Loss: 0.013286\n",
      "Epoch [220/1500], Loss: 0.007292\n",
      "Epoch [240/1500], Loss: 0.004489\n",
      "Epoch [260/1500], Loss: 0.003622\n",
      "Epoch [280/1500], Loss: 0.003242\n",
      "Epoch [300/1500], Loss: 0.003439\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002078\n",
      "Epoch [340/1500], Loss: 0.002163\n",
      "Epoch [360/1500], Loss: 0.002611\n",
      "Epoch [380/1500], Loss: 0.002932\n",
      "Epoch [400/1500], Loss: 0.002104\n",
      "Epoch [420/1500], Loss: 0.002560\n",
      "Epoch [440/1500], Loss: 0.002022\n",
      "Epoch [460/1500], Loss: 0.002247\n",
      "Epoch [480/1500], Loss: 0.003498\n",
      "Epoch [500/1500], Loss: 0.002199\n",
      "Epoch [520/1500], Loss: 0.002937\n",
      "Epoch [540/1500], Loss: 0.002054\n",
      "Epoch [560/1500], Loss: 0.002492\n",
      "Epoch [580/1500], Loss: 0.002055\n",
      "Epoch [600/1500], Loss: 0.002453\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001931\n",
      "Epoch [640/1500], Loss: 0.001912\n",
      "Epoch [660/1500], Loss: 0.002013\n",
      "Epoch [680/1500], Loss: 0.001888\n",
      "Epoch [700/1500], Loss: 0.002015\n",
      "Epoch [720/1500], Loss: 0.001872\n",
      "Epoch [740/1500], Loss: 0.001842\n",
      "Epoch [760/1500], Loss: 0.001983\n",
      "Epoch [780/1500], Loss: 0.001853\n",
      "Epoch [800/1500], Loss: 0.001881\n",
      "Epoch [820/1500], Loss: 0.002006\n",
      "Epoch [840/1500], Loss: 0.001782\n",
      "Epoch [860/1500], Loss: 0.001974\n",
      "Epoch [880/1500], Loss: 0.002131\n",
      "Epoch [900/1500], Loss: 0.001812\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001740\n",
      "Epoch [940/1500], Loss: 0.001783\n",
      "Epoch [960/1500], Loss: 0.001698\n",
      "Epoch [980/1500], Loss: 0.001756\n",
      "Epoch [1000/1500], Loss: 0.001703\n",
      "Epoch [1020/1500], Loss: 0.001750\n",
      "Epoch [1040/1500], Loss: 0.001706\n",
      "Epoch [1060/1500], Loss: 0.001748\n",
      "Epoch [1080/1500], Loss: 0.001729\n",
      "Epoch [1100/1500], Loss: 0.001746\n",
      "Epoch [1120/1500], Loss: 0.001743\n",
      "Epoch [1140/1500], Loss: 0.001774\n",
      "Epoch [1160/1500], Loss: 0.001733\n",
      "Epoch [1180/1500], Loss: 0.001734\n",
      "Epoch [1200/1500], Loss: 0.001761\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.002143\n",
      "Epoch [1240/1500], Loss: 0.002126\n",
      "Epoch [1260/1500], Loss: 0.002125\n",
      "Epoch [1280/1500], Loss: 0.002125\n",
      "Epoch [1300/1500], Loss: 0.002125\n",
      "Epoch [1320/1500], Loss: 0.002125\n",
      "Epoch [1340/1500], Loss: 0.002125\n",
      "Epoch [1360/1500], Loss: 0.002125\n",
      "Epoch [1380/1500], Loss: 0.002125\n",
      "Epoch [1400/1500], Loss: 0.002125\n",
      "Epoch [1420/1500], Loss: 0.002125\n",
      "Epoch [1440/1500], Loss: 0.002125\n",
      "Epoch [1460/1500], Loss: 0.002125\n",
      "Epoch [1480/1500], Loss: 0.002125\n",
      "Epoch [1500/1500], Loss: 0.002125\n",
      "tensor(0.0291, device='cuda:0')\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.268848 for selected strength\n",
      "We have a total strength of 0.268848 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.040150\n",
      "Epoch [40/1500], Loss: 1.335029\n",
      "Epoch [60/1500], Loss: 0.845309\n",
      "Epoch [80/1500], Loss: 0.502097\n",
      "Epoch [100/1500], Loss: 0.273100\n",
      "Epoch [120/1500], Loss: 0.139965\n",
      "Epoch [140/1500], Loss: 0.070788\n",
      "Epoch [160/1500], Loss: 0.034748\n",
      "Epoch [180/1500], Loss: 0.016988\n",
      "Epoch [200/1500], Loss: 0.008487\n",
      "Epoch [220/1500], Loss: 0.004558\n",
      "Epoch [240/1500], Loss: 0.002965\n",
      "Epoch [260/1500], Loss: 0.002687\n",
      "Epoch [280/1500], Loss: 0.002745\n",
      "Epoch [300/1500], Loss: 0.002094\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.001968\n",
      "Epoch [340/1500], Loss: 0.002076\n",
      "Epoch [360/1500], Loss: 0.002603\n",
      "Epoch [380/1500], Loss: 0.001810\n",
      "Epoch [400/1500], Loss: 0.002034\n",
      "Epoch [420/1500], Loss: 0.002691\n",
      "Epoch [440/1500], Loss: 0.001821\n",
      "Epoch [460/1500], Loss: 0.002189\n",
      "Epoch [480/1500], Loss: 0.003410\n",
      "Epoch [500/1500], Loss: 0.001960\n",
      "Epoch [520/1500], Loss: 0.002677\n",
      "Epoch [540/1500], Loss: 0.001804\n",
      "Epoch [560/1500], Loss: 0.002407\n",
      "Epoch [580/1500], Loss: 0.001861\n",
      "Epoch [600/1500], Loss: 0.002322\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.001762\n",
      "Epoch [640/1500], Loss: 0.001837\n",
      "Epoch [660/1500], Loss: 0.001673\n",
      "Epoch [680/1500], Loss: 0.001624\n",
      "Epoch [700/1500], Loss: 0.001749\n",
      "Epoch [720/1500], Loss: 0.001553\n",
      "Epoch [740/1500], Loss: 0.001593\n",
      "Epoch [760/1500], Loss: 0.001837\n",
      "Epoch [780/1500], Loss: 0.001584\n",
      "Epoch [800/1500], Loss: 0.001747\n",
      "Epoch [820/1500], Loss: 0.001565\n",
      "Epoch [840/1500], Loss: 0.001726\n",
      "Epoch [860/1500], Loss: 0.001652\n",
      "Epoch [880/1500], Loss: 0.001669\n",
      "Epoch [900/1500], Loss: 0.001982\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.001560\n",
      "Epoch [940/1500], Loss: 0.001514\n",
      "Epoch [960/1500], Loss: 0.001510\n",
      "Epoch [980/1500], Loss: 0.001746\n",
      "Epoch [1000/1500], Loss: 0.001497\n",
      "Epoch [1020/1500], Loss: 0.001632\n",
      "Epoch [1040/1500], Loss: 0.001495\n",
      "Epoch [1060/1500], Loss: 0.001566\n",
      "Epoch [1080/1500], Loss: 0.001511\n",
      "Epoch [1100/1500], Loss: 0.001532\n",
      "Epoch [1120/1500], Loss: 0.001534\n",
      "Epoch [1140/1500], Loss: 0.001512\n",
      "Epoch [1160/1500], Loss: 0.001640\n",
      "Epoch [1180/1500], Loss: 0.001509\n",
      "Epoch [1200/1500], Loss: 0.001715\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.001876\n",
      "Epoch [1240/1500], Loss: 0.001866\n",
      "Epoch [1260/1500], Loss: 0.001865\n",
      "Epoch [1280/1500], Loss: 0.001865\n",
      "Epoch [1300/1500], Loss: 0.001865\n",
      "Epoch [1320/1500], Loss: 0.001865\n",
      "Epoch [1340/1500], Loss: 0.001865\n",
      "Epoch [1360/1500], Loss: 0.001865\n",
      "Epoch [1380/1500], Loss: 0.001865\n",
      "Epoch [1400/1500], Loss: 0.001865\n",
      "Epoch [1420/1500], Loss: 0.001865\n",
      "Epoch [1440/1500], Loss: 0.001866\n",
      "Epoch [1460/1500], Loss: 0.001866\n",
      "Epoch [1480/1500], Loss: 0.001866\n",
      "Epoch [1500/1500], Loss: 0.001866\n",
      "tensor(0.0281, device='cuda:0')\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.167527 for selected strength\n",
      "We have a total strength of 0.167527 for all the columns\n",
      " 50%|██████████████████████                      | 2/4 [04:51<04:51, 145.90s/it][3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.045857\n",
      "Epoch [40/1500], Loss: 1.342371\n",
      "Epoch [60/1500], Loss: 0.858183\n",
      "Epoch [80/1500], Loss: 0.517315\n",
      "Epoch [100/1500], Loss: 0.288005\n",
      "Epoch [120/1500], Loss: 0.152859\n",
      "Epoch [140/1500], Loss: 0.080235\n",
      "Epoch [160/1500], Loss: 0.041453\n",
      "Epoch [180/1500], Loss: 0.021443\n",
      "Epoch [200/1500], Loss: 0.011248\n",
      "Epoch [220/1500], Loss: 0.006500\n",
      "Epoch [240/1500], Loss: 0.004298\n",
      "Epoch [260/1500], Loss: 0.003479\n",
      "Epoch [280/1500], Loss: 0.003482\n",
      "Epoch [300/1500], Loss: 0.004100\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002516\n",
      "Epoch [340/1500], Loss: 0.002536\n",
      "Epoch [360/1500], Loss: 0.002975\n",
      "Epoch [380/1500], Loss: 0.003351\n",
      "Epoch [400/1500], Loss: 0.002546\n",
      "Epoch [420/1500], Loss: 0.002865\n",
      "Epoch [440/1500], Loss: 0.002629\n",
      "Epoch [460/1500], Loss: 0.002664\n",
      "Epoch [480/1500], Loss: 0.003790\n",
      "Epoch [500/1500], Loss: 0.002554\n",
      "Epoch [520/1500], Loss: 0.002808\n",
      "Epoch [540/1500], Loss: 0.003743\n",
      "Epoch [560/1500], Loss: 0.002643\n",
      "Epoch [580/1500], Loss: 0.003394\n",
      "Epoch [600/1500], Loss: 0.002551\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002546\n",
      "Epoch [640/1500], Loss: 0.002454\n",
      "Epoch [660/1500], Loss: 0.002456\n",
      "Epoch [680/1500], Loss: 0.002642\n",
      "Epoch [700/1500], Loss: 0.002468\n",
      "Epoch [720/1500], Loss: 0.002688\n",
      "Epoch [740/1500], Loss: 0.002411\n",
      "Epoch [760/1500], Loss: 0.002705\n",
      "Epoch [780/1500], Loss: 0.002369\n",
      "Epoch [800/1500], Loss: 0.002624\n",
      "Epoch [820/1500], Loss: 0.002371\n",
      "Epoch [840/1500], Loss: 0.002595\n",
      "Epoch [860/1500], Loss: 0.002392\n",
      "Epoch [880/1500], Loss: 0.002478\n",
      "Epoch [900/1500], Loss: 0.002736\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002418\n",
      "Epoch [940/1500], Loss: 0.002436\n",
      "Epoch [960/1500], Loss: 0.002417\n",
      "Epoch [980/1500], Loss: 0.002454\n",
      "Epoch [1000/1500], Loss: 0.002434\n",
      "Epoch [1020/1500], Loss: 0.002400\n",
      "Epoch [1040/1500], Loss: 0.002403\n",
      "Epoch [1060/1500], Loss: 0.002405\n",
      "Epoch [1080/1500], Loss: 0.002422\n",
      "Epoch [1100/1500], Loss: 0.002447\n",
      "Epoch [1120/1500], Loss: 0.002428\n",
      "Epoch [1140/1500], Loss: 0.002413\n",
      "Epoch [1160/1500], Loss: 0.002401\n",
      "Epoch [1180/1500], Loss: 0.002410\n",
      "Epoch [1200/1500], Loss: 0.002390\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.002990\n",
      "Epoch [1240/1500], Loss: 0.002962\n",
      "Epoch [1260/1500], Loss: 0.002961\n",
      "Epoch [1280/1500], Loss: 0.002961\n",
      "Epoch [1300/1500], Loss: 0.002961\n",
      "Epoch [1320/1500], Loss: 0.002961\n",
      "Epoch [1340/1500], Loss: 0.002961\n",
      "Epoch [1360/1500], Loss: 0.002961\n",
      "Epoch [1380/1500], Loss: 0.002961\n",
      "Epoch [1400/1500], Loss: 0.002961\n",
      "Epoch [1420/1500], Loss: 0.002961\n",
      "Epoch [1440/1500], Loss: 0.002961\n",
      "Epoch [1460/1500], Loss: 0.002961\n",
      "Epoch [1480/1500], Loss: 0.002961\n",
      "Epoch [1500/1500], Loss: 0.002961\n",
      "tensor(0.0493, device='cuda:0')\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.248577 for selected strength\n",
      "We have a total strength of 0.248577 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.042289\n",
      "Epoch [40/1500], Loss: 1.328918\n",
      "Epoch [60/1500], Loss: 0.837445\n",
      "Epoch [80/1500], Loss: 0.494717\n",
      "Epoch [100/1500], Loss: 0.268117\n",
      "Epoch [120/1500], Loss: 0.138897\n",
      "Epoch [140/1500], Loss: 0.071284\n",
      "Epoch [160/1500], Loss: 0.036392\n",
      "Epoch [180/1500], Loss: 0.019553\n",
      "Epoch [200/1500], Loss: 0.011735\n",
      "Epoch [220/1500], Loss: 0.007613\n",
      "Epoch [240/1500], Loss: 0.004136\n",
      "Epoch [260/1500], Loss: 0.002924\n",
      "Epoch [280/1500], Loss: 0.002793\n",
      "Epoch [300/1500], Loss: 0.002818\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002986\n",
      "Epoch [340/1500], Loss: 0.002443\n",
      "Epoch [360/1500], Loss: 0.002382\n",
      "Epoch [380/1500], Loss: 0.002609\n",
      "Epoch [400/1500], Loss: 0.003129\n",
      "Epoch [420/1500], Loss: 0.002293\n",
      "Epoch [440/1500], Loss: 0.002491\n",
      "Epoch [460/1500], Loss: 0.003188\n",
      "Epoch [480/1500], Loss: 0.002391\n",
      "Epoch [500/1500], Loss: 0.002671\n",
      "Epoch [520/1500], Loss: 0.002456\n",
      "Epoch [540/1500], Loss: 0.002442\n",
      "Epoch [560/1500], Loss: 0.003288\n",
      "Epoch [580/1500], Loss: 0.002383\n",
      "Epoch [600/1500], Loss: 0.002834\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002233\n",
      "Epoch [640/1500], Loss: 0.002522\n",
      "Epoch [660/1500], Loss: 0.002255\n",
      "Epoch [680/1500], Loss: 0.002217\n",
      "Epoch [700/1500], Loss: 0.002500\n",
      "Epoch [720/1500], Loss: 0.002167\n",
      "Epoch [740/1500], Loss: 0.002305\n",
      "Epoch [760/1500], Loss: 0.002281\n",
      "Epoch [780/1500], Loss: 0.002234\n",
      "Epoch [800/1500], Loss: 0.002712\n",
      "Epoch [820/1500], Loss: 0.002167\n",
      "Epoch [840/1500], Loss: 0.002433\n",
      "Epoch [860/1500], Loss: 0.002264\n",
      "Epoch [880/1500], Loss: 0.002206\n",
      "Epoch [900/1500], Loss: 0.002722\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002220\n",
      "Epoch [940/1500], Loss: 0.002191\n",
      "Epoch [960/1500], Loss: 0.002184\n",
      "Epoch [980/1500], Loss: 0.002184\n",
      "Epoch [1000/1500], Loss: 0.002185\n",
      "Epoch [1020/1500], Loss: 0.002185\n",
      "Epoch [1040/1500], Loss: 0.002185\n",
      "Epoch [1060/1500], Loss: 0.002186\n",
      "Epoch [1080/1500], Loss: 0.002185\n",
      "Epoch [1100/1500], Loss: 0.002185\n",
      "Epoch [1120/1500], Loss: 0.002188\n",
      "Epoch [1140/1500], Loss: 0.002192\n",
      "Epoch [1160/1500], Loss: 0.002207\n",
      "Epoch [1180/1500], Loss: 0.002233\n",
      "Epoch [1200/1500], Loss: 0.002242\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.002836\n",
      "Epoch [1240/1500], Loss: 0.002791\n",
      "Epoch [1260/1500], Loss: 0.002788\n",
      "Epoch [1280/1500], Loss: 0.002788\n",
      "Epoch [1300/1500], Loss: 0.002788\n",
      "Epoch [1320/1500], Loss: 0.002788\n",
      "Epoch [1340/1500], Loss: 0.002788\n",
      "Epoch [1360/1500], Loss: 0.002788\n",
      "Epoch [1380/1500], Loss: 0.002788\n",
      "Epoch [1400/1500], Loss: 0.002788\n",
      "Epoch [1420/1500], Loss: 0.002788\n",
      "Epoch [1440/1500], Loss: 0.002788\n",
      "Epoch [1460/1500], Loss: 0.002788\n",
      "Epoch [1480/1500], Loss: 0.002788\n",
      "Epoch [1500/1500], Loss: 0.002788\n",
      "tensor(0.0614, device='cuda:0')\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.257172 for selected strength\n",
      "We have a total strength of 0.257172 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.036617\n",
      "Epoch [40/1500], Loss: 1.320447\n",
      "Epoch [60/1500], Loss: 0.829121\n",
      "Epoch [80/1500], Loss: 0.488634\n",
      "Epoch [100/1500], Loss: 0.264649\n",
      "Epoch [120/1500], Loss: 0.138208\n",
      "Epoch [140/1500], Loss: 0.071882\n",
      "Epoch [160/1500], Loss: 0.037671\n",
      "Epoch [180/1500], Loss: 0.020999\n",
      "Epoch [200/1500], Loss: 0.011775\n",
      "Epoch [220/1500], Loss: 0.007179\n",
      "Epoch [240/1500], Loss: 0.004500\n",
      "Epoch [260/1500], Loss: 0.003827\n",
      "Epoch [280/1500], Loss: 0.003667\n",
      "Epoch [300/1500], Loss: 0.004277\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003070\n",
      "Epoch [340/1500], Loss: 0.003110\n",
      "Epoch [360/1500], Loss: 0.003358\n",
      "Epoch [380/1500], Loss: 0.003425\n",
      "Epoch [400/1500], Loss: 0.003028\n",
      "Epoch [420/1500], Loss: 0.003208\n",
      "Epoch [440/1500], Loss: 0.004162\n",
      "Epoch [460/1500], Loss: 0.003085\n",
      "Epoch [480/1500], Loss: 0.003281\n",
      "Epoch [500/1500], Loss: 0.004066\n",
      "Epoch [520/1500], Loss: 0.003111\n",
      "Epoch [540/1500], Loss: 0.003575\n",
      "Epoch [560/1500], Loss: 0.003023\n",
      "Epoch [580/1500], Loss: 0.003420\n",
      "Epoch [600/1500], Loss: 0.003047\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.003459\n",
      "Epoch [640/1500], Loss: 0.002965\n",
      "Epoch [660/1500], Loss: 0.003191\n",
      "Epoch [680/1500], Loss: 0.002957\n",
      "Epoch [700/1500], Loss: 0.002973\n",
      "Epoch [720/1500], Loss: 0.003361\n",
      "Epoch [740/1500], Loss: 0.002932\n",
      "Epoch [760/1500], Loss: 0.003197\n",
      "Epoch [780/1500], Loss: 0.002969\n",
      "Epoch [800/1500], Loss: 0.003018\n",
      "Epoch [820/1500], Loss: 0.003191\n",
      "Epoch [840/1500], Loss: 0.002973\n",
      "Epoch [860/1500], Loss: 0.003529\n",
      "Epoch [880/1500], Loss: 0.002961\n",
      "Epoch [900/1500], Loss: 0.003447\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.003055\n",
      "Epoch [940/1500], Loss: 0.002993\n",
      "Epoch [960/1500], Loss: 0.002990\n",
      "Epoch [980/1500], Loss: 0.002984\n",
      "Epoch [1000/1500], Loss: 0.002986\n",
      "Epoch [1020/1500], Loss: 0.002986\n",
      "Epoch [1040/1500], Loss: 0.002993\n",
      "Epoch [1060/1500], Loss: 0.002996\n",
      "Epoch [1080/1500], Loss: 0.002988\n",
      "Epoch [1100/1500], Loss: 0.002988\n",
      "Epoch [1120/1500], Loss: 0.002990\n",
      "Epoch [1140/1500], Loss: 0.002998\n",
      "Epoch [1160/1500], Loss: 0.002999\n",
      "Epoch [1180/1500], Loss: 0.002995\n",
      "Epoch [1200/1500], Loss: 0.002997\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.003967\n",
      "Epoch [1240/1500], Loss: 0.003898\n",
      "Epoch [1260/1500], Loss: 0.003894\n",
      "Epoch [1280/1500], Loss: 0.003894\n",
      "Epoch [1300/1500], Loss: 0.003894\n",
      "Epoch [1320/1500], Loss: 0.003894\n",
      "Epoch [1340/1500], Loss: 0.003894\n",
      "Epoch [1360/1500], Loss: 0.003894\n",
      "Epoch [1380/1500], Loss: 0.003894\n",
      "Epoch [1400/1500], Loss: 0.003894\n",
      "Epoch [1420/1500], Loss: 0.003894\n",
      "Epoch [1440/1500], Loss: 0.003894\n",
      "Epoch [1460/1500], Loss: 0.003894\n",
      "Epoch [1480/1500], Loss: 0.003894\n",
      "Epoch [1500/1500], Loss: 0.003894\n",
      "tensor(0.0455, device='cuda:0')\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.364156 for selected strength\n",
      "We have a total strength of 0.364156 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.089831\n",
      "Epoch [40/1500], Loss: 1.400783\n",
      "Epoch [60/1500], Loss: 0.919833\n",
      "Epoch [80/1500], Loss: 0.580718\n",
      "Epoch [100/1500], Loss: 0.345907\n",
      "Epoch [120/1500], Loss: 0.197080\n",
      "Epoch [140/1500], Loss: 0.108430\n",
      "Epoch [160/1500], Loss: 0.059076\n",
      "Epoch [180/1500], Loss: 0.031482\n",
      "Epoch [200/1500], Loss: 0.016938\n",
      "Epoch [220/1500], Loss: 0.009929\n",
      "Epoch [240/1500], Loss: 0.006543\n",
      "Epoch [260/1500], Loss: 0.005850\n",
      "Epoch [280/1500], Loss: 0.003483\n",
      "Epoch [300/1500], Loss: 0.003162\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003073\n",
      "Epoch [340/1500], Loss: 0.003992\n",
      "Epoch [360/1500], Loss: 0.002730\n",
      "Epoch [380/1500], Loss: 0.003135\n",
      "Epoch [400/1500], Loss: 0.002997\n",
      "Epoch [420/1500], Loss: 0.002750\n",
      "Epoch [440/1500], Loss: 0.003381\n",
      "Epoch [460/1500], Loss: 0.002661\n",
      "Epoch [480/1500], Loss: 0.003030\n",
      "Epoch [500/1500], Loss: 0.003096\n",
      "Epoch [520/1500], Loss: 0.002874\n",
      "Epoch [540/1500], Loss: 0.003074\n",
      "Epoch [560/1500], Loss: 0.002894\n",
      "Epoch [580/1500], Loss: 0.002907\n",
      "Epoch [600/1500], Loss: 0.002986\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002535\n",
      "Epoch [640/1500], Loss: 0.002657\n",
      "Epoch [660/1500], Loss: 0.002492\n",
      "Epoch [680/1500], Loss: 0.002703\n",
      "Epoch [700/1500], Loss: 0.002509\n",
      "Epoch [720/1500], Loss: 0.002726\n",
      "Epoch [740/1500], Loss: 0.002547\n",
      "Epoch [760/1500], Loss: 0.002559\n",
      "Epoch [780/1500], Loss: 0.002635\n",
      "Epoch [800/1500], Loss: 0.002438\n",
      "Epoch [820/1500], Loss: 0.002754\n",
      "Epoch [840/1500], Loss: 0.002548\n",
      "Epoch [860/1500], Loss: 0.002629\n",
      "Epoch [880/1500], Loss: 0.002606\n",
      "Epoch [900/1500], Loss: 0.002458\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002500\n",
      "Epoch [940/1500], Loss: 0.002469\n",
      "Epoch [960/1500], Loss: 0.002465\n",
      "Epoch [980/1500], Loss: 0.002466\n",
      "Epoch [1000/1500], Loss: 0.002466\n",
      "Epoch [1020/1500], Loss: 0.002472\n",
      "Epoch [1040/1500], Loss: 0.002479\n",
      "Epoch [1060/1500], Loss: 0.002474\n",
      "Epoch [1080/1500], Loss: 0.002481\n",
      "Epoch [1100/1500], Loss: 0.002478\n",
      "Epoch [1120/1500], Loss: 0.002485\n",
      "Epoch [1140/1500], Loss: 0.002487\n",
      "Epoch [1160/1500], Loss: 0.002485\n",
      "Epoch [1180/1500], Loss: 0.002507\n",
      "Epoch [1200/1500], Loss: 0.002527\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.003201\n",
      "Epoch [1240/1500], Loss: 0.003162\n",
      "Epoch [1260/1500], Loss: 0.003161\n",
      "Epoch [1280/1500], Loss: 0.003160\n",
      "Epoch [1300/1500], Loss: 0.003160\n",
      "Epoch [1320/1500], Loss: 0.003160\n",
      "Epoch [1340/1500], Loss: 0.003160\n",
      "Epoch [1360/1500], Loss: 0.003160\n",
      "Epoch [1380/1500], Loss: 0.003161\n",
      "Epoch [1400/1500], Loss: 0.003161\n",
      "Epoch [1420/1500], Loss: 0.003161\n",
      "Epoch [1440/1500], Loss: 0.003161\n",
      "Epoch [1460/1500], Loss: 0.003161\n",
      "Epoch [1480/1500], Loss: 0.003161\n",
      "Epoch [1500/1500], Loss: 0.003161\n",
      "tensor(0.0513, device='cuda:0')\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.327738 for selected strength\n",
      "We have a total strength of 0.327738 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.051474\n",
      "Epoch [40/1500], Loss: 1.368381\n",
      "Epoch [60/1500], Loss: 0.891774\n",
      "Epoch [80/1500], Loss: 0.552944\n",
      "Epoch [100/1500], Loss: 0.322941\n",
      "Epoch [120/1500], Loss: 0.185356\n",
      "Epoch [140/1500], Loss: 0.105853\n",
      "Epoch [160/1500], Loss: 0.062432\n",
      "Epoch [180/1500], Loss: 0.035884\n",
      "Epoch [200/1500], Loss: 0.020955\n",
      "Epoch [220/1500], Loss: 0.012451\n",
      "Epoch [240/1500], Loss: 0.008314\n",
      "Epoch [260/1500], Loss: 0.006325\n",
      "Epoch [280/1500], Loss: 0.004442\n",
      "Epoch [300/1500], Loss: 0.003839\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003596\n",
      "Epoch [340/1500], Loss: 0.003870\n",
      "Epoch [360/1500], Loss: 0.003695\n",
      "Epoch [380/1500], Loss: 0.003334\n",
      "Epoch [400/1500], Loss: 0.003571\n",
      "Epoch [420/1500], Loss: 0.004132\n",
      "Epoch [440/1500], Loss: 0.003280\n",
      "Epoch [460/1500], Loss: 0.003689\n",
      "Epoch [480/1500], Loss: 0.003688\n",
      "Epoch [500/1500], Loss: 0.003342\n",
      "Epoch [520/1500], Loss: 0.003977\n",
      "Epoch [540/1500], Loss: 0.003346\n",
      "Epoch [560/1500], Loss: 0.003918\n",
      "Epoch [580/1500], Loss: 0.003232\n",
      "Epoch [600/1500], Loss: 0.003775\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.003141\n",
      "Epoch [640/1500], Loss: 0.003264\n",
      "Epoch [660/1500], Loss: 0.003352\n",
      "Epoch [680/1500], Loss: 0.003144\n",
      "Epoch [700/1500], Loss: 0.003137\n",
      "Epoch [720/1500], Loss: 0.003227\n",
      "Epoch [740/1500], Loss: 0.003347\n",
      "Epoch [760/1500], Loss: 0.003129\n",
      "Epoch [780/1500], Loss: 0.003341\n",
      "Epoch [800/1500], Loss: 0.003142\n",
      "Epoch [820/1500], Loss: 0.003119\n",
      "Epoch [840/1500], Loss: 0.003322\n",
      "Epoch [860/1500], Loss: 0.003264\n",
      "Epoch [880/1500], Loss: 0.003177\n",
      "Epoch [900/1500], Loss: 0.003386\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.003183\n",
      "Epoch [940/1500], Loss: 0.003232\n",
      "Epoch [960/1500], Loss: 0.003131\n",
      "Epoch [980/1500], Loss: 0.003138\n",
      "Epoch [1000/1500], Loss: 0.003145\n",
      "Epoch [1020/1500], Loss: 0.003135\n",
      "Epoch [1040/1500], Loss: 0.003152\n",
      "Epoch [1060/1500], Loss: 0.003136\n",
      "Epoch [1080/1500], Loss: 0.003160\n",
      "Epoch [1100/1500], Loss: 0.003135\n",
      "Epoch [1120/1500], Loss: 0.003162\n",
      "Epoch [1140/1500], Loss: 0.003121\n",
      "Epoch [1160/1500], Loss: 0.003188\n",
      "Epoch [1180/1500], Loss: 0.003123\n",
      "Epoch [1200/1500], Loss: 0.003172\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.004259\n",
      "Epoch [1240/1500], Loss: 0.004168\n",
      "Epoch [1260/1500], Loss: 0.004164\n",
      "Epoch [1280/1500], Loss: 0.004163\n",
      "Epoch [1300/1500], Loss: 0.004163\n",
      "Epoch [1320/1500], Loss: 0.004163\n",
      "Epoch [1340/1500], Loss: 0.004163\n",
      "Epoch [1360/1500], Loss: 0.004163\n",
      "Epoch [1380/1500], Loss: 0.004163\n",
      "Epoch [1400/1500], Loss: 0.004163\n",
      "Epoch [1420/1500], Loss: 0.004163\n",
      "Epoch [1440/1500], Loss: 0.004163\n",
      "Epoch [1460/1500], Loss: 0.004163\n",
      "Epoch [1480/1500], Loss: 0.004163\n",
      "Epoch [1500/1500], Loss: 0.004163\n",
      "tensor(0.0409, device='cuda:0')\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.470119 for selected strength\n",
      "We have a total strength of 0.470119 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.071402\n",
      "Epoch [40/1500], Loss: 1.387136\n",
      "Epoch [60/1500], Loss: 0.907509\n",
      "Epoch [80/1500], Loss: 0.567171\n",
      "Epoch [100/1500], Loss: 0.333435\n",
      "Epoch [120/1500], Loss: 0.188820\n",
      "Epoch [140/1500], Loss: 0.103637\n",
      "Epoch [160/1500], Loss: 0.057129\n",
      "Epoch [180/1500], Loss: 0.030629\n",
      "Epoch [200/1500], Loss: 0.016353\n",
      "Epoch [220/1500], Loss: 0.008863\n",
      "Epoch [240/1500], Loss: 0.005479\n",
      "Epoch [260/1500], Loss: 0.004000\n",
      "Epoch [280/1500], Loss: 0.003531\n",
      "Epoch [300/1500], Loss: 0.003495\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003457\n",
      "Epoch [340/1500], Loss: 0.002506\n",
      "Epoch [360/1500], Loss: 0.002551\n",
      "Epoch [380/1500], Loss: 0.002935\n",
      "Epoch [400/1500], Loss: 0.003066\n",
      "Epoch [420/1500], Loss: 0.002514\n",
      "Epoch [440/1500], Loss: 0.003073\n",
      "Epoch [460/1500], Loss: 0.002436\n",
      "Epoch [480/1500], Loss: 0.002688\n",
      "Epoch [500/1500], Loss: 0.003334\n",
      "Epoch [520/1500], Loss: 0.002556\n",
      "Epoch [540/1500], Loss: 0.003352\n",
      "Epoch [560/1500], Loss: 0.002493\n",
      "Epoch [580/1500], Loss: 0.003139\n",
      "Epoch [600/1500], Loss: 0.002435\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002469\n",
      "Epoch [640/1500], Loss: 0.002629\n",
      "Epoch [660/1500], Loss: 0.002294\n",
      "Epoch [680/1500], Loss: 0.002375\n",
      "Epoch [700/1500], Loss: 0.002501\n",
      "Epoch [720/1500], Loss: 0.002333\n",
      "Epoch [740/1500], Loss: 0.002633\n",
      "Epoch [760/1500], Loss: 0.002332\n",
      "Epoch [780/1500], Loss: 0.002549\n",
      "Epoch [800/1500], Loss: 0.002626\n",
      "Epoch [820/1500], Loss: 0.002299\n",
      "Epoch [840/1500], Loss: 0.002602\n",
      "Epoch [860/1500], Loss: 0.002294\n",
      "Epoch [880/1500], Loss: 0.002615\n",
      "Epoch [900/1500], Loss: 0.002282\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002566\n",
      "Epoch [940/1500], Loss: 0.002228\n",
      "Epoch [960/1500], Loss: 0.002479\n",
      "Epoch [980/1500], Loss: 0.002220\n",
      "Epoch [1000/1500], Loss: 0.002355\n",
      "Epoch [1020/1500], Loss: 0.002216\n",
      "Epoch [1040/1500], Loss: 0.002364\n",
      "Epoch [1060/1500], Loss: 0.002215\n",
      "Epoch [1080/1500], Loss: 0.002330\n",
      "Epoch [1100/1500], Loss: 0.002216\n",
      "Epoch [1120/1500], Loss: 0.002359\n",
      "Epoch [1140/1500], Loss: 0.002215\n",
      "Epoch [1160/1500], Loss: 0.002377\n",
      "Epoch [1180/1500], Loss: 0.002217\n",
      "Epoch [1200/1500], Loss: 0.002345\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.003051\n",
      "Epoch [1240/1500], Loss: 0.003002\n",
      "Epoch [1260/1500], Loss: 0.002999\n",
      "Epoch [1280/1500], Loss: 0.002999\n",
      "Epoch [1300/1500], Loss: 0.002999\n",
      "Epoch [1320/1500], Loss: 0.002999\n",
      "Epoch [1340/1500], Loss: 0.002999\n",
      "Epoch [1360/1500], Loss: 0.002999\n",
      "Epoch [1380/1500], Loss: 0.002999\n",
      "Epoch [1400/1500], Loss: 0.002999\n",
      "Epoch [1420/1500], Loss: 0.002999\n",
      "Epoch [1440/1500], Loss: 0.002999\n",
      "Epoch [1460/1500], Loss: 0.002999\n",
      "Epoch [1480/1500], Loss: 0.002999\n",
      "Epoch [1500/1500], Loss: 0.002999\n",
      "tensor(0.0360, device='cuda:0')\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.305077 for selected strength\n",
      "We have a total strength of 0.305077 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.039222\n",
      "Epoch [40/1500], Loss: 1.331880\n",
      "Epoch [60/1500], Loss: 0.816428\n",
      "Epoch [80/1500], Loss: 0.452852\n",
      "Epoch [100/1500], Loss: 0.221388\n",
      "Epoch [120/1500], Loss: 0.097676\n",
      "Epoch [140/1500], Loss: 0.041097\n",
      "Epoch [160/1500], Loss: 0.019524\n",
      "Epoch [180/1500], Loss: 0.009377\n",
      "Epoch [200/1500], Loss: 0.005619\n",
      "Epoch [220/1500], Loss: 0.004393\n",
      "Epoch [240/1500], Loss: 0.003924\n",
      "Epoch [260/1500], Loss: 0.004124\n",
      "Epoch [280/1500], Loss: 0.004884\n",
      "Epoch [300/1500], Loss: 0.003293\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003203\n",
      "Epoch [340/1500], Loss: 0.003283\n",
      "Epoch [360/1500], Loss: 0.003892\n",
      "Epoch [380/1500], Loss: 0.003179\n",
      "Epoch [400/1500], Loss: 0.003239\n",
      "Epoch [420/1500], Loss: 0.003617\n",
      "Epoch [440/1500], Loss: 0.004017\n",
      "Epoch [460/1500], Loss: 0.003184\n",
      "Epoch [480/1500], Loss: 0.003651\n",
      "Epoch [500/1500], Loss: 0.003165\n",
      "Epoch [520/1500], Loss: 0.003296\n",
      "Epoch [540/1500], Loss: 0.004391\n",
      "Epoch [560/1500], Loss: 0.003189\n",
      "Epoch [580/1500], Loss: 0.003779\n",
      "Epoch [600/1500], Loss: 0.003147\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.003133\n",
      "Epoch [640/1500], Loss: 0.003247\n",
      "Epoch [660/1500], Loss: 0.003076\n",
      "Epoch [680/1500], Loss: 0.003369\n",
      "Epoch [700/1500], Loss: 0.003084\n",
      "Epoch [720/1500], Loss: 0.003778\n",
      "Epoch [740/1500], Loss: 0.003056\n",
      "Epoch [760/1500], Loss: 0.003562\n",
      "Epoch [780/1500], Loss: 0.003054\n",
      "Epoch [800/1500], Loss: 0.003364\n",
      "Epoch [820/1500], Loss: 0.003046\n",
      "Epoch [840/1500], Loss: 0.003365\n",
      "Epoch [860/1500], Loss: 0.003047\n",
      "Epoch [880/1500], Loss: 0.003223\n",
      "Epoch [900/1500], Loss: 0.003046\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.003179\n",
      "Epoch [940/1500], Loss: 0.003125\n",
      "Epoch [960/1500], Loss: 0.003123\n",
      "Epoch [980/1500], Loss: 0.003122\n",
      "Epoch [1000/1500], Loss: 0.003122\n",
      "Epoch [1020/1500], Loss: 0.003123\n",
      "Epoch [1040/1500], Loss: 0.003123\n",
      "Epoch [1060/1500], Loss: 0.003124\n",
      "Epoch [1080/1500], Loss: 0.003124\n",
      "Epoch [1100/1500], Loss: 0.003125\n",
      "Epoch [1120/1500], Loss: 0.003125\n",
      "Epoch [1140/1500], Loss: 0.003126\n",
      "Epoch [1160/1500], Loss: 0.003126\n",
      "Epoch [1180/1500], Loss: 0.003127\n",
      "Epoch [1200/1500], Loss: 0.003128\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.003935\n",
      "Epoch [1240/1500], Loss: 0.003886\n",
      "Epoch [1260/1500], Loss: 0.003884\n",
      "Epoch [1280/1500], Loss: 0.003884\n",
      "Epoch [1300/1500], Loss: 0.003884\n",
      "Epoch [1320/1500], Loss: 0.003884\n",
      "Epoch [1340/1500], Loss: 0.003884\n",
      "Epoch [1360/1500], Loss: 0.003884\n",
      "Epoch [1380/1500], Loss: 0.003884\n",
      "Epoch [1400/1500], Loss: 0.003884\n",
      "Epoch [1420/1500], Loss: 0.003884\n",
      "Epoch [1440/1500], Loss: 0.003884\n",
      "Epoch [1460/1500], Loss: 0.003884\n",
      "Epoch [1480/1500], Loss: 0.003884\n",
      "Epoch [1500/1500], Loss: 0.003884\n",
      "tensor(0.0470, device='cuda:0')\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.335053 for selected strength\n",
      "We have a total strength of 0.335053 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.072822\n",
      "Epoch [40/1500], Loss: 1.393003\n",
      "Epoch [60/1500], Loss: 0.917395\n",
      "Epoch [80/1500], Loss: 0.577032\n",
      "Epoch [100/1500], Loss: 0.339612\n",
      "Epoch [120/1500], Loss: 0.189714\n",
      "Epoch [140/1500], Loss: 0.101338\n",
      "Epoch [160/1500], Loss: 0.054423\n",
      "Epoch [180/1500], Loss: 0.028256\n",
      "Epoch [200/1500], Loss: 0.014694\n",
      "Epoch [220/1500], Loss: 0.007976\n",
      "Epoch [240/1500], Loss: 0.004974\n",
      "Epoch [260/1500], Loss: 0.003648\n",
      "Epoch [280/1500], Loss: 0.003351\n",
      "Epoch [300/1500], Loss: 0.003514\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003469\n",
      "Epoch [340/1500], Loss: 0.002822\n",
      "Epoch [360/1500], Loss: 0.002751\n",
      "Epoch [380/1500], Loss: 0.002941\n",
      "Epoch [400/1500], Loss: 0.003606\n",
      "Epoch [420/1500], Loss: 0.002660\n",
      "Epoch [440/1500], Loss: 0.002880\n",
      "Epoch [460/1500], Loss: 0.003263\n",
      "Epoch [480/1500], Loss: 0.002766\n",
      "Epoch [500/1500], Loss: 0.003125\n",
      "Epoch [520/1500], Loss: 0.002953\n",
      "Epoch [540/1500], Loss: 0.002735\n",
      "Epoch [560/1500], Loss: 0.003305\n",
      "Epoch [580/1500], Loss: 0.002753\n",
      "Epoch [600/1500], Loss: 0.002973\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002844\n",
      "Epoch [640/1500], Loss: 0.002565\n",
      "Epoch [660/1500], Loss: 0.002683\n",
      "Epoch [680/1500], Loss: 0.002606\n",
      "Epoch [700/1500], Loss: 0.002683\n",
      "Epoch [720/1500], Loss: 0.002556\n",
      "Epoch [740/1500], Loss: 0.002777\n",
      "Epoch [760/1500], Loss: 0.002538\n",
      "Epoch [780/1500], Loss: 0.002822\n",
      "Epoch [800/1500], Loss: 0.002628\n",
      "Epoch [820/1500], Loss: 0.002676\n",
      "Epoch [840/1500], Loss: 0.002694\n",
      "Epoch [860/1500], Loss: 0.002579\n",
      "Epoch [880/1500], Loss: 0.002728\n",
      "Epoch [900/1500], Loss: 0.002545\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002590\n",
      "Epoch [940/1500], Loss: 0.002550\n",
      "Epoch [960/1500], Loss: 0.002585\n",
      "Epoch [980/1500], Loss: 0.002535\n",
      "Epoch [1000/1500], Loss: 0.002586\n",
      "Epoch [1020/1500], Loss: 0.002551\n",
      "Epoch [1040/1500], Loss: 0.002589\n",
      "Epoch [1060/1500], Loss: 0.002591\n",
      "Epoch [1080/1500], Loss: 0.002559\n",
      "Epoch [1100/1500], Loss: 0.002577\n",
      "Epoch [1120/1500], Loss: 0.002528\n",
      "Epoch [1140/1500], Loss: 0.002623\n",
      "Epoch [1160/1500], Loss: 0.002549\n",
      "Epoch [1180/1500], Loss: 0.002587\n",
      "Epoch [1200/1500], Loss: 0.002605\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.003545\n",
      "Epoch [1240/1500], Loss: 0.003486\n",
      "Epoch [1260/1500], Loss: 0.003484\n",
      "Epoch [1280/1500], Loss: 0.003484\n",
      "Epoch [1300/1500], Loss: 0.003484\n",
      "Epoch [1320/1500], Loss: 0.003484\n",
      "Epoch [1340/1500], Loss: 0.003484\n",
      "Epoch [1360/1500], Loss: 0.003484\n",
      "Epoch [1380/1500], Loss: 0.003484\n",
      "Epoch [1400/1500], Loss: 0.003484\n",
      "Epoch [1420/1500], Loss: 0.003484\n",
      "Epoch [1440/1500], Loss: 0.003484\n",
      "Epoch [1460/1500], Loss: 0.003484\n",
      "Epoch [1480/1500], Loss: 0.003484\n",
      "Epoch [1500/1500], Loss: 0.003484\n",
      "tensor(0.0468, device='cuda:0')\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.332835 for selected strength\n",
      "We have a total strength of 0.332835 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.070862\n",
      "Epoch [40/1500], Loss: 1.340612\n",
      "Epoch [60/1500], Loss: 0.820745\n",
      "Epoch [80/1500], Loss: 0.475167\n",
      "Epoch [100/1500], Loss: 0.249620\n",
      "Epoch [120/1500], Loss: 0.123159\n",
      "Epoch [140/1500], Loss: 0.058864\n",
      "Epoch [160/1500], Loss: 0.027904\n",
      "Epoch [180/1500], Loss: 0.012578\n",
      "Epoch [200/1500], Loss: 0.006534\n",
      "Epoch [220/1500], Loss: 0.004499\n",
      "Epoch [240/1500], Loss: 0.005568\n",
      "Epoch [260/1500], Loss: 0.002548\n",
      "Epoch [280/1500], Loss: 0.003105\n",
      "Epoch [300/1500], Loss: 0.002334\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002530\n",
      "Epoch [340/1500], Loss: 0.002875\n",
      "Epoch [360/1500], Loss: 0.002564\n",
      "Epoch [380/1500], Loss: 0.002598\n",
      "Epoch [400/1500], Loss: 0.002375\n",
      "Epoch [420/1500], Loss: 0.002434\n",
      "Epoch [440/1500], Loss: 0.002718\n",
      "Epoch [460/1500], Loss: 0.002194\n",
      "Epoch [480/1500], Loss: 0.002998\n",
      "Epoch [500/1500], Loss: 0.002301\n",
      "Epoch [520/1500], Loss: 0.004113\n",
      "Epoch [540/1500], Loss: 0.002671\n",
      "Epoch [560/1500], Loss: 0.002227\n",
      "Epoch [580/1500], Loss: 0.003268\n",
      "Epoch [600/1500], Loss: 0.002338\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002091\n",
      "Epoch [640/1500], Loss: 0.002089\n",
      "Epoch [660/1500], Loss: 0.002089\n",
      "Epoch [680/1500], Loss: 0.002090\n",
      "Epoch [700/1500], Loss: 0.002091\n",
      "Epoch [720/1500], Loss: 0.002142\n",
      "Epoch [740/1500], Loss: 0.002094\n",
      "Epoch [760/1500], Loss: 0.002110\n",
      "Epoch [780/1500], Loss: 0.002098\n",
      "Epoch [800/1500], Loss: 0.002118\n",
      "Epoch [820/1500], Loss: 0.002109\n",
      "Epoch [840/1500], Loss: 0.002104\n",
      "Epoch [860/1500], Loss: 0.002102\n",
      "Epoch [880/1500], Loss: 0.002107\n",
      "Epoch [900/1500], Loss: 0.002154\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002100\n",
      "Epoch [940/1500], Loss: 0.002091\n",
      "Epoch [960/1500], Loss: 0.002089\n",
      "Epoch [980/1500], Loss: 0.002089\n",
      "Epoch [1000/1500], Loss: 0.002089\n",
      "Epoch [1020/1500], Loss: 0.002089\n",
      "Epoch [1040/1500], Loss: 0.002089\n",
      "Epoch [1060/1500], Loss: 0.002090\n",
      "Epoch [1080/1500], Loss: 0.002090\n",
      "Epoch [1100/1500], Loss: 0.002090\n",
      "Epoch [1120/1500], Loss: 0.002090\n",
      "Epoch [1140/1500], Loss: 0.002091\n",
      "Epoch [1160/1500], Loss: 0.002091\n",
      "Epoch [1180/1500], Loss: 0.002091\n",
      "Epoch [1200/1500], Loss: 0.002091\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.002246\n",
      "Epoch [1240/1500], Loss: 0.002225\n",
      "Epoch [1260/1500], Loss: 0.002222\n",
      "Epoch [1280/1500], Loss: 0.002221\n",
      "Epoch [1300/1500], Loss: 0.002221\n",
      "Epoch [1320/1500], Loss: 0.002221\n",
      "Epoch [1340/1500], Loss: 0.002221\n",
      "Epoch [1360/1500], Loss: 0.002221\n",
      "Epoch [1380/1500], Loss: 0.002221\n",
      "Epoch [1400/1500], Loss: 0.002221\n",
      "Epoch [1420/1500], Loss: 0.002221\n",
      "Epoch [1440/1500], Loss: 0.002221\n",
      "Epoch [1460/1500], Loss: 0.002221\n",
      "Epoch [1480/1500], Loss: 0.002221\n",
      "Epoch [1500/1500], Loss: 0.002221\n",
      "tensor(0.0527, device='cuda:0')\n",
      "tensor(0.0509, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.133463 for selected strength\n",
      "We have a total strength of 0.133463 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.033812\n",
      "Epoch [40/1500], Loss: 1.331296\n",
      "Epoch [60/1500], Loss: 0.839424\n",
      "Epoch [80/1500], Loss: 0.494442\n",
      "Epoch [100/1500], Loss: 0.266278\n",
      "Epoch [120/1500], Loss: 0.136365\n",
      "Epoch [140/1500], Loss: 0.069618\n",
      "Epoch [160/1500], Loss: 0.035302\n",
      "Epoch [180/1500], Loss: 0.018095\n",
      "Epoch [200/1500], Loss: 0.009736\n",
      "Epoch [220/1500], Loss: 0.005727\n",
      "Epoch [240/1500], Loss: 0.003940\n",
      "Epoch [260/1500], Loss: 0.003271\n",
      "Epoch [280/1500], Loss: 0.003011\n",
      "Epoch [300/1500], Loss: 0.003291\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003298\n",
      "Epoch [340/1500], Loss: 0.002611\n",
      "Epoch [360/1500], Loss: 0.002512\n",
      "Epoch [380/1500], Loss: 0.002637\n",
      "Epoch [400/1500], Loss: 0.002894\n",
      "Epoch [420/1500], Loss: 0.002758\n",
      "Epoch [440/1500], Loss: 0.002495\n",
      "Epoch [460/1500], Loss: 0.002761\n",
      "Epoch [480/1500], Loss: 0.002522\n",
      "Epoch [500/1500], Loss: 0.002535\n",
      "Epoch [520/1500], Loss: 0.002886\n",
      "Epoch [540/1500], Loss: 0.002533\n",
      "Epoch [560/1500], Loss: 0.002589\n",
      "Epoch [580/1500], Loss: 0.003427\n",
      "Epoch [600/1500], Loss: 0.002567\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002400\n",
      "Epoch [640/1500], Loss: 0.002454\n",
      "Epoch [660/1500], Loss: 0.002471\n",
      "Epoch [680/1500], Loss: 0.002427\n",
      "Epoch [700/1500], Loss: 0.002392\n",
      "Epoch [720/1500], Loss: 0.002499\n",
      "Epoch [740/1500], Loss: 0.002526\n",
      "Epoch [760/1500], Loss: 0.002359\n",
      "Epoch [780/1500], Loss: 0.002535\n",
      "Epoch [800/1500], Loss: 0.002379\n",
      "Epoch [820/1500], Loss: 0.002388\n",
      "Epoch [840/1500], Loss: 0.002519\n",
      "Epoch [860/1500], Loss: 0.002347\n",
      "Epoch [880/1500], Loss: 0.002445\n",
      "Epoch [900/1500], Loss: 0.002661\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002417\n",
      "Epoch [940/1500], Loss: 0.002384\n",
      "Epoch [960/1500], Loss: 0.002537\n",
      "Epoch [980/1500], Loss: 0.002415\n",
      "Epoch [1000/1500], Loss: 0.002381\n",
      "Epoch [1020/1500], Loss: 0.002386\n",
      "Epoch [1040/1500], Loss: 0.002493\n",
      "Epoch [1060/1500], Loss: 0.002389\n",
      "Epoch [1080/1500], Loss: 0.002379\n",
      "Epoch [1100/1500], Loss: 0.002437\n",
      "Epoch [1120/1500], Loss: 0.002430\n",
      "Epoch [1140/1500], Loss: 0.002382\n",
      "Epoch [1160/1500], Loss: 0.002396\n",
      "Epoch [1180/1500], Loss: 0.002465\n",
      "Epoch [1200/1500], Loss: 0.002385\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.003118\n",
      "Epoch [1240/1500], Loss: 0.003083\n",
      "Epoch [1260/1500], Loss: 0.003081\n",
      "Epoch [1280/1500], Loss: 0.003081\n",
      "Epoch [1300/1500], Loss: 0.003081\n",
      "Epoch [1320/1500], Loss: 0.003081\n",
      "Epoch [1340/1500], Loss: 0.003081\n",
      "Epoch [1360/1500], Loss: 0.003081\n",
      "Epoch [1380/1500], Loss: 0.003081\n",
      "Epoch [1400/1500], Loss: 0.003081\n",
      "Epoch [1420/1500], Loss: 0.003081\n",
      "Epoch [1440/1500], Loss: 0.003081\n",
      "Epoch [1460/1500], Loss: 0.003081\n",
      "Epoch [1480/1500], Loss: 0.003081\n",
      "Epoch [1500/1500], Loss: 0.003081\n",
      "tensor(0.0313, device='cuda:0')\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.253439 for selected strength\n",
      "We have a total strength of 0.253439 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.059924\n",
      "Epoch [40/1500], Loss: 1.354321\n",
      "Epoch [60/1500], Loss: 0.836444\n",
      "Epoch [80/1500], Loss: 0.466683\n",
      "Epoch [100/1500], Loss: 0.229124\n",
      "Epoch [120/1500], Loss: 0.102026\n",
      "Epoch [140/1500], Loss: 0.044805\n",
      "Epoch [160/1500], Loss: 0.020373\n",
      "Epoch [180/1500], Loss: 0.010466\n",
      "Epoch [200/1500], Loss: 0.006588\n",
      "Epoch [220/1500], Loss: 0.004806\n",
      "Epoch [240/1500], Loss: 0.003080\n",
      "Epoch [260/1500], Loss: 0.002666\n",
      "Epoch [280/1500], Loss: 0.002699\n",
      "Epoch [300/1500], Loss: 0.003078\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002745\n",
      "Epoch [340/1500], Loss: 0.002149\n",
      "Epoch [360/1500], Loss: 0.002204\n",
      "Epoch [380/1500], Loss: 0.002464\n",
      "Epoch [400/1500], Loss: 0.002960\n",
      "Epoch [420/1500], Loss: 0.002164\n",
      "Epoch [440/1500], Loss: 0.002384\n",
      "Epoch [460/1500], Loss: 0.003209\n",
      "Epoch [480/1500], Loss: 0.002180\n",
      "Epoch [500/1500], Loss: 0.002513\n",
      "Epoch [520/1500], Loss: 0.002131\n",
      "Epoch [540/1500], Loss: 0.002215\n",
      "Epoch [560/1500], Loss: 0.002754\n",
      "Epoch [580/1500], Loss: 0.002130\n",
      "Epoch [600/1500], Loss: 0.002476\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002011\n",
      "Epoch [640/1500], Loss: 0.002081\n",
      "Epoch [660/1500], Loss: 0.002014\n",
      "Epoch [680/1500], Loss: 0.002086\n",
      "Epoch [700/1500], Loss: 0.002324\n",
      "Epoch [720/1500], Loss: 0.002002\n",
      "Epoch [740/1500], Loss: 0.002159\n",
      "Epoch [760/1500], Loss: 0.002114\n",
      "Epoch [780/1500], Loss: 0.001998\n",
      "Epoch [800/1500], Loss: 0.002188\n",
      "Epoch [820/1500], Loss: 0.002067\n",
      "Epoch [840/1500], Loss: 0.002009\n",
      "Epoch [860/1500], Loss: 0.002193\n",
      "Epoch [880/1500], Loss: 0.001999\n",
      "Epoch [900/1500], Loss: 0.002070\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002024\n",
      "Epoch [940/1500], Loss: 0.002009\n",
      "Epoch [960/1500], Loss: 0.002008\n",
      "Epoch [980/1500], Loss: 0.002009\n",
      "Epoch [1000/1500], Loss: 0.002009\n",
      "Epoch [1020/1500], Loss: 0.002011\n",
      "Epoch [1040/1500], Loss: 0.002011\n",
      "Epoch [1060/1500], Loss: 0.002011\n",
      "Epoch [1080/1500], Loss: 0.002012\n",
      "Epoch [1100/1500], Loss: 0.002013\n",
      "Epoch [1120/1500], Loss: 0.002015\n",
      "Epoch [1140/1500], Loss: 0.002014\n",
      "Epoch [1160/1500], Loss: 0.002015\n",
      "Epoch [1180/1500], Loss: 0.002016\n",
      "Epoch [1200/1500], Loss: 0.002017\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.002507\n",
      "Epoch [1240/1500], Loss: 0.002491\n",
      "Epoch [1260/1500], Loss: 0.002490\n",
      "Epoch [1280/1500], Loss: 0.002490\n",
      "Epoch [1300/1500], Loss: 0.002490\n",
      "Epoch [1320/1500], Loss: 0.002490\n",
      "Epoch [1340/1500], Loss: 0.002490\n",
      "Epoch [1360/1500], Loss: 0.002490\n",
      "Epoch [1380/1500], Loss: 0.002490\n",
      "Epoch [1400/1500], Loss: 0.002490\n",
      "Epoch [1420/1500], Loss: 0.002490\n",
      "Epoch [1440/1500], Loss: 0.002490\n",
      "Epoch [1460/1500], Loss: 0.002490\n",
      "Epoch [1480/1500], Loss: 0.002490\n",
      "Epoch [1500/1500], Loss: 0.002490\n",
      "tensor(0.0365, device='cuda:0')\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.205881 for selected strength\n",
      "We have a total strength of 0.205881 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.024598\n",
      "Epoch [40/1500], Loss: 1.302544\n",
      "Epoch [60/1500], Loss: 0.807184\n",
      "Epoch [80/1500], Loss: 0.464180\n",
      "Epoch [100/1500], Loss: 0.241169\n",
      "Epoch [120/1500], Loss: 0.118427\n",
      "Epoch [140/1500], Loss: 0.057607\n",
      "Epoch [160/1500], Loss: 0.027769\n",
      "Epoch [180/1500], Loss: 0.013758\n",
      "Epoch [200/1500], Loss: 0.008236\n",
      "Epoch [220/1500], Loss: 0.005790\n",
      "Epoch [240/1500], Loss: 0.004816\n",
      "Epoch [260/1500], Loss: 0.003118\n",
      "Epoch [280/1500], Loss: 0.002522\n",
      "Epoch [300/1500], Loss: 0.002701\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.002849\n",
      "Epoch [340/1500], Loss: 0.003109\n",
      "Epoch [360/1500], Loss: 0.002336\n",
      "Epoch [380/1500], Loss: 0.002350\n",
      "Epoch [400/1500], Loss: 0.002526\n",
      "Epoch [420/1500], Loss: 0.002783\n",
      "Epoch [440/1500], Loss: 0.002569\n",
      "Epoch [460/1500], Loss: 0.002344\n",
      "Epoch [480/1500], Loss: 0.002616\n",
      "Epoch [500/1500], Loss: 0.002377\n",
      "Epoch [520/1500], Loss: 0.002370\n",
      "Epoch [540/1500], Loss: 0.002747\n",
      "Epoch [560/1500], Loss: 0.002402\n",
      "Epoch [580/1500], Loss: 0.002511\n",
      "Epoch [600/1500], Loss: 0.003259\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002333\n",
      "Epoch [640/1500], Loss: 0.002827\n",
      "Epoch [660/1500], Loss: 0.002249\n",
      "Epoch [680/1500], Loss: 0.002460\n",
      "Epoch [700/1500], Loss: 0.002271\n",
      "Epoch [720/1500], Loss: 0.002318\n",
      "Epoch [740/1500], Loss: 0.002768\n",
      "Epoch [760/1500], Loss: 0.002271\n",
      "Epoch [780/1500], Loss: 0.002619\n",
      "Epoch [800/1500], Loss: 0.002262\n",
      "Epoch [820/1500], Loss: 0.002541\n",
      "Epoch [840/1500], Loss: 0.002271\n",
      "Epoch [860/1500], Loss: 0.002586\n",
      "Epoch [880/1500], Loss: 0.002254\n",
      "Epoch [900/1500], Loss: 0.002407\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002310\n",
      "Epoch [940/1500], Loss: 0.002283\n",
      "Epoch [960/1500], Loss: 0.002282\n",
      "Epoch [980/1500], Loss: 0.002282\n",
      "Epoch [1000/1500], Loss: 0.002283\n",
      "Epoch [1020/1500], Loss: 0.002283\n",
      "Epoch [1040/1500], Loss: 0.002284\n",
      "Epoch [1060/1500], Loss: 0.002284\n",
      "Epoch [1080/1500], Loss: 0.002285\n",
      "Epoch [1100/1500], Loss: 0.002285\n",
      "Epoch [1120/1500], Loss: 0.002286\n",
      "Epoch [1140/1500], Loss: 0.002287\n",
      "Epoch [1160/1500], Loss: 0.002287\n",
      "Epoch [1180/1500], Loss: 0.002288\n",
      "Epoch [1200/1500], Loss: 0.002289\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.002832\n",
      "Epoch [1240/1500], Loss: 0.002811\n",
      "Epoch [1260/1500], Loss: 0.002810\n",
      "Epoch [1280/1500], Loss: 0.002810\n",
      "Epoch [1300/1500], Loss: 0.002810\n",
      "Epoch [1320/1500], Loss: 0.002810\n",
      "Epoch [1340/1500], Loss: 0.002810\n",
      "Epoch [1360/1500], Loss: 0.002810\n",
      "Epoch [1380/1500], Loss: 0.002810\n",
      "Epoch [1400/1500], Loss: 0.002810\n",
      "Epoch [1420/1500], Loss: 0.002810\n",
      "Epoch [1440/1500], Loss: 0.002810\n",
      "Epoch [1460/1500], Loss: 0.002810\n",
      "Epoch [1480/1500], Loss: 0.002810\n",
      "Epoch [1500/1500], Loss: 0.002810\n",
      "tensor(0.0328, device='cuda:0')\n",
      "tensor(0.0222, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.225544 for selected strength\n",
      "We have a total strength of 0.225544 for all the columns\n",
      " 75%|█████████████████████████████████           | 3/4 [07:17<02:25, 145.85s/it][3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.074110\n",
      "Epoch [40/1500], Loss: 1.350081\n",
      "Epoch [60/1500], Loss: 0.851639\n",
      "Epoch [80/1500], Loss: 0.511498\n",
      "Epoch [100/1500], Loss: 0.285711\n",
      "Epoch [120/1500], Loss: 0.155033\n",
      "Epoch [140/1500], Loss: 0.082163\n",
      "Epoch [160/1500], Loss: 0.043251\n",
      "Epoch [180/1500], Loss: 0.023033\n",
      "Epoch [200/1500], Loss: 0.013347\n",
      "Epoch [220/1500], Loss: 0.006842\n",
      "Epoch [240/1500], Loss: 0.004640\n",
      "Epoch [260/1500], Loss: 0.004159\n",
      "Epoch [280/1500], Loss: 0.003883\n",
      "Epoch [300/1500], Loss: 0.003252\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003297\n",
      "Epoch [340/1500], Loss: 0.003099\n",
      "Epoch [360/1500], Loss: 0.002969\n",
      "Epoch [380/1500], Loss: 0.003221\n",
      "Epoch [400/1500], Loss: 0.003081\n",
      "Epoch [420/1500], Loss: 0.002978\n",
      "Epoch [440/1500], Loss: 0.003719\n",
      "Epoch [460/1500], Loss: 0.003061\n",
      "Epoch [480/1500], Loss: 0.002997\n",
      "Epoch [500/1500], Loss: 0.003819\n",
      "Epoch [520/1500], Loss: 0.003061\n",
      "Epoch [540/1500], Loss: 0.002983\n",
      "Epoch [560/1500], Loss: 0.003776\n",
      "Epoch [580/1500], Loss: 0.003104\n",
      "Epoch [600/1500], Loss: 0.002982\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002920\n",
      "Epoch [640/1500], Loss: 0.002916\n",
      "Epoch [660/1500], Loss: 0.002917\n",
      "Epoch [680/1500], Loss: 0.002918\n",
      "Epoch [700/1500], Loss: 0.002920\n",
      "Epoch [720/1500], Loss: 0.002922\n",
      "Epoch [740/1500], Loss: 0.002923\n",
      "Epoch [760/1500], Loss: 0.002925\n",
      "Epoch [780/1500], Loss: 0.002926\n",
      "Epoch [800/1500], Loss: 0.002928\n",
      "Epoch [820/1500], Loss: 0.002930\n",
      "Epoch [840/1500], Loss: 0.002931\n",
      "Epoch [860/1500], Loss: 0.002933\n",
      "Epoch [880/1500], Loss: 0.002934\n",
      "Epoch [900/1500], Loss: 0.002936\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002956\n",
      "Epoch [940/1500], Loss: 0.002946\n",
      "Epoch [960/1500], Loss: 0.002946\n",
      "Epoch [980/1500], Loss: 0.002946\n",
      "Epoch [1000/1500], Loss: 0.002946\n",
      "Epoch [1020/1500], Loss: 0.002946\n",
      "Epoch [1040/1500], Loss: 0.002947\n",
      "Epoch [1060/1500], Loss: 0.002947\n",
      "Epoch [1080/1500], Loss: 0.002947\n",
      "Epoch [1100/1500], Loss: 0.002948\n",
      "Epoch [1120/1500], Loss: 0.002948\n",
      "Epoch [1140/1500], Loss: 0.002948\n",
      "Epoch [1160/1500], Loss: 0.002948\n",
      "Epoch [1180/1500], Loss: 0.002949\n",
      "Epoch [1200/1500], Loss: 0.002949\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.003236\n",
      "Epoch [1240/1500], Loss: 0.003220\n",
      "Epoch [1260/1500], Loss: 0.003219\n",
      "Epoch [1280/1500], Loss: 0.003219\n",
      "Epoch [1300/1500], Loss: 0.003219\n",
      "Epoch [1320/1500], Loss: 0.003219\n",
      "Epoch [1340/1500], Loss: 0.003219\n",
      "Epoch [1360/1500], Loss: 0.003219\n",
      "Epoch [1380/1500], Loss: 0.003219\n",
      "Epoch [1400/1500], Loss: 0.003219\n",
      "Epoch [1420/1500], Loss: 0.003219\n",
      "Epoch [1440/1500], Loss: 0.003219\n",
      "Epoch [1460/1500], Loss: 0.003219\n",
      "Epoch [1480/1500], Loss: 0.003219\n",
      "Epoch [1500/1500], Loss: 0.003219\n",
      "tensor(0.0524, device='cuda:0')\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.235677 for selected strength\n",
      "We have a total strength of 0.235677 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.047707\n",
      "Epoch [40/1500], Loss: 1.335405\n",
      "Epoch [60/1500], Loss: 0.858510\n",
      "Epoch [80/1500], Loss: 0.527455\n",
      "Epoch [100/1500], Loss: 0.307665\n",
      "Epoch [120/1500], Loss: 0.178409\n",
      "Epoch [140/1500], Loss: 0.105665\n",
      "Epoch [160/1500], Loss: 0.062305\n",
      "Epoch [180/1500], Loss: 0.037299\n",
      "Epoch [200/1500], Loss: 0.022211\n",
      "Epoch [220/1500], Loss: 0.015011\n",
      "Epoch [240/1500], Loss: 0.008861\n",
      "Epoch [260/1500], Loss: 0.005960\n",
      "Epoch [280/1500], Loss: 0.005077\n",
      "Epoch [300/1500], Loss: 0.005907\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003699\n",
      "Epoch [340/1500], Loss: 0.004113\n",
      "Epoch [360/1500], Loss: 0.003430\n",
      "Epoch [380/1500], Loss: 0.003811\n",
      "Epoch [400/1500], Loss: 0.003370\n",
      "Epoch [420/1500], Loss: 0.003654\n",
      "Epoch [440/1500], Loss: 0.003406\n",
      "Epoch [460/1500], Loss: 0.003690\n",
      "Epoch [480/1500], Loss: 0.003373\n",
      "Epoch [500/1500], Loss: 0.003795\n",
      "Epoch [520/1500], Loss: 0.003428\n",
      "Epoch [540/1500], Loss: 0.004517\n",
      "Epoch [560/1500], Loss: 0.003486\n",
      "Epoch [580/1500], Loss: 0.003959\n",
      "Epoch [600/1500], Loss: 0.003636\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.003323\n",
      "Epoch [640/1500], Loss: 0.003306\n",
      "Epoch [660/1500], Loss: 0.003360\n",
      "Epoch [680/1500], Loss: 0.003269\n",
      "Epoch [700/1500], Loss: 0.003322\n",
      "Epoch [720/1500], Loss: 0.003453\n",
      "Epoch [740/1500], Loss: 0.003256\n",
      "Epoch [760/1500], Loss: 0.003385\n",
      "Epoch [780/1500], Loss: 0.003569\n",
      "Epoch [800/1500], Loss: 0.003253\n",
      "Epoch [820/1500], Loss: 0.003361\n",
      "Epoch [840/1500], Loss: 0.003456\n",
      "Epoch [860/1500], Loss: 0.003246\n",
      "Epoch [880/1500], Loss: 0.003468\n",
      "Epoch [900/1500], Loss: 0.003337\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.003391\n",
      "Epoch [940/1500], Loss: 0.003336\n",
      "Epoch [960/1500], Loss: 0.003329\n",
      "Epoch [980/1500], Loss: 0.003327\n",
      "Epoch [1000/1500], Loss: 0.003326\n",
      "Epoch [1020/1500], Loss: 0.003326\n",
      "Epoch [1040/1500], Loss: 0.003327\n",
      "Epoch [1060/1500], Loss: 0.003327\n",
      "Epoch [1080/1500], Loss: 0.003327\n",
      "Epoch [1100/1500], Loss: 0.003328\n",
      "Epoch [1120/1500], Loss: 0.003328\n",
      "Epoch [1140/1500], Loss: 0.003329\n",
      "Epoch [1160/1500], Loss: 0.003329\n",
      "Epoch [1180/1500], Loss: 0.003330\n",
      "Epoch [1200/1500], Loss: 0.003330\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.004238\n",
      "Epoch [1240/1500], Loss: 0.004168\n",
      "Epoch [1260/1500], Loss: 0.004165\n",
      "Epoch [1280/1500], Loss: 0.004164\n",
      "Epoch [1300/1500], Loss: 0.004164\n",
      "Epoch [1320/1500], Loss: 0.004164\n",
      "Epoch [1340/1500], Loss: 0.004164\n",
      "Epoch [1360/1500], Loss: 0.004164\n",
      "Epoch [1380/1500], Loss: 0.004164\n",
      "Epoch [1400/1500], Loss: 0.004164\n",
      "Epoch [1420/1500], Loss: 0.004164\n",
      "Epoch [1440/1500], Loss: 0.004164\n",
      "Epoch [1460/1500], Loss: 0.004164\n",
      "Epoch [1480/1500], Loss: 0.004164\n",
      "Epoch [1500/1500], Loss: 0.004164\n",
      "tensor(0.0569, device='cuda:0')\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.347727 for selected strength\n",
      "We have a total strength of 0.347727 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.060122\n",
      "Epoch [40/1500], Loss: 1.346696\n",
      "Epoch [60/1500], Loss: 0.865051\n",
      "Epoch [80/1500], Loss: 0.528377\n",
      "Epoch [100/1500], Loss: 0.301572\n",
      "Epoch [120/1500], Loss: 0.167219\n",
      "Epoch [140/1500], Loss: 0.091352\n",
      "Epoch [160/1500], Loss: 0.050499\n",
      "Epoch [180/1500], Loss: 0.028417\n",
      "Epoch [200/1500], Loss: 0.016777\n",
      "Epoch [220/1500], Loss: 0.010877\n",
      "Epoch [240/1500], Loss: 0.008287\n",
      "Epoch [260/1500], Loss: 0.006425\n",
      "Epoch [280/1500], Loss: 0.005537\n",
      "Epoch [300/1500], Loss: 0.006362\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.005588\n",
      "Epoch [340/1500], Loss: 0.004866\n",
      "Epoch [360/1500], Loss: 0.005043\n",
      "Epoch [380/1500], Loss: 0.004927\n",
      "Epoch [400/1500], Loss: 0.004827\n",
      "Epoch [420/1500], Loss: 0.005640\n",
      "Epoch [440/1500], Loss: 0.004813\n",
      "Epoch [460/1500], Loss: 0.004887\n",
      "Epoch [480/1500], Loss: 0.005231\n",
      "Epoch [500/1500], Loss: 0.004804\n",
      "Epoch [520/1500], Loss: 0.004994\n",
      "Epoch [540/1500], Loss: 0.005106\n",
      "Epoch [560/1500], Loss: 0.004808\n",
      "Epoch [580/1500], Loss: 0.005173\n",
      "Epoch [600/1500], Loss: 0.005109\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.004786\n",
      "Epoch [640/1500], Loss: 0.004815\n",
      "Epoch [660/1500], Loss: 0.004806\n",
      "Epoch [680/1500], Loss: 0.004815\n",
      "Epoch [700/1500], Loss: 0.004770\n",
      "Epoch [720/1500], Loss: 0.004795\n",
      "Epoch [740/1500], Loss: 0.004789\n",
      "Epoch [760/1500], Loss: 0.004863\n",
      "Epoch [780/1500], Loss: 0.004772\n",
      "Epoch [800/1500], Loss: 0.004780\n",
      "Epoch [820/1500], Loss: 0.004815\n",
      "Epoch [840/1500], Loss: 0.004902\n",
      "Epoch [860/1500], Loss: 0.004812\n",
      "Epoch [880/1500], Loss: 0.004766\n",
      "Epoch [900/1500], Loss: 0.004813\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.004927\n",
      "Epoch [940/1500], Loss: 0.004862\n",
      "Epoch [960/1500], Loss: 0.004854\n",
      "Epoch [980/1500], Loss: 0.004851\n",
      "Epoch [1000/1500], Loss: 0.004850\n",
      "Epoch [1020/1500], Loss: 0.004850\n",
      "Epoch [1040/1500], Loss: 0.004850\n",
      "Epoch [1060/1500], Loss: 0.004850\n",
      "Epoch [1080/1500], Loss: 0.004850\n",
      "Epoch [1100/1500], Loss: 0.004851\n",
      "Epoch [1120/1500], Loss: 0.004851\n",
      "Epoch [1140/1500], Loss: 0.004851\n",
      "Epoch [1160/1500], Loss: 0.004852\n",
      "Epoch [1180/1500], Loss: 0.004852\n",
      "Epoch [1200/1500], Loss: 0.004852\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.005877\n",
      "Epoch [1240/1500], Loss: 0.005749\n",
      "Epoch [1260/1500], Loss: 0.005742\n",
      "Epoch [1280/1500], Loss: 0.005741\n",
      "Epoch [1300/1500], Loss: 0.005741\n",
      "Epoch [1320/1500], Loss: 0.005741\n",
      "Epoch [1340/1500], Loss: 0.005741\n",
      "Epoch [1360/1500], Loss: 0.005741\n",
      "Epoch [1380/1500], Loss: 0.005741\n",
      "Epoch [1400/1500], Loss: 0.005741\n",
      "Epoch [1420/1500], Loss: 0.005741\n",
      "Epoch [1440/1500], Loss: 0.005741\n",
      "Epoch [1460/1500], Loss: 0.005741\n",
      "Epoch [1480/1500], Loss: 0.005741\n",
      "Epoch [1500/1500], Loss: 0.005741\n",
      "tensor(0.0976, device='cuda:0')\n",
      "tensor(0.0831, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.671326 for selected strength\n",
      "We have a total strength of 0.671326 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.071784\n",
      "Epoch [40/1500], Loss: 1.395827\n",
      "Epoch [60/1500], Loss: 0.920086\n",
      "Epoch [80/1500], Loss: 0.580659\n",
      "Epoch [100/1500], Loss: 0.348195\n",
      "Epoch [120/1500], Loss: 0.205504\n",
      "Epoch [140/1500], Loss: 0.120254\n",
      "Epoch [160/1500], Loss: 0.072711\n",
      "Epoch [180/1500], Loss: 0.043114\n",
      "Epoch [200/1500], Loss: 0.026059\n",
      "Epoch [220/1500], Loss: 0.015909\n",
      "Epoch [240/1500], Loss: 0.010656\n",
      "Epoch [260/1500], Loss: 0.008439\n",
      "Epoch [280/1500], Loss: 0.006416\n",
      "Epoch [300/1500], Loss: 0.004248\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003559\n",
      "Epoch [340/1500], Loss: 0.003772\n",
      "Epoch [360/1500], Loss: 0.003763\n",
      "Epoch [380/1500], Loss: 0.003239\n",
      "Epoch [400/1500], Loss: 0.003825\n",
      "Epoch [420/1500], Loss: 0.003289\n",
      "Epoch [440/1500], Loss: 0.003314\n",
      "Epoch [460/1500], Loss: 0.004801\n",
      "Epoch [480/1500], Loss: 0.003187\n",
      "Epoch [500/1500], Loss: 0.003876\n",
      "Epoch [520/1500], Loss: 0.003174\n",
      "Epoch [540/1500], Loss: 0.003897\n",
      "Epoch [560/1500], Loss: 0.003185\n",
      "Epoch [580/1500], Loss: 0.003915\n",
      "Epoch [600/1500], Loss: 0.003175\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002984\n",
      "Epoch [640/1500], Loss: 0.003005\n",
      "Epoch [660/1500], Loss: 0.003337\n",
      "Epoch [680/1500], Loss: 0.002937\n",
      "Epoch [700/1500], Loss: 0.003121\n",
      "Epoch [720/1500], Loss: 0.003019\n",
      "Epoch [740/1500], Loss: 0.003019\n",
      "Epoch [760/1500], Loss: 0.002916\n",
      "Epoch [780/1500], Loss: 0.003080\n",
      "Epoch [800/1500], Loss: 0.003095\n",
      "Epoch [820/1500], Loss: 0.002984\n",
      "Epoch [840/1500], Loss: 0.003354\n",
      "Epoch [860/1500], Loss: 0.002913\n",
      "Epoch [880/1500], Loss: 0.003326\n",
      "Epoch [900/1500], Loss: 0.002970\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.003017\n",
      "Epoch [940/1500], Loss: 0.002941\n",
      "Epoch [960/1500], Loss: 0.003056\n",
      "Epoch [980/1500], Loss: 0.002948\n",
      "Epoch [1000/1500], Loss: 0.002939\n",
      "Epoch [1020/1500], Loss: 0.003053\n",
      "Epoch [1040/1500], Loss: 0.002931\n",
      "Epoch [1060/1500], Loss: 0.002995\n",
      "Epoch [1080/1500], Loss: 0.002964\n",
      "Epoch [1100/1500], Loss: 0.002928\n",
      "Epoch [1120/1500], Loss: 0.003062\n",
      "Epoch [1140/1500], Loss: 0.002937\n",
      "Epoch [1160/1500], Loss: 0.002972\n",
      "Epoch [1180/1500], Loss: 0.003025\n",
      "Epoch [1200/1500], Loss: 0.002931\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.004303\n",
      "Epoch [1240/1500], Loss: 0.004196\n",
      "Epoch [1260/1500], Loss: 0.004189\n",
      "Epoch [1280/1500], Loss: 0.004187\n",
      "Epoch [1300/1500], Loss: 0.004187\n",
      "Epoch [1320/1500], Loss: 0.004187\n",
      "Epoch [1340/1500], Loss: 0.004187\n",
      "Epoch [1360/1500], Loss: 0.004187\n",
      "Epoch [1380/1500], Loss: 0.004187\n",
      "Epoch [1400/1500], Loss: 0.004187\n",
      "Epoch [1420/1500], Loss: 0.004187\n",
      "Epoch [1440/1500], Loss: 0.004187\n",
      "Epoch [1460/1500], Loss: 0.004187\n",
      "Epoch [1480/1500], Loss: 0.004187\n",
      "Epoch [1500/1500], Loss: 0.004187\n",
      "tensor(0.0778, device='cuda:0')\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.363431 for selected strength\n",
      "We have a total strength of 0.363431 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.033979\n",
      "Epoch [40/1500], Loss: 1.326758\n",
      "Epoch [60/1500], Loss: 0.843764\n",
      "Epoch [80/1500], Loss: 0.504594\n",
      "Epoch [100/1500], Loss: 0.281465\n",
      "Epoch [120/1500], Loss: 0.153219\n",
      "Epoch [140/1500], Loss: 0.084714\n",
      "Epoch [160/1500], Loss: 0.047218\n",
      "Epoch [180/1500], Loss: 0.026643\n",
      "Epoch [200/1500], Loss: 0.015547\n",
      "Epoch [220/1500], Loss: 0.009510\n",
      "Epoch [240/1500], Loss: 0.007312\n",
      "Epoch [260/1500], Loss: 0.004629\n",
      "Epoch [280/1500], Loss: 0.003775\n",
      "Epoch [300/1500], Loss: 0.004098\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003233\n",
      "Epoch [340/1500], Loss: 0.003067\n",
      "Epoch [360/1500], Loss: 0.003617\n",
      "Epoch [380/1500], Loss: 0.002932\n",
      "Epoch [400/1500], Loss: 0.003215\n",
      "Epoch [420/1500], Loss: 0.004165\n",
      "Epoch [440/1500], Loss: 0.003039\n",
      "Epoch [460/1500], Loss: 0.003885\n",
      "Epoch [480/1500], Loss: 0.003130\n",
      "Epoch [500/1500], Loss: 0.004508\n",
      "Epoch [520/1500], Loss: 0.003014\n",
      "Epoch [540/1500], Loss: 0.004301\n",
      "Epoch [560/1500], Loss: 0.003100\n",
      "Epoch [580/1500], Loss: 0.004779\n",
      "Epoch [600/1500], Loss: 0.003135\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.002887\n",
      "Epoch [640/1500], Loss: 0.003110\n",
      "Epoch [660/1500], Loss: 0.002838\n",
      "Epoch [680/1500], Loss: 0.002955\n",
      "Epoch [700/1500], Loss: 0.003061\n",
      "Epoch [720/1500], Loss: 0.002864\n",
      "Epoch [740/1500], Loss: 0.003314\n",
      "Epoch [760/1500], Loss: 0.002829\n",
      "Epoch [780/1500], Loss: 0.003230\n",
      "Epoch [800/1500], Loss: 0.002859\n",
      "Epoch [820/1500], Loss: 0.003187\n",
      "Epoch [840/1500], Loss: 0.002835\n",
      "Epoch [860/1500], Loss: 0.003294\n",
      "Epoch [880/1500], Loss: 0.002839\n",
      "Epoch [900/1500], Loss: 0.003160\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.002925\n",
      "Epoch [940/1500], Loss: 0.002871\n",
      "Epoch [960/1500], Loss: 0.002863\n",
      "Epoch [980/1500], Loss: 0.002862\n",
      "Epoch [1000/1500], Loss: 0.002862\n",
      "Epoch [1020/1500], Loss: 0.002863\n",
      "Epoch [1040/1500], Loss: 0.002868\n",
      "Epoch [1060/1500], Loss: 0.002872\n",
      "Epoch [1080/1500], Loss: 0.002872\n",
      "Epoch [1100/1500], Loss: 0.002871\n",
      "Epoch [1120/1500], Loss: 0.002873\n",
      "Epoch [1140/1500], Loss: 0.002884\n",
      "Epoch [1160/1500], Loss: 0.002892\n",
      "Epoch [1180/1500], Loss: 0.002898\n",
      "Epoch [1200/1500], Loss: 0.002882\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.003779\n",
      "Epoch [1240/1500], Loss: 0.003706\n",
      "Epoch [1260/1500], Loss: 0.003702\n",
      "Epoch [1280/1500], Loss: 0.003701\n",
      "Epoch [1300/1500], Loss: 0.003701\n",
      "Epoch [1320/1500], Loss: 0.003701\n",
      "Epoch [1340/1500], Loss: 0.003701\n",
      "Epoch [1360/1500], Loss: 0.003701\n",
      "Epoch [1380/1500], Loss: 0.003701\n",
      "Epoch [1400/1500], Loss: 0.003701\n",
      "Epoch [1420/1500], Loss: 0.003701\n",
      "Epoch [1440/1500], Loss: 0.003701\n",
      "Epoch [1460/1500], Loss: 0.003701\n",
      "Epoch [1480/1500], Loss: 0.003701\n",
      "Epoch [1500/1500], Loss: 0.003701\n",
      "tensor(0.0602, device='cuda:0')\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.330081 for selected strength\n",
      "We have a total strength of 0.330081 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.057117\n",
      "Epoch [40/1500], Loss: 1.349065\n",
      "Epoch [60/1500], Loss: 0.875830\n",
      "Epoch [80/1500], Loss: 0.546234\n",
      "Epoch [100/1500], Loss: 0.324010\n",
      "Epoch [120/1500], Loss: 0.189907\n",
      "Epoch [140/1500], Loss: 0.111351\n",
      "Epoch [160/1500], Loss: 0.064849\n",
      "Epoch [180/1500], Loss: 0.037536\n",
      "Epoch [200/1500], Loss: 0.022227\n",
      "Epoch [220/1500], Loss: 0.014302\n",
      "Epoch [240/1500], Loss: 0.009581\n",
      "Epoch [260/1500], Loss: 0.006127\n",
      "Epoch [280/1500], Loss: 0.005052\n",
      "Epoch [300/1500], Loss: 0.004922\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.004555\n",
      "Epoch [340/1500], Loss: 0.004168\n",
      "Epoch [360/1500], Loss: 0.004764\n",
      "Epoch [380/1500], Loss: 0.004104\n",
      "Epoch [400/1500], Loss: 0.004802\n",
      "Epoch [420/1500], Loss: 0.004169\n",
      "Epoch [440/1500], Loss: 0.004192\n",
      "Epoch [460/1500], Loss: 0.004432\n",
      "Epoch [480/1500], Loss: 0.004089\n",
      "Epoch [500/1500], Loss: 0.004945\n",
      "Epoch [520/1500], Loss: 0.004204\n",
      "Epoch [540/1500], Loss: 0.004108\n",
      "Epoch [560/1500], Loss: 0.004785\n",
      "Epoch [580/1500], Loss: 0.004134\n",
      "Epoch [600/1500], Loss: 0.004182\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.004058\n",
      "Epoch [640/1500], Loss: 0.004037\n",
      "Epoch [660/1500], Loss: 0.004038\n",
      "Epoch [680/1500], Loss: 0.004041\n",
      "Epoch [700/1500], Loss: 0.004051\n",
      "Epoch [720/1500], Loss: 0.004062\n",
      "Epoch [740/1500], Loss: 0.004089\n",
      "Epoch [760/1500], Loss: 0.004256\n",
      "Epoch [780/1500], Loss: 0.004290\n",
      "Epoch [800/1500], Loss: 0.004102\n",
      "Epoch [820/1500], Loss: 0.004050\n",
      "Epoch [840/1500], Loss: 0.004053\n",
      "Epoch [860/1500], Loss: 0.004111\n",
      "Epoch [880/1500], Loss: 0.004291\n",
      "Epoch [900/1500], Loss: 0.004226\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.004174\n",
      "Epoch [940/1500], Loss: 0.004118\n",
      "Epoch [960/1500], Loss: 0.004112\n",
      "Epoch [980/1500], Loss: 0.004110\n",
      "Epoch [1000/1500], Loss: 0.004110\n",
      "Epoch [1020/1500], Loss: 0.004110\n",
      "Epoch [1040/1500], Loss: 0.004110\n",
      "Epoch [1060/1500], Loss: 0.004110\n",
      "Epoch [1080/1500], Loss: 0.004110\n",
      "Epoch [1100/1500], Loss: 0.004111\n",
      "Epoch [1120/1500], Loss: 0.004111\n",
      "Epoch [1140/1500], Loss: 0.004111\n",
      "Epoch [1160/1500], Loss: 0.004111\n",
      "Epoch [1180/1500], Loss: 0.004112\n",
      "Epoch [1200/1500], Loss: 0.004112\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.005012\n",
      "Epoch [1240/1500], Loss: 0.004920\n",
      "Epoch [1260/1500], Loss: 0.004914\n",
      "Epoch [1280/1500], Loss: 0.004913\n",
      "Epoch [1300/1500], Loss: 0.004913\n",
      "Epoch [1320/1500], Loss: 0.004913\n",
      "Epoch [1340/1500], Loss: 0.004913\n",
      "Epoch [1360/1500], Loss: 0.004913\n",
      "Epoch [1380/1500], Loss: 0.004913\n",
      "Epoch [1400/1500], Loss: 0.004913\n",
      "Epoch [1420/1500], Loss: 0.004913\n",
      "Epoch [1440/1500], Loss: 0.004913\n",
      "Epoch [1460/1500], Loss: 0.004913\n",
      "Epoch [1480/1500], Loss: 0.004913\n",
      "Epoch [1500/1500], Loss: 0.004913\n",
      "tensor(0.2305, device='cuda:0')\n",
      "tensor(0.1097, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.448475 for selected strength\n",
      "We have a total strength of 0.448475 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.042441\n",
      "Epoch [40/1500], Loss: 1.331495\n",
      "Epoch [60/1500], Loss: 0.846293\n",
      "Epoch [80/1500], Loss: 0.509128\n",
      "Epoch [100/1500], Loss: 0.285392\n",
      "Epoch [120/1500], Loss: 0.156824\n",
      "Epoch [140/1500], Loss: 0.085669\n",
      "Epoch [160/1500], Loss: 0.047069\n",
      "Epoch [180/1500], Loss: 0.026117\n",
      "Epoch [200/1500], Loss: 0.015034\n",
      "Epoch [220/1500], Loss: 0.009374\n",
      "Epoch [240/1500], Loss: 0.006605\n",
      "Epoch [260/1500], Loss: 0.007030\n",
      "Epoch [280/1500], Loss: 0.003985\n",
      "Epoch [300/1500], Loss: 0.003974\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.004327\n",
      "Epoch [340/1500], Loss: 0.003394\n",
      "Epoch [360/1500], Loss: 0.003849\n",
      "Epoch [380/1500], Loss: 0.003401\n",
      "Epoch [400/1500], Loss: 0.003418\n",
      "Epoch [420/1500], Loss: 0.004136\n",
      "Epoch [440/1500], Loss: 0.003301\n",
      "Epoch [460/1500], Loss: 0.003942\n",
      "Epoch [480/1500], Loss: 0.003289\n",
      "Epoch [500/1500], Loss: 0.003729\n",
      "Epoch [520/1500], Loss: 0.003297\n",
      "Epoch [540/1500], Loss: 0.003958\n",
      "Epoch [560/1500], Loss: 0.003289\n",
      "Epoch [580/1500], Loss: 0.003769\n",
      "Epoch [600/1500], Loss: 0.003402\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.003408\n",
      "Epoch [640/1500], Loss: 0.003228\n",
      "Epoch [660/1500], Loss: 0.003301\n",
      "Epoch [680/1500], Loss: 0.003284\n",
      "Epoch [700/1500], Loss: 0.003287\n",
      "Epoch [720/1500], Loss: 0.003247\n",
      "Epoch [740/1500], Loss: 0.003360\n",
      "Epoch [760/1500], Loss: 0.003210\n",
      "Epoch [780/1500], Loss: 0.003360\n",
      "Epoch [800/1500], Loss: 0.003196\n",
      "Epoch [820/1500], Loss: 0.003591\n",
      "Epoch [840/1500], Loss: 0.003214\n",
      "Epoch [860/1500], Loss: 0.003729\n",
      "Epoch [880/1500], Loss: 0.003213\n",
      "Epoch [900/1500], Loss: 0.003738\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.003333\n",
      "Epoch [940/1500], Loss: 0.003266\n",
      "Epoch [960/1500], Loss: 0.003257\n",
      "Epoch [980/1500], Loss: 0.003254\n",
      "Epoch [1000/1500], Loss: 0.003258\n",
      "Epoch [1020/1500], Loss: 0.003257\n",
      "Epoch [1040/1500], Loss: 0.003256\n",
      "Epoch [1060/1500], Loss: 0.003298\n",
      "Epoch [1080/1500], Loss: 0.003263\n",
      "Epoch [1100/1500], Loss: 0.003260\n",
      "Epoch [1120/1500], Loss: 0.003257\n",
      "Epoch [1140/1500], Loss: 0.003257\n",
      "Epoch [1160/1500], Loss: 0.003364\n",
      "Epoch [1180/1500], Loss: 0.003270\n",
      "Epoch [1200/1500], Loss: 0.003265\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.004212\n",
      "Epoch [1240/1500], Loss: 0.004117\n",
      "Epoch [1260/1500], Loss: 0.004111\n",
      "Epoch [1280/1500], Loss: 0.004110\n",
      "Epoch [1300/1500], Loss: 0.004110\n",
      "Epoch [1320/1500], Loss: 0.004110\n",
      "Epoch [1340/1500], Loss: 0.004110\n",
      "Epoch [1360/1500], Loss: 0.004110\n",
      "Epoch [1380/1500], Loss: 0.004110\n",
      "Epoch [1400/1500], Loss: 0.004110\n",
      "Epoch [1420/1500], Loss: 0.004110\n",
      "Epoch [1440/1500], Loss: 0.004110\n",
      "Epoch [1460/1500], Loss: 0.004110\n",
      "Epoch [1480/1500], Loss: 0.004110\n",
      "Epoch [1500/1500], Loss: 0.004110\n",
      "tensor(0.0583, device='cuda:0')\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.377628 for selected strength\n",
      "We have a total strength of 0.377628 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.032794\n",
      "Epoch [40/1500], Loss: 1.288152\n",
      "Epoch [60/1500], Loss: 0.788685\n",
      "Epoch [80/1500], Loss: 0.449806\n",
      "Epoch [100/1500], Loss: 0.235856\n",
      "Epoch [120/1500], Loss: 0.122974\n",
      "Epoch [140/1500], Loss: 0.065582\n",
      "Epoch [160/1500], Loss: 0.036632\n",
      "Epoch [180/1500], Loss: 0.022053\n",
      "Epoch [200/1500], Loss: 0.015007\n",
      "Epoch [220/1500], Loss: 0.011672\n",
      "Epoch [240/1500], Loss: 0.010122\n",
      "Epoch [260/1500], Loss: 0.009408\n",
      "Epoch [280/1500], Loss: 0.009077\n",
      "Epoch [300/1500], Loss: 0.008918\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.008824\n",
      "Epoch [340/1500], Loss: 0.008773\n",
      "Epoch [360/1500], Loss: 0.008749\n",
      "Epoch [380/1500], Loss: 0.008736\n",
      "Epoch [400/1500], Loss: 0.008728\n",
      "Epoch [420/1500], Loss: 0.008723\n",
      "Epoch [440/1500], Loss: 0.008721\n",
      "Epoch [460/1500], Loss: 0.008720\n",
      "Epoch [480/1500], Loss: 0.008720\n",
      "Epoch [500/1500], Loss: 0.008721\n",
      "Epoch [520/1500], Loss: 0.008722\n",
      "Epoch [540/1500], Loss: 0.008723\n",
      "Epoch [560/1500], Loss: 0.008725\n",
      "Epoch [580/1500], Loss: 0.008727\n",
      "Epoch [600/1500], Loss: 0.008729\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.008774\n",
      "Epoch [640/1500], Loss: 0.008733\n",
      "Epoch [660/1500], Loss: 0.008728\n",
      "Epoch [680/1500], Loss: 0.008727\n",
      "Epoch [700/1500], Loss: 0.008727\n",
      "Epoch [720/1500], Loss: 0.008727\n",
      "Epoch [740/1500], Loss: 0.008727\n",
      "Epoch [760/1500], Loss: 0.008728\n",
      "Epoch [780/1500], Loss: 0.008728\n",
      "Epoch [800/1500], Loss: 0.008729\n",
      "Epoch [820/1500], Loss: 0.008729\n",
      "Epoch [840/1500], Loss: 0.008730\n",
      "Epoch [860/1500], Loss: 0.008730\n",
      "Epoch [880/1500], Loss: 0.008731\n",
      "Epoch [900/1500], Loss: 0.008731\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.009007\n",
      "Epoch [940/1500], Loss: 0.008891\n",
      "Epoch [960/1500], Loss: 0.008879\n",
      "Epoch [980/1500], Loss: 0.008876\n",
      "Epoch [1000/1500], Loss: 0.008875\n",
      "Epoch [1020/1500], Loss: 0.008874\n",
      "Epoch [1040/1500], Loss: 0.008874\n",
      "Epoch [1060/1500], Loss: 0.008874\n",
      "Epoch [1080/1500], Loss: 0.008874\n",
      "Epoch [1100/1500], Loss: 0.008874\n",
      "Epoch [1120/1500], Loss: 0.008874\n",
      "Epoch [1140/1500], Loss: 0.008874\n",
      "Epoch [1160/1500], Loss: 0.008874\n",
      "Epoch [1180/1500], Loss: 0.008874\n",
      "Epoch [1200/1500], Loss: 0.008874\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.010363\n",
      "Epoch [1240/1500], Loss: 0.010157\n",
      "Epoch [1260/1500], Loss: 0.010145\n",
      "Epoch [1280/1500], Loss: 0.010144\n",
      "Epoch [1300/1500], Loss: 0.010143\n",
      "Epoch [1320/1500], Loss: 0.010143\n",
      "Epoch [1340/1500], Loss: 0.010143\n",
      "Epoch [1360/1500], Loss: 0.010143\n",
      "Epoch [1380/1500], Loss: 0.010143\n",
      "Epoch [1400/1500], Loss: 0.010143\n",
      "Epoch [1420/1500], Loss: 0.010143\n",
      "Epoch [1440/1500], Loss: 0.010143\n",
      "Epoch [1460/1500], Loss: 0.010143\n",
      "Epoch [1480/1500], Loss: 0.010143\n",
      "Epoch [1500/1500], Loss: 0.010143\n",
      "tensor(0.0858, device='cuda:0')\n",
      "tensor(0.0532, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.853638 for selected strength\n",
      "We have a total strength of 0.853638 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.053716\n",
      "Epoch [40/1500], Loss: 1.347757\n",
      "Epoch [60/1500], Loss: 0.865881\n",
      "Epoch [80/1500], Loss: 0.531590\n",
      "Epoch [100/1500], Loss: 0.308025\n",
      "Epoch [120/1500], Loss: 0.175726\n",
      "Epoch [140/1500], Loss: 0.100717\n",
      "Epoch [160/1500], Loss: 0.057756\n",
      "Epoch [180/1500], Loss: 0.033333\n",
      "Epoch [200/1500], Loss: 0.019583\n",
      "Epoch [220/1500], Loss: 0.012058\n",
      "Epoch [240/1500], Loss: 0.008529\n",
      "Epoch [260/1500], Loss: 0.007784\n",
      "Epoch [280/1500], Loss: 0.004830\n",
      "Epoch [300/1500], Loss: 0.004726\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.005137\n",
      "Epoch [340/1500], Loss: 0.004009\n",
      "Epoch [360/1500], Loss: 0.004423\n",
      "Epoch [380/1500], Loss: 0.003963\n",
      "Epoch [400/1500], Loss: 0.004263\n",
      "Epoch [420/1500], Loss: 0.004023\n",
      "Epoch [440/1500], Loss: 0.004208\n",
      "Epoch [460/1500], Loss: 0.003928\n",
      "Epoch [480/1500], Loss: 0.004465\n",
      "Epoch [500/1500], Loss: 0.003911\n",
      "Epoch [520/1500], Loss: 0.004905\n",
      "Epoch [540/1500], Loss: 0.003956\n",
      "Epoch [560/1500], Loss: 0.004641\n",
      "Epoch [580/1500], Loss: 0.004067\n",
      "Epoch [600/1500], Loss: 0.003969\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.004427\n",
      "Epoch [640/1500], Loss: 0.003928\n",
      "Epoch [660/1500], Loss: 0.003855\n",
      "Epoch [680/1500], Loss: 0.004543\n",
      "Epoch [700/1500], Loss: 0.003892\n",
      "Epoch [720/1500], Loss: 0.003856\n",
      "Epoch [740/1500], Loss: 0.004511\n",
      "Epoch [760/1500], Loss: 0.003876\n",
      "Epoch [780/1500], Loss: 0.003874\n",
      "Epoch [800/1500], Loss: 0.004221\n",
      "Epoch [820/1500], Loss: 0.003887\n",
      "Epoch [840/1500], Loss: 0.003864\n",
      "Epoch [860/1500], Loss: 0.004357\n",
      "Epoch [880/1500], Loss: 0.003917\n",
      "Epoch [900/1500], Loss: 0.003860\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.004066\n",
      "Epoch [940/1500], Loss: 0.003971\n",
      "Epoch [960/1500], Loss: 0.003958\n",
      "Epoch [980/1500], Loss: 0.003955\n",
      "Epoch [1000/1500], Loss: 0.003954\n",
      "Epoch [1020/1500], Loss: 0.003953\n",
      "Epoch [1040/1500], Loss: 0.003954\n",
      "Epoch [1060/1500], Loss: 0.003954\n",
      "Epoch [1080/1500], Loss: 0.003955\n",
      "Epoch [1100/1500], Loss: 0.003955\n",
      "Epoch [1120/1500], Loss: 0.003956\n",
      "Epoch [1140/1500], Loss: 0.003957\n",
      "Epoch [1160/1500], Loss: 0.003958\n",
      "Epoch [1180/1500], Loss: 0.003959\n",
      "Epoch [1200/1500], Loss: 0.003959\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.005193\n",
      "Epoch [1240/1500], Loss: 0.005058\n",
      "Epoch [1260/1500], Loss: 0.005051\n",
      "Epoch [1280/1500], Loss: 0.005050\n",
      "Epoch [1300/1500], Loss: 0.005050\n",
      "Epoch [1320/1500], Loss: 0.005050\n",
      "Epoch [1340/1500], Loss: 0.005050\n",
      "Epoch [1360/1500], Loss: 0.005050\n",
      "Epoch [1380/1500], Loss: 0.005050\n",
      "Epoch [1400/1500], Loss: 0.005050\n",
      "Epoch [1420/1500], Loss: 0.005050\n",
      "Epoch [1440/1500], Loss: 0.005050\n",
      "Epoch [1460/1500], Loss: 0.005050\n",
      "Epoch [1480/1500], Loss: 0.005050\n",
      "Epoch [1500/1500], Loss: 0.005050\n",
      "tensor(0.0435, device='cuda:0')\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.455564 for selected strength\n",
      "We have a total strength of 0.455564 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.090000\n",
      "Epoch [40/1500], Loss: 1.400386\n",
      "Epoch [60/1500], Loss: 0.926195\n",
      "Epoch [80/1500], Loss: 0.591448\n",
      "Epoch [100/1500], Loss: 0.359451\n",
      "Epoch [120/1500], Loss: 0.211990\n",
      "Epoch [140/1500], Loss: 0.121620\n",
      "Epoch [160/1500], Loss: 0.069689\n",
      "Epoch [180/1500], Loss: 0.040807\n",
      "Epoch [200/1500], Loss: 0.023587\n",
      "Epoch [220/1500], Loss: 0.013927\n",
      "Epoch [240/1500], Loss: 0.008790\n",
      "Epoch [260/1500], Loss: 0.006289\n",
      "Epoch [280/1500], Loss: 0.005332\n",
      "Epoch [300/1500], Loss: 0.005525\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.004182\n",
      "Epoch [340/1500], Loss: 0.004520\n",
      "Epoch [360/1500], Loss: 0.004021\n",
      "Epoch [380/1500], Loss: 0.004438\n",
      "Epoch [400/1500], Loss: 0.004008\n",
      "Epoch [420/1500], Loss: 0.004356\n",
      "Epoch [440/1500], Loss: 0.004047\n",
      "Epoch [460/1500], Loss: 0.004493\n",
      "Epoch [480/1500], Loss: 0.003980\n",
      "Epoch [500/1500], Loss: 0.004780\n",
      "Epoch [520/1500], Loss: 0.004072\n",
      "Epoch [540/1500], Loss: 0.005105\n",
      "Epoch [560/1500], Loss: 0.004164\n",
      "Epoch [580/1500], Loss: 0.004084\n",
      "Epoch [600/1500], Loss: 0.004409\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.004002\n",
      "Epoch [640/1500], Loss: 0.004046\n",
      "Epoch [660/1500], Loss: 0.003911\n",
      "Epoch [680/1500], Loss: 0.004019\n",
      "Epoch [700/1500], Loss: 0.004113\n",
      "Epoch [720/1500], Loss: 0.003899\n",
      "Epoch [740/1500], Loss: 0.004000\n",
      "Epoch [760/1500], Loss: 0.004222\n",
      "Epoch [780/1500], Loss: 0.003932\n",
      "Epoch [800/1500], Loss: 0.003947\n",
      "Epoch [820/1500], Loss: 0.004035\n",
      "Epoch [840/1500], Loss: 0.003948\n",
      "Epoch [860/1500], Loss: 0.003901\n",
      "Epoch [880/1500], Loss: 0.004042\n",
      "Epoch [900/1500], Loss: 0.004170\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.004116\n",
      "Epoch [940/1500], Loss: 0.004027\n",
      "Epoch [960/1500], Loss: 0.004015\n",
      "Epoch [980/1500], Loss: 0.004012\n",
      "Epoch [1000/1500], Loss: 0.004011\n",
      "Epoch [1020/1500], Loss: 0.004011\n",
      "Epoch [1040/1500], Loss: 0.004010\n",
      "Epoch [1060/1500], Loss: 0.004011\n",
      "Epoch [1080/1500], Loss: 0.004011\n",
      "Epoch [1100/1500], Loss: 0.004011\n",
      "Epoch [1120/1500], Loss: 0.004011\n",
      "Epoch [1140/1500], Loss: 0.004011\n",
      "Epoch [1160/1500], Loss: 0.004012\n",
      "Epoch [1180/1500], Loss: 0.004012\n",
      "Epoch [1200/1500], Loss: 0.004013\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.005391\n",
      "Epoch [1240/1500], Loss: 0.005265\n",
      "Epoch [1260/1500], Loss: 0.005258\n",
      "Epoch [1280/1500], Loss: 0.005257\n",
      "Epoch [1300/1500], Loss: 0.005257\n",
      "Epoch [1320/1500], Loss: 0.005257\n",
      "Epoch [1340/1500], Loss: 0.005257\n",
      "Epoch [1360/1500], Loss: 0.005257\n",
      "Epoch [1380/1500], Loss: 0.005257\n",
      "Epoch [1400/1500], Loss: 0.005257\n",
      "Epoch [1420/1500], Loss: 0.005257\n",
      "Epoch [1440/1500], Loss: 0.005257\n",
      "Epoch [1460/1500], Loss: 0.005257\n",
      "Epoch [1480/1500], Loss: 0.005257\n",
      "Epoch [1500/1500], Loss: 0.005257\n",
      "tensor(0.1135, device='cuda:0')\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.469591 for selected strength\n",
      "We have a total strength of 0.469591 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.048932\n",
      "Epoch [40/1500], Loss: 1.341242\n",
      "Epoch [60/1500], Loss: 0.852872\n",
      "Epoch [80/1500], Loss: 0.510900\n",
      "Epoch [100/1500], Loss: 0.283768\n",
      "Epoch [120/1500], Loss: 0.154300\n",
      "Epoch [140/1500], Loss: 0.083258\n",
      "Epoch [160/1500], Loss: 0.045852\n",
      "Epoch [180/1500], Loss: 0.025837\n",
      "Epoch [200/1500], Loss: 0.014977\n",
      "Epoch [220/1500], Loss: 0.009229\n",
      "Epoch [240/1500], Loss: 0.006366\n",
      "Epoch [260/1500], Loss: 0.005081\n",
      "Epoch [280/1500], Loss: 0.004838\n",
      "Epoch [300/1500], Loss: 0.004168\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.003495\n",
      "Epoch [340/1500], Loss: 0.003843\n",
      "Epoch [360/1500], Loss: 0.003392\n",
      "Epoch [380/1500], Loss: 0.003450\n",
      "Epoch [400/1500], Loss: 0.004737\n",
      "Epoch [420/1500], Loss: 0.003318\n",
      "Epoch [440/1500], Loss: 0.004360\n",
      "Epoch [460/1500], Loss: 0.003358\n",
      "Epoch [480/1500], Loss: 0.004104\n",
      "Epoch [500/1500], Loss: 0.003312\n",
      "Epoch [520/1500], Loss: 0.004055\n",
      "Epoch [540/1500], Loss: 0.003304\n",
      "Epoch [560/1500], Loss: 0.004657\n",
      "Epoch [580/1500], Loss: 0.003421\n",
      "Epoch [600/1500], Loss: 0.004793\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.003611\n",
      "Epoch [640/1500], Loss: 0.003157\n",
      "Epoch [660/1500], Loss: 0.003464\n",
      "Epoch [680/1500], Loss: 0.003204\n",
      "Epoch [700/1500], Loss: 0.003178\n",
      "Epoch [720/1500], Loss: 0.003372\n",
      "Epoch [740/1500], Loss: 0.003142\n",
      "Epoch [760/1500], Loss: 0.003622\n",
      "Epoch [780/1500], Loss: 0.003153\n",
      "Epoch [800/1500], Loss: 0.003724\n",
      "Epoch [820/1500], Loss: 0.003228\n",
      "Epoch [840/1500], Loss: 0.003158\n",
      "Epoch [860/1500], Loss: 0.003341\n",
      "Epoch [880/1500], Loss: 0.003192\n",
      "Epoch [900/1500], Loss: 0.003185\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.003327\n",
      "Epoch [940/1500], Loss: 0.003239\n",
      "Epoch [960/1500], Loss: 0.003225\n",
      "Epoch [980/1500], Loss: 0.003221\n",
      "Epoch [1000/1500], Loss: 0.003220\n",
      "Epoch [1020/1500], Loss: 0.003220\n",
      "Epoch [1040/1500], Loss: 0.003220\n",
      "Epoch [1060/1500], Loss: 0.003220\n",
      "Epoch [1080/1500], Loss: 0.003220\n",
      "Epoch [1100/1500], Loss: 0.003221\n",
      "Epoch [1120/1500], Loss: 0.003221\n",
      "Epoch [1140/1500], Loss: 0.003223\n",
      "Epoch [1160/1500], Loss: 0.003223\n",
      "Epoch [1180/1500], Loss: 0.003227\n",
      "Epoch [1200/1500], Loss: 0.003225\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.004363\n",
      "Epoch [1240/1500], Loss: 0.004221\n",
      "Epoch [1260/1500], Loss: 0.004206\n",
      "Epoch [1280/1500], Loss: 0.004203\n",
      "Epoch [1300/1500], Loss: 0.004203\n",
      "Epoch [1320/1500], Loss: 0.004203\n",
      "Epoch [1340/1500], Loss: 0.004203\n",
      "Epoch [1360/1500], Loss: 0.004203\n",
      "Epoch [1380/1500], Loss: 0.004203\n",
      "Epoch [1400/1500], Loss: 0.004203\n",
      "Epoch [1420/1500], Loss: 0.004203\n",
      "Epoch [1440/1500], Loss: 0.004203\n",
      "Epoch [1460/1500], Loss: 0.004203\n",
      "Epoch [1480/1500], Loss: 0.004203\n",
      "Epoch [1500/1500], Loss: 0.004203\n",
      "tensor(0.0765, device='cuda:0')\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.352338 for selected strength\n",
      "We have a total strength of 0.352338 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 2.052974\n",
      "Epoch [40/1500], Loss: 1.350653\n",
      "Epoch [60/1500], Loss: 0.864452\n",
      "Epoch [80/1500], Loss: 0.526237\n",
      "Epoch [100/1500], Loss: 0.301781\n",
      "Epoch [120/1500], Loss: 0.171662\n",
      "Epoch [140/1500], Loss: 0.098271\n",
      "Epoch [160/1500], Loss: 0.057793\n",
      "Epoch [180/1500], Loss: 0.034939\n",
      "Epoch [200/1500], Loss: 0.021550\n",
      "Epoch [220/1500], Loss: 0.013248\n",
      "Epoch [240/1500], Loss: 0.009119\n",
      "Epoch [260/1500], Loss: 0.007029\n",
      "Epoch [280/1500], Loss: 0.006189\n",
      "Epoch [300/1500], Loss: 0.006031\n",
      "Usng step side 2368\n",
      "Epoch [320/1500], Loss: 0.004820\n",
      "Epoch [340/1500], Loss: 0.005315\n",
      "Epoch [360/1500], Loss: 0.004567\n",
      "Epoch [380/1500], Loss: 0.004760\n",
      "Epoch [400/1500], Loss: 0.005159\n",
      "Epoch [420/1500], Loss: 0.004624\n",
      "Epoch [440/1500], Loss: 0.005535\n",
      "Epoch [460/1500], Loss: 0.004542\n",
      "Epoch [480/1500], Loss: 0.005161\n",
      "Epoch [500/1500], Loss: 0.004532\n",
      "Epoch [520/1500], Loss: 0.005277\n",
      "Epoch [540/1500], Loss: 0.004499\n",
      "Epoch [560/1500], Loss: 0.005104\n",
      "Epoch [580/1500], Loss: 0.004537\n",
      "Epoch [600/1500], Loss: 0.005443\n",
      "Usng step side 1612\n",
      "Epoch [620/1500], Loss: 0.004718\n",
      "Epoch [640/1500], Loss: 0.004507\n",
      "Epoch [660/1500], Loss: 0.004427\n",
      "Epoch [680/1500], Loss: 0.004803\n",
      "Epoch [700/1500], Loss: 0.004438\n",
      "Epoch [720/1500], Loss: 0.004653\n",
      "Epoch [740/1500], Loss: 0.004470\n",
      "Epoch [760/1500], Loss: 0.004441\n",
      "Epoch [780/1500], Loss: 0.004647\n",
      "Epoch [800/1500], Loss: 0.004431\n",
      "Epoch [820/1500], Loss: 0.004895\n",
      "Epoch [840/1500], Loss: 0.004450\n",
      "Epoch [860/1500], Loss: 0.004555\n",
      "Epoch [880/1500], Loss: 0.004572\n",
      "Epoch [900/1500], Loss: 0.004427\n",
      "Usng step side 856\n",
      "Epoch [920/1500], Loss: 0.004771\n",
      "Epoch [940/1500], Loss: 0.004626\n",
      "Epoch [960/1500], Loss: 0.004605\n",
      "Epoch [980/1500], Loss: 0.004598\n",
      "Epoch [1000/1500], Loss: 0.004596\n",
      "Epoch [1020/1500], Loss: 0.004596\n",
      "Epoch [1040/1500], Loss: 0.004596\n",
      "Epoch [1060/1500], Loss: 0.004596\n",
      "Epoch [1080/1500], Loss: 0.004597\n",
      "Epoch [1100/1500], Loss: 0.004598\n",
      "Epoch [1120/1500], Loss: 0.004598\n",
      "Epoch [1140/1500], Loss: 0.004599\n",
      "Epoch [1160/1500], Loss: 0.004600\n",
      "Epoch [1180/1500], Loss: 0.004601\n",
      "Epoch [1200/1500], Loss: 0.004602\n",
      "Usng step side 100\n",
      "Epoch [1220/1500], Loss: 0.006304\n",
      "Epoch [1240/1500], Loss: 0.006104\n",
      "Epoch [1260/1500], Loss: 0.006094\n",
      "Epoch [1280/1500], Loss: 0.006093\n",
      "Epoch [1300/1500], Loss: 0.006093\n",
      "Epoch [1320/1500], Loss: 0.006093\n",
      "Epoch [1340/1500], Loss: 0.006093\n",
      "Epoch [1360/1500], Loss: 0.006093\n",
      "Epoch [1380/1500], Loss: 0.006093\n",
      "Epoch [1400/1500], Loss: 0.006093\n",
      "Epoch [1420/1500], Loss: 0.006093\n",
      "Epoch [1440/1500], Loss: 0.006093\n",
      "Epoch [1460/1500], Loss: 0.006093\n",
      "Epoch [1480/1500], Loss: 0.006093\n",
      "Epoch [1500/1500], Loss: 0.006093\n",
      "tensor(0.0720, device='cuda:0')\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.557698 for selected strength\n",
      "We have a total strength of 0.557699 for all the columns\n",
      "100%|████████████████████████████████████████████| 4/4 [09:41<00:00, 145.46s/it]\n",
      "Current accuracy: 19.968 \n",
      "Number of texts: 4800\n"
     ]
    }
   ],
   "source": [
    "!python compute_complete_text_set.py --device cuda:0 --model ViT-B-32 --texts_per_head 100 --num_of_last_layers 4 --text_descriptions image_descriptions_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Number of layers: 12\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 43.74it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s][3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.517662\n",
      "Epoch [40/1500], Loss: 0.467849\n",
      "Epoch [60/1500], Loss: 0.444533\n",
      "Epoch [80/1500], Loss: 0.417296\n",
      "Epoch [100/1500], Loss: 0.391512\n",
      "Epoch [120/1500], Loss: 0.367294\n",
      "Epoch [140/1500], Loss: 0.342210\n",
      "Epoch [160/1500], Loss: 0.319005\n",
      "Epoch [180/1500], Loss: 0.293711\n",
      "Epoch [200/1500], Loss: 0.272005\n",
      "Epoch [220/1500], Loss: 0.248405\n",
      "Epoch [240/1500], Loss: 0.231151\n",
      "Epoch [260/1500], Loss: 0.209372\n",
      "Epoch [280/1500], Loss: 0.189782\n",
      "Epoch [300/1500], Loss: 0.171604\n",
      "Epoch [320/1500], Loss: 0.146924\n",
      "Epoch [340/1500], Loss: 0.131276\n",
      "Epoch [360/1500], Loss: 0.125272\n",
      "Epoch [380/1500], Loss: 0.116314\n",
      "Epoch [400/1500], Loss: 0.105169\n",
      "Epoch [420/1500], Loss: 0.097588\n",
      "Epoch [440/1500], Loss: 0.086184\n",
      "Epoch [460/1500], Loss: 0.076753\n",
      "Epoch [480/1500], Loss: 0.069112\n",
      "Epoch [500/1500], Loss: 0.057945\n",
      "Epoch [520/1500], Loss: 0.049929\n",
      "Epoch [540/1500], Loss: 0.042095\n",
      "Epoch [560/1500], Loss: 0.035189\n",
      "Epoch [580/1500], Loss: 0.028905\n",
      "Epoch [600/1500], Loss: 0.023756\n",
      "Epoch [620/1500], Loss: 0.018668\n",
      "Epoch [640/1500], Loss: 0.015740\n",
      "Epoch [660/1500], Loss: 0.013333\n",
      "Epoch [680/1500], Loss: 0.011919\n",
      "Epoch [700/1500], Loss: 0.010276\n",
      "Epoch [720/1500], Loss: 0.008793\n",
      "Epoch [740/1500], Loss: 0.007758\n",
      "Epoch [760/1500], Loss: 0.006952\n",
      "Epoch [780/1500], Loss: 0.005491\n",
      "Epoch [800/1500], Loss: 0.005066\n",
      "Epoch [820/1500], Loss: 0.005252\n",
      "Epoch [840/1500], Loss: 0.004267\n",
      "Epoch [860/1500], Loss: 0.004593\n",
      "Epoch [880/1500], Loss: 0.003948\n",
      "Epoch [900/1500], Loss: 0.005081\n",
      "Epoch [920/1500], Loss: 0.002246\n",
      "Epoch [940/1500], Loss: 0.002385\n",
      "Epoch [960/1500], Loss: 0.002321\n",
      "Epoch [980/1500], Loss: 0.001951\n",
      "Epoch [1000/1500], Loss: 0.002670\n",
      "Epoch [1020/1500], Loss: 0.002446\n",
      "Epoch [1040/1500], Loss: 0.001838\n",
      "Epoch [1060/1500], Loss: 0.002068\n",
      "Epoch [1080/1500], Loss: 0.002288\n",
      "Epoch [1100/1500], Loss: 0.001922\n",
      "Epoch [1120/1500], Loss: 0.001668\n",
      "Epoch [1140/1500], Loss: 0.001889\n",
      "Epoch [1160/1500], Loss: 0.001752\n",
      "Epoch [1180/1500], Loss: 0.001658\n",
      "Epoch [1200/1500], Loss: 0.001336\n",
      "Epoch [1220/1500], Loss: 0.001022\n",
      "Epoch [1240/1500], Loss: 0.000924\n",
      "Epoch [1260/1500], Loss: 0.000921\n",
      "Epoch [1280/1500], Loss: 0.000888\n",
      "Epoch [1300/1500], Loss: 0.000878\n",
      "Epoch [1320/1500], Loss: 0.000868\n",
      "Epoch [1340/1500], Loss: 0.000863\n",
      "Epoch [1360/1500], Loss: 0.000862\n",
      "Epoch [1380/1500], Loss: 0.000862\n",
      "Epoch [1400/1500], Loss: 0.000862\n",
      "Epoch [1420/1500], Loss: 0.000862\n",
      "Epoch [1440/1500], Loss: 0.000862\n",
      "Epoch [1460/1500], Loss: 0.000862\n",
      "Epoch [1480/1500], Loss: 0.000862\n",
      "Epoch [1500/1500], Loss: 0.000862\n",
      "tensor(0.0174, device='cuda:0')\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.973097 for selected strength\n",
      "We have a total strength of 4.056264 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.508772\n",
      "Epoch [40/1500], Loss: 0.469768\n",
      "Epoch [60/1500], Loss: 0.440368\n",
      "Epoch [80/1500], Loss: 0.416227\n",
      "Epoch [100/1500], Loss: 0.390221\n",
      "Epoch [120/1500], Loss: 0.358063\n",
      "Epoch [140/1500], Loss: 0.334820\n",
      "Epoch [160/1500], Loss: 0.312479\n",
      "Epoch [180/1500], Loss: 0.287089\n",
      "Epoch [200/1500], Loss: 0.263078\n",
      "Epoch [220/1500], Loss: 0.238754\n",
      "Epoch [240/1500], Loss: 0.218770\n",
      "Epoch [260/1500], Loss: 0.197676\n",
      "Epoch [280/1500], Loss: 0.175718\n",
      "Epoch [300/1500], Loss: 0.157418\n",
      "Epoch [320/1500], Loss: 0.130643\n",
      "Epoch [340/1500], Loss: 0.121897\n",
      "Epoch [360/1500], Loss: 0.111845\n",
      "Epoch [380/1500], Loss: 0.101667\n",
      "Epoch [400/1500], Loss: 0.091580\n",
      "Epoch [420/1500], Loss: 0.082546\n",
      "Epoch [440/1500], Loss: 0.073119\n",
      "Epoch [460/1500], Loss: 0.063489\n",
      "Epoch [480/1500], Loss: 0.054391\n",
      "Epoch [500/1500], Loss: 0.046417\n",
      "Epoch [520/1500], Loss: 0.039493\n",
      "Epoch [540/1500], Loss: 0.033665\n",
      "Epoch [560/1500], Loss: 0.026954\n",
      "Epoch [580/1500], Loss: 0.022879\n",
      "Epoch [600/1500], Loss: 0.019582\n",
      "Epoch [620/1500], Loss: 0.016680\n",
      "Epoch [640/1500], Loss: 0.014294\n",
      "Epoch [660/1500], Loss: 0.012648\n",
      "Epoch [680/1500], Loss: 0.010876\n",
      "Epoch [700/1500], Loss: 0.009490\n",
      "Epoch [720/1500], Loss: 0.008992\n",
      "Epoch [740/1500], Loss: 0.007234\n",
      "Epoch [760/1500], Loss: 0.006737\n",
      "Epoch [780/1500], Loss: 0.006276\n",
      "Epoch [800/1500], Loss: 0.005471\n",
      "Epoch [820/1500], Loss: 0.004858\n",
      "Epoch [840/1500], Loss: 0.005734\n",
      "Epoch [860/1500], Loss: 0.005114\n",
      "Epoch [880/1500], Loss: 0.003320\n",
      "Epoch [900/1500], Loss: 0.005222\n",
      "Epoch [920/1500], Loss: 0.003215\n",
      "Epoch [940/1500], Loss: 0.003252\n",
      "Epoch [960/1500], Loss: 0.002630\n",
      "Epoch [980/1500], Loss: 0.002994\n",
      "Epoch [1000/1500], Loss: 0.002093\n",
      "Epoch [1020/1500], Loss: 0.001838\n",
      "Epoch [1040/1500], Loss: 0.002019\n",
      "Epoch [1060/1500], Loss: 0.002101\n",
      "Epoch [1080/1500], Loss: 0.001621\n",
      "Epoch [1100/1500], Loss: 0.001708\n",
      "Epoch [1120/1500], Loss: 0.001669\n",
      "Epoch [1140/1500], Loss: 0.001608\n",
      "Epoch [1160/1500], Loss: 0.001437\n",
      "Epoch [1180/1500], Loss: 0.001445\n",
      "Epoch [1200/1500], Loss: 0.001355\n",
      "Epoch [1220/1500], Loss: 0.000666\n",
      "Epoch [1240/1500], Loss: 0.000585\n",
      "Epoch [1260/1500], Loss: 0.000537\n",
      "Epoch [1280/1500], Loss: 0.000526\n",
      "Epoch [1300/1500], Loss: 0.000522\n",
      "Epoch [1320/1500], Loss: 0.000525\n",
      "Epoch [1340/1500], Loss: 0.000497\n",
      "Epoch [1360/1500], Loss: 0.000495\n",
      "Epoch [1380/1500], Loss: 0.000495\n",
      "Epoch [1400/1500], Loss: 0.000495\n",
      "Epoch [1420/1500], Loss: 0.000495\n",
      "Epoch [1440/1500], Loss: 0.000495\n",
      "Epoch [1460/1500], Loss: 0.000495\n",
      "Epoch [1480/1500], Loss: 0.000495\n",
      "Epoch [1500/1500], Loss: 0.000495\n",
      "tensor(0.0141, device='cuda:0')\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.560263 for selected strength\n",
      "We have a total strength of 2.949364 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.502674\n",
      "Epoch [40/1500], Loss: 0.468961\n",
      "Epoch [60/1500], Loss: 0.442060\n",
      "Epoch [80/1500], Loss: 0.414987\n",
      "Epoch [100/1500], Loss: 0.384099\n",
      "Epoch [120/1500], Loss: 0.358996\n",
      "Epoch [140/1500], Loss: 0.334525\n",
      "Epoch [160/1500], Loss: 0.307277\n",
      "Epoch [180/1500], Loss: 0.282420\n",
      "Epoch [200/1500], Loss: 0.259093\n",
      "Epoch [220/1500], Loss: 0.238514\n",
      "Epoch [240/1500], Loss: 0.216037\n",
      "Epoch [260/1500], Loss: 0.195993\n",
      "Epoch [280/1500], Loss: 0.174777\n",
      "Epoch [300/1500], Loss: 0.157915\n",
      "Epoch [320/1500], Loss: 0.130719\n",
      "Epoch [340/1500], Loss: 0.120178\n",
      "Epoch [360/1500], Loss: 0.112027\n",
      "Epoch [380/1500], Loss: 0.103960\n",
      "Epoch [400/1500], Loss: 0.094652\n",
      "Epoch [420/1500], Loss: 0.085408\n",
      "Epoch [440/1500], Loss: 0.074370\n",
      "Epoch [460/1500], Loss: 0.065968\n",
      "Epoch [480/1500], Loss: 0.056202\n",
      "Epoch [500/1500], Loss: 0.046787\n",
      "Epoch [520/1500], Loss: 0.039468\n",
      "Epoch [540/1500], Loss: 0.032153\n",
      "Epoch [560/1500], Loss: 0.026103\n",
      "Epoch [580/1500], Loss: 0.021557\n",
      "Epoch [600/1500], Loss: 0.017844\n",
      "Epoch [620/1500], Loss: 0.014229\n",
      "Epoch [640/1500], Loss: 0.012383\n",
      "Epoch [660/1500], Loss: 0.010647\n",
      "Epoch [680/1500], Loss: 0.009334\n",
      "Epoch [700/1500], Loss: 0.008069\n",
      "Epoch [720/1500], Loss: 0.006558\n",
      "Epoch [740/1500], Loss: 0.006707\n",
      "Epoch [760/1500], Loss: 0.005654\n",
      "Epoch [780/1500], Loss: 0.005222\n",
      "Epoch [800/1500], Loss: 0.005041\n",
      "Epoch [820/1500], Loss: 0.003655\n",
      "Epoch [840/1500], Loss: 0.003927\n",
      "Epoch [860/1500], Loss: 0.003849\n",
      "Epoch [880/1500], Loss: 0.004263\n",
      "Epoch [900/1500], Loss: 0.004575\n",
      "Epoch [920/1500], Loss: 0.002168\n",
      "Epoch [940/1500], Loss: 0.001843\n",
      "Epoch [960/1500], Loss: 0.002251\n",
      "Epoch [980/1500], Loss: 0.001906\n",
      "Epoch [1000/1500], Loss: 0.002321\n",
      "Epoch [1020/1500], Loss: 0.001838\n",
      "Epoch [1040/1500], Loss: 0.001811\n",
      "Epoch [1060/1500], Loss: 0.002036\n",
      "Epoch [1080/1500], Loss: 0.001537\n",
      "Epoch [1100/1500], Loss: 0.001654\n",
      "Epoch [1120/1500], Loss: 0.001403\n",
      "Epoch [1140/1500], Loss: 0.001415\n",
      "Epoch [1160/1500], Loss: 0.001555\n",
      "Epoch [1180/1500], Loss: 0.001633\n",
      "Epoch [1200/1500], Loss: 0.001456\n",
      "Epoch [1220/1500], Loss: 0.000811\n",
      "Epoch [1240/1500], Loss: 0.000758\n",
      "Epoch [1260/1500], Loss: 0.000738\n",
      "Epoch [1280/1500], Loss: 0.000736\n",
      "Epoch [1300/1500], Loss: 0.000736\n",
      "Epoch [1320/1500], Loss: 0.000736\n",
      "Epoch [1340/1500], Loss: 0.000736\n",
      "Epoch [1360/1500], Loss: 0.000736\n",
      "Epoch [1380/1500], Loss: 0.000736\n",
      "Epoch [1400/1500], Loss: 0.000736\n",
      "Epoch [1420/1500], Loss: 0.000736\n",
      "Epoch [1440/1500], Loss: 0.000736\n",
      "Epoch [1460/1500], Loss: 0.000736\n",
      "Epoch [1480/1500], Loss: 0.000736\n",
      "Epoch [1500/1500], Loss: 0.000736\n",
      "tensor(0.0109, device='cuda:0')\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.706772 for selected strength\n",
      "We have a total strength of 3.348994 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.513365\n",
      "Epoch [40/1500], Loss: 0.473158\n",
      "Epoch [60/1500], Loss: 0.437717\n",
      "Epoch [80/1500], Loss: 0.414652\n",
      "Epoch [100/1500], Loss: 0.382518\n",
      "Epoch [120/1500], Loss: 0.363940\n",
      "Epoch [140/1500], Loss: 0.333436\n",
      "Epoch [160/1500], Loss: 0.309849\n",
      "Epoch [180/1500], Loss: 0.286425\n",
      "Epoch [200/1500], Loss: 0.261308\n",
      "Epoch [220/1500], Loss: 0.243278\n",
      "Epoch [240/1500], Loss: 0.219192\n",
      "Epoch [260/1500], Loss: 0.196936\n",
      "Epoch [280/1500], Loss: 0.177141\n",
      "Epoch [300/1500], Loss: 0.160207\n",
      "Epoch [320/1500], Loss: 0.132532\n",
      "Epoch [340/1500], Loss: 0.121896\n",
      "Epoch [360/1500], Loss: 0.116305\n",
      "Epoch [380/1500], Loss: 0.104538\n",
      "Epoch [400/1500], Loss: 0.094276\n",
      "Epoch [420/1500], Loss: 0.085278\n",
      "Epoch [440/1500], Loss: 0.076405\n",
      "Epoch [460/1500], Loss: 0.066067\n",
      "Epoch [480/1500], Loss: 0.057856\n",
      "Epoch [500/1500], Loss: 0.049163\n",
      "Epoch [520/1500], Loss: 0.041113\n",
      "Epoch [540/1500], Loss: 0.034798\n",
      "Epoch [560/1500], Loss: 0.028339\n",
      "Epoch [580/1500], Loss: 0.024056\n",
      "Epoch [600/1500], Loss: 0.020213\n",
      "Epoch [620/1500], Loss: 0.016500\n",
      "Epoch [640/1500], Loss: 0.014314\n",
      "Epoch [660/1500], Loss: 0.012573\n",
      "Epoch [680/1500], Loss: 0.011222\n",
      "Epoch [700/1500], Loss: 0.010396\n",
      "Epoch [720/1500], Loss: 0.008640\n",
      "Epoch [740/1500], Loss: 0.007597\n",
      "Epoch [760/1500], Loss: 0.007139\n",
      "Epoch [780/1500], Loss: 0.005618\n",
      "Epoch [800/1500], Loss: 0.006441\n",
      "Epoch [820/1500], Loss: 0.006117\n",
      "Epoch [840/1500], Loss: 0.004959\n",
      "Epoch [860/1500], Loss: 0.005020\n",
      "Epoch [880/1500], Loss: 0.004171\n",
      "Epoch [900/1500], Loss: 0.004000\n",
      "Epoch [920/1500], Loss: 0.003118\n",
      "Epoch [940/1500], Loss: 0.002345\n",
      "Epoch [960/1500], Loss: 0.002060\n",
      "Epoch [980/1500], Loss: 0.002233\n",
      "Epoch [1000/1500], Loss: 0.002146\n",
      "Epoch [1020/1500], Loss: 0.002291\n",
      "Epoch [1040/1500], Loss: 0.002186\n",
      "Epoch [1060/1500], Loss: 0.001864\n",
      "Epoch [1080/1500], Loss: 0.001909\n",
      "Epoch [1100/1500], Loss: 0.001877\n",
      "Epoch [1120/1500], Loss: 0.001724\n",
      "Epoch [1140/1500], Loss: 0.001615\n",
      "Epoch [1160/1500], Loss: 0.002053\n",
      "Epoch [1180/1500], Loss: 0.001544\n",
      "Epoch [1200/1500], Loss: 0.001686\n",
      "Epoch [1220/1500], Loss: 0.000685\n",
      "Epoch [1240/1500], Loss: 0.000613\n",
      "Epoch [1260/1500], Loss: 0.000544\n",
      "Epoch [1280/1500], Loss: 0.000547\n",
      "Epoch [1300/1500], Loss: 0.000544\n",
      "Epoch [1320/1500], Loss: 0.000544\n",
      "Epoch [1340/1500], Loss: 0.000537\n",
      "Epoch [1360/1500], Loss: 0.000524\n",
      "Epoch [1380/1500], Loss: 0.000542\n",
      "Epoch [1400/1500], Loss: 0.000546\n",
      "Epoch [1420/1500], Loss: 0.000531\n",
      "Epoch [1440/1500], Loss: 0.000515\n",
      "Epoch [1460/1500], Loss: 0.000527\n",
      "Epoch [1480/1500], Loss: 0.000520\n",
      "Epoch [1500/1500], Loss: 0.000510\n",
      "tensor(0.0127, device='cuda:0')\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.638863 for selected strength\n",
      "We have a total strength of 3.071126 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.512427\n",
      "Epoch [40/1500], Loss: 0.466458\n",
      "Epoch [60/1500], Loss: 0.437838\n",
      "Epoch [80/1500], Loss: 0.401692\n",
      "Epoch [100/1500], Loss: 0.371758\n",
      "Epoch [120/1500], Loss: 0.349230\n",
      "Epoch [140/1500], Loss: 0.323490\n",
      "Epoch [160/1500], Loss: 0.293085\n",
      "Epoch [180/1500], Loss: 0.269383\n",
      "Epoch [200/1500], Loss: 0.248560\n",
      "Epoch [220/1500], Loss: 0.225003\n",
      "Epoch [240/1500], Loss: 0.199062\n",
      "Epoch [260/1500], Loss: 0.179258\n",
      "Epoch [280/1500], Loss: 0.159973\n",
      "Epoch [300/1500], Loss: 0.142342\n",
      "Epoch [320/1500], Loss: 0.117543\n",
      "Epoch [340/1500], Loss: 0.108537\n",
      "Epoch [360/1500], Loss: 0.097930\n",
      "Epoch [380/1500], Loss: 0.089485\n",
      "Epoch [400/1500], Loss: 0.079904\n",
      "Epoch [420/1500], Loss: 0.071208\n",
      "Epoch [440/1500], Loss: 0.061093\n",
      "Epoch [460/1500], Loss: 0.052430\n",
      "Epoch [480/1500], Loss: 0.044939\n",
      "Epoch [500/1500], Loss: 0.037256\n",
      "Epoch [520/1500], Loss: 0.029799\n",
      "Epoch [540/1500], Loss: 0.024181\n",
      "Epoch [560/1500], Loss: 0.020495\n",
      "Epoch [580/1500], Loss: 0.017877\n",
      "Epoch [600/1500], Loss: 0.015388\n",
      "Epoch [620/1500], Loss: 0.012202\n",
      "Epoch [640/1500], Loss: 0.010811\n",
      "Epoch [660/1500], Loss: 0.009253\n",
      "Epoch [680/1500], Loss: 0.008373\n",
      "Epoch [700/1500], Loss: 0.006852\n",
      "Epoch [720/1500], Loss: 0.006555\n",
      "Epoch [740/1500], Loss: 0.005993\n",
      "Epoch [760/1500], Loss: 0.005074\n",
      "Epoch [780/1500], Loss: 0.004485\n",
      "Epoch [800/1500], Loss: 0.005310\n",
      "Epoch [820/1500], Loss: 0.005399\n",
      "Epoch [840/1500], Loss: 0.005211\n",
      "Epoch [860/1500], Loss: 0.004990\n",
      "Epoch [880/1500], Loss: 0.004732\n",
      "Epoch [900/1500], Loss: 0.004510\n",
      "Epoch [920/1500], Loss: 0.002996\n",
      "Epoch [940/1500], Loss: 0.002965\n",
      "Epoch [960/1500], Loss: 0.002108\n",
      "Epoch [980/1500], Loss: 0.002258\n",
      "Epoch [1000/1500], Loss: 0.001999\n",
      "Epoch [1020/1500], Loss: 0.002092\n",
      "Epoch [1040/1500], Loss: 0.002091\n",
      "Epoch [1060/1500], Loss: 0.001877\n",
      "Epoch [1080/1500], Loss: 0.001932\n",
      "Epoch [1100/1500], Loss: 0.001863\n",
      "Epoch [1120/1500], Loss: 0.001833\n",
      "Epoch [1140/1500], Loss: 0.001724\n",
      "Epoch [1160/1500], Loss: 0.001440\n",
      "Epoch [1180/1500], Loss: 0.001875\n",
      "Epoch [1200/1500], Loss: 0.001372\n",
      "Epoch [1220/1500], Loss: 0.000695\n",
      "Epoch [1240/1500], Loss: 0.000599\n",
      "Epoch [1260/1500], Loss: 0.000543\n",
      "Epoch [1280/1500], Loss: 0.000523\n",
      "Epoch [1300/1500], Loss: 0.000518\n",
      "Epoch [1320/1500], Loss: 0.000511\n",
      "Epoch [1340/1500], Loss: 0.000506\n",
      "Epoch [1360/1500], Loss: 0.000490\n",
      "Epoch [1380/1500], Loss: 0.000489\n",
      "Epoch [1400/1500], Loss: 0.000489\n",
      "Epoch [1420/1500], Loss: 0.000489\n",
      "Epoch [1440/1500], Loss: 0.000489\n",
      "Epoch [1460/1500], Loss: 0.000489\n",
      "Epoch [1480/1500], Loss: 0.000489\n",
      "Epoch [1500/1500], Loss: 0.000489\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.523868 for selected strength\n",
      "We have a total strength of 2.712867 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.514170\n",
      "Epoch [40/1500], Loss: 0.473998\n",
      "Epoch [60/1500], Loss: 0.455003\n",
      "Epoch [80/1500], Loss: 0.421016\n",
      "Epoch [100/1500], Loss: 0.392351\n",
      "Epoch [120/1500], Loss: 0.366503\n",
      "Epoch [140/1500], Loss: 0.340331\n",
      "Epoch [160/1500], Loss: 0.321537\n",
      "Epoch [180/1500], Loss: 0.295461\n",
      "Epoch [200/1500], Loss: 0.273783\n",
      "Epoch [220/1500], Loss: 0.251143\n",
      "Epoch [240/1500], Loss: 0.232626\n",
      "Epoch [260/1500], Loss: 0.215347\n",
      "Epoch [280/1500], Loss: 0.194094\n",
      "Epoch [300/1500], Loss: 0.175876\n",
      "Epoch [320/1500], Loss: 0.147701\n",
      "Epoch [340/1500], Loss: 0.135219\n",
      "Epoch [360/1500], Loss: 0.128219\n",
      "Epoch [380/1500], Loss: 0.119779\n",
      "Epoch [400/1500], Loss: 0.109509\n",
      "Epoch [420/1500], Loss: 0.101464\n",
      "Epoch [440/1500], Loss: 0.091960\n",
      "Epoch [460/1500], Loss: 0.080531\n",
      "Epoch [480/1500], Loss: 0.071556\n",
      "Epoch [500/1500], Loss: 0.062625\n",
      "Epoch [520/1500], Loss: 0.053934\n",
      "Epoch [540/1500], Loss: 0.044754\n",
      "Epoch [560/1500], Loss: 0.037471\n",
      "Epoch [580/1500], Loss: 0.031451\n",
      "Epoch [600/1500], Loss: 0.024862\n",
      "Epoch [620/1500], Loss: 0.018533\n",
      "Epoch [640/1500], Loss: 0.015921\n",
      "Epoch [660/1500], Loss: 0.013658\n",
      "Epoch [680/1500], Loss: 0.012100\n",
      "Epoch [700/1500], Loss: 0.010107\n",
      "Epoch [720/1500], Loss: 0.008311\n",
      "Epoch [740/1500], Loss: 0.007081\n",
      "Epoch [760/1500], Loss: 0.005804\n",
      "Epoch [780/1500], Loss: 0.005497\n",
      "Epoch [800/1500], Loss: 0.004492\n",
      "Epoch [820/1500], Loss: 0.003873\n",
      "Epoch [840/1500], Loss: 0.004714\n",
      "Epoch [860/1500], Loss: 0.003445\n",
      "Epoch [880/1500], Loss: 0.003103\n",
      "Epoch [900/1500], Loss: 0.003420\n",
      "Epoch [920/1500], Loss: 0.002226\n",
      "Epoch [940/1500], Loss: 0.002418\n",
      "Epoch [960/1500], Loss: 0.002022\n",
      "Epoch [980/1500], Loss: 0.002189\n",
      "Epoch [1000/1500], Loss: 0.002274\n",
      "Epoch [1020/1500], Loss: 0.002338\n",
      "Epoch [1040/1500], Loss: 0.002242\n",
      "Epoch [1060/1500], Loss: 0.002311\n",
      "Epoch [1080/1500], Loss: 0.001945\n",
      "Epoch [1100/1500], Loss: 0.001638\n",
      "Epoch [1120/1500], Loss: 0.002135\n",
      "Epoch [1140/1500], Loss: 0.001759\n",
      "Epoch [1160/1500], Loss: 0.001913\n",
      "Epoch [1180/1500], Loss: 0.001478\n",
      "Epoch [1200/1500], Loss: 0.001642\n",
      "Epoch [1220/1500], Loss: 0.001262\n",
      "Epoch [1240/1500], Loss: 0.001180\n",
      "Epoch [1260/1500], Loss: 0.001158\n",
      "Epoch [1280/1500], Loss: 0.001160\n",
      "Epoch [1300/1500], Loss: 0.001148\n",
      "Epoch [1320/1500], Loss: 0.001145\n",
      "Epoch [1340/1500], Loss: 0.001127\n",
      "Epoch [1360/1500], Loss: 0.001116\n",
      "Epoch [1380/1500], Loss: 0.001113\n",
      "Epoch [1400/1500], Loss: 0.001112\n",
      "Epoch [1420/1500], Loss: 0.001112\n",
      "Epoch [1440/1500], Loss: 0.001112\n",
      "Epoch [1460/1500], Loss: 0.001112\n",
      "Epoch [1480/1500], Loss: 0.001112\n",
      "Epoch [1500/1500], Loss: 0.001112\n",
      "tensor(0.0197, device='cuda:0')\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.122256 for selected strength\n",
      "We have a total strength of 4.367408 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.506252\n",
      "Epoch [40/1500], Loss: 0.476520\n",
      "Epoch [60/1500], Loss: 0.446317\n",
      "Epoch [80/1500], Loss: 0.421148\n",
      "Epoch [100/1500], Loss: 0.394842\n",
      "Epoch [120/1500], Loss: 0.376187\n",
      "Epoch [140/1500], Loss: 0.347194\n",
      "Epoch [160/1500], Loss: 0.323001\n",
      "Epoch [180/1500], Loss: 0.300246\n",
      "Epoch [200/1500], Loss: 0.279386\n",
      "Epoch [220/1500], Loss: 0.254984\n",
      "Epoch [240/1500], Loss: 0.233051\n",
      "Epoch [260/1500], Loss: 0.215649\n",
      "Epoch [280/1500], Loss: 0.195983\n",
      "Epoch [300/1500], Loss: 0.176576\n",
      "Epoch [320/1500], Loss: 0.146986\n",
      "Epoch [340/1500], Loss: 0.135121\n",
      "Epoch [360/1500], Loss: 0.128031\n",
      "Epoch [380/1500], Loss: 0.120878\n",
      "Epoch [400/1500], Loss: 0.111101\n",
      "Epoch [420/1500], Loss: 0.101301\n",
      "Epoch [440/1500], Loss: 0.091708\n",
      "Epoch [460/1500], Loss: 0.081838\n",
      "Epoch [480/1500], Loss: 0.071304\n",
      "Epoch [500/1500], Loss: 0.062645\n",
      "Epoch [520/1500], Loss: 0.053711\n",
      "Epoch [540/1500], Loss: 0.046924\n",
      "Epoch [560/1500], Loss: 0.039575\n",
      "Epoch [580/1500], Loss: 0.032171\n",
      "Epoch [600/1500], Loss: 0.026703\n",
      "Epoch [620/1500], Loss: 0.020012\n",
      "Epoch [640/1500], Loss: 0.017338\n",
      "Epoch [660/1500], Loss: 0.014929\n",
      "Epoch [680/1500], Loss: 0.012899\n",
      "Epoch [700/1500], Loss: 0.011469\n",
      "Epoch [720/1500], Loss: 0.010250\n",
      "Epoch [740/1500], Loss: 0.008781\n",
      "Epoch [760/1500], Loss: 0.007057\n",
      "Epoch [780/1500], Loss: 0.006337\n",
      "Epoch [800/1500], Loss: 0.005357\n",
      "Epoch [820/1500], Loss: 0.005806\n",
      "Epoch [840/1500], Loss: 0.004713\n",
      "Epoch [860/1500], Loss: 0.003626\n",
      "Epoch [880/1500], Loss: 0.003634\n",
      "Epoch [900/1500], Loss: 0.004405\n",
      "Epoch [920/1500], Loss: 0.002743\n",
      "Epoch [940/1500], Loss: 0.002342\n",
      "Epoch [960/1500], Loss: 0.002888\n",
      "Epoch [980/1500], Loss: 0.002678\n",
      "Epoch [1000/1500], Loss: 0.001987\n",
      "Epoch [1020/1500], Loss: 0.002455\n",
      "Epoch [1040/1500], Loss: 0.002123\n",
      "Epoch [1060/1500], Loss: 0.001807\n",
      "Epoch [1080/1500], Loss: 0.002322\n",
      "Epoch [1100/1500], Loss: 0.001882\n",
      "Epoch [1120/1500], Loss: 0.001786\n",
      "Epoch [1140/1500], Loss: 0.001663\n",
      "Epoch [1160/1500], Loss: 0.001812\n",
      "Epoch [1180/1500], Loss: 0.001408\n",
      "Epoch [1200/1500], Loss: 0.001669\n",
      "Epoch [1220/1500], Loss: 0.000955\n",
      "Epoch [1240/1500], Loss: 0.000930\n",
      "Epoch [1260/1500], Loss: 0.000880\n",
      "Epoch [1280/1500], Loss: 0.000852\n",
      "Epoch [1300/1500], Loss: 0.000844\n",
      "Epoch [1320/1500], Loss: 0.000844\n",
      "Epoch [1340/1500], Loss: 0.000836\n",
      "Epoch [1360/1500], Loss: 0.000818\n",
      "Epoch [1380/1500], Loss: 0.000823\n",
      "Epoch [1400/1500], Loss: 0.000811\n",
      "Epoch [1420/1500], Loss: 0.000835\n",
      "Epoch [1440/1500], Loss: 0.000833\n",
      "Epoch [1460/1500], Loss: 0.000802\n",
      "Epoch [1480/1500], Loss: 0.000799\n",
      "Epoch [1500/1500], Loss: 0.000799\n",
      "tensor(0.0239, device='cuda:0')\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.931691 for selected strength\n",
      "We have a total strength of 3.685710 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.508198\n",
      "Epoch [40/1500], Loss: 0.473940\n",
      "Epoch [60/1500], Loss: 0.438068\n",
      "Epoch [80/1500], Loss: 0.411804\n",
      "Epoch [100/1500], Loss: 0.383383\n",
      "Epoch [120/1500], Loss: 0.356798\n",
      "Epoch [140/1500], Loss: 0.330126\n",
      "Epoch [160/1500], Loss: 0.302442\n",
      "Epoch [180/1500], Loss: 0.280737\n",
      "Epoch [200/1500], Loss: 0.253563\n",
      "Epoch [220/1500], Loss: 0.231034\n",
      "Epoch [240/1500], Loss: 0.208532\n",
      "Epoch [260/1500], Loss: 0.189348\n",
      "Epoch [280/1500], Loss: 0.169905\n",
      "Epoch [300/1500], Loss: 0.151299\n",
      "Epoch [320/1500], Loss: 0.125577\n",
      "Epoch [340/1500], Loss: 0.113838\n",
      "Epoch [360/1500], Loss: 0.107393\n",
      "Epoch [380/1500], Loss: 0.096552\n",
      "Epoch [400/1500], Loss: 0.087977\n",
      "Epoch [420/1500], Loss: 0.079383\n",
      "Epoch [440/1500], Loss: 0.069985\n",
      "Epoch [460/1500], Loss: 0.060162\n",
      "Epoch [480/1500], Loss: 0.051132\n",
      "Epoch [500/1500], Loss: 0.042733\n",
      "Epoch [520/1500], Loss: 0.035883\n",
      "Epoch [540/1500], Loss: 0.030284\n",
      "Epoch [560/1500], Loss: 0.024035\n",
      "Epoch [580/1500], Loss: 0.020224\n",
      "Epoch [600/1500], Loss: 0.017068\n",
      "Epoch [620/1500], Loss: 0.014315\n",
      "Epoch [640/1500], Loss: 0.012371\n",
      "Epoch [660/1500], Loss: 0.010467\n",
      "Epoch [680/1500], Loss: 0.009669\n",
      "Epoch [700/1500], Loss: 0.008264\n",
      "Epoch [720/1500], Loss: 0.007340\n",
      "Epoch [740/1500], Loss: 0.006242\n",
      "Epoch [760/1500], Loss: 0.006279\n",
      "Epoch [780/1500], Loss: 0.004973\n",
      "Epoch [800/1500], Loss: 0.004729\n",
      "Epoch [820/1500], Loss: 0.005823\n",
      "Epoch [840/1500], Loss: 0.005210\n",
      "Epoch [860/1500], Loss: 0.005367\n",
      "Epoch [880/1500], Loss: 0.004438\n",
      "Epoch [900/1500], Loss: 0.005161\n",
      "Epoch [920/1500], Loss: 0.002607\n",
      "Epoch [940/1500], Loss: 0.002246\n",
      "Epoch [960/1500], Loss: 0.002964\n",
      "Epoch [980/1500], Loss: 0.002784\n",
      "Epoch [1000/1500], Loss: 0.002057\n",
      "Epoch [1020/1500], Loss: 0.001832\n",
      "Epoch [1040/1500], Loss: 0.002396\n",
      "Epoch [1060/1500], Loss: 0.001670\n",
      "Epoch [1080/1500], Loss: 0.001847\n",
      "Epoch [1100/1500], Loss: 0.001728\n",
      "Epoch [1120/1500], Loss: 0.001550\n",
      "Epoch [1140/1500], Loss: 0.001584\n",
      "Epoch [1160/1500], Loss: 0.001442\n",
      "Epoch [1180/1500], Loss: 0.001569\n",
      "Epoch [1200/1500], Loss: 0.001477\n",
      "Epoch [1220/1500], Loss: 0.000775\n",
      "Epoch [1240/1500], Loss: 0.000640\n",
      "Epoch [1260/1500], Loss: 0.000627\n",
      "Epoch [1280/1500], Loss: 0.000604\n",
      "Epoch [1300/1500], Loss: 0.000597\n",
      "Epoch [1320/1500], Loss: 0.000597\n",
      "Epoch [1340/1500], Loss: 0.000597\n",
      "Epoch [1360/1500], Loss: 0.000597\n",
      "Epoch [1380/1500], Loss: 0.000597\n",
      "Epoch [1400/1500], Loss: 0.000597\n",
      "Epoch [1420/1500], Loss: 0.000597\n",
      "Epoch [1440/1500], Loss: 0.000597\n",
      "Epoch [1460/1500], Loss: 0.000597\n",
      "Epoch [1480/1500], Loss: 0.000597\n",
      "Epoch [1500/1500], Loss: 0.000597\n",
      "tensor(0.0097, device='cuda:0')\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.667226 for selected strength\n",
      "We have a total strength of 3.198719 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.515852\n",
      "Epoch [40/1500], Loss: 0.469429\n",
      "Epoch [60/1500], Loss: 0.443143\n",
      "Epoch [80/1500], Loss: 0.416053\n",
      "Epoch [100/1500], Loss: 0.388969\n",
      "Epoch [120/1500], Loss: 0.360796\n",
      "Epoch [140/1500], Loss: 0.335968\n",
      "Epoch [160/1500], Loss: 0.316615\n",
      "Epoch [180/1500], Loss: 0.291731\n",
      "Epoch [200/1500], Loss: 0.268714\n",
      "Epoch [220/1500], Loss: 0.249428\n",
      "Epoch [240/1500], Loss: 0.227982\n",
      "Epoch [260/1500], Loss: 0.208806\n",
      "Epoch [280/1500], Loss: 0.189913\n",
      "Epoch [300/1500], Loss: 0.170500\n",
      "Epoch [320/1500], Loss: 0.143920\n",
      "Epoch [340/1500], Loss: 0.133622\n",
      "Epoch [360/1500], Loss: 0.128716\n",
      "Epoch [380/1500], Loss: 0.115489\n",
      "Epoch [400/1500], Loss: 0.105783\n",
      "Epoch [420/1500], Loss: 0.096332\n",
      "Epoch [440/1500], Loss: 0.087661\n",
      "Epoch [460/1500], Loss: 0.077146\n",
      "Epoch [480/1500], Loss: 0.067498\n",
      "Epoch [500/1500], Loss: 0.058376\n",
      "Epoch [520/1500], Loss: 0.049905\n",
      "Epoch [540/1500], Loss: 0.041763\n",
      "Epoch [560/1500], Loss: 0.035612\n",
      "Epoch [580/1500], Loss: 0.028362\n",
      "Epoch [600/1500], Loss: 0.022857\n",
      "Epoch [620/1500], Loss: 0.017507\n",
      "Epoch [640/1500], Loss: 0.014737\n",
      "Epoch [660/1500], Loss: 0.012722\n",
      "Epoch [680/1500], Loss: 0.011066\n",
      "Epoch [700/1500], Loss: 0.009496\n",
      "Epoch [720/1500], Loss: 0.008002\n",
      "Epoch [740/1500], Loss: 0.006859\n",
      "Epoch [760/1500], Loss: 0.005786\n",
      "Epoch [780/1500], Loss: 0.005217\n",
      "Epoch [800/1500], Loss: 0.004270\n",
      "Epoch [820/1500], Loss: 0.005007\n",
      "Epoch [840/1500], Loss: 0.004575\n",
      "Epoch [860/1500], Loss: 0.003137\n",
      "Epoch [880/1500], Loss: 0.004113\n",
      "Epoch [900/1500], Loss: 0.003036\n",
      "Epoch [920/1500], Loss: 0.002157\n",
      "Epoch [940/1500], Loss: 0.002395\n",
      "Epoch [960/1500], Loss: 0.002293\n",
      "Epoch [980/1500], Loss: 0.002201\n",
      "Epoch [1000/1500], Loss: 0.001832\n",
      "Epoch [1020/1500], Loss: 0.001485\n",
      "Epoch [1040/1500], Loss: 0.002267\n",
      "Epoch [1060/1500], Loss: 0.001935\n",
      "Epoch [1080/1500], Loss: 0.001917\n",
      "Epoch [1100/1500], Loss: 0.001452\n",
      "Epoch [1120/1500], Loss: 0.001779\n",
      "Epoch [1140/1500], Loss: 0.001520\n",
      "Epoch [1160/1500], Loss: 0.001789\n",
      "Epoch [1180/1500], Loss: 0.001557\n",
      "Epoch [1200/1500], Loss: 0.001713\n",
      "Epoch [1220/1500], Loss: 0.001228\n",
      "Epoch [1240/1500], Loss: 0.001139\n",
      "Epoch [1260/1500], Loss: 0.001113\n",
      "Epoch [1280/1500], Loss: 0.001099\n",
      "Epoch [1300/1500], Loss: 0.001114\n",
      "Epoch [1320/1500], Loss: 0.001082\n",
      "Epoch [1340/1500], Loss: 0.001079\n",
      "Epoch [1360/1500], Loss: 0.001078\n",
      "Epoch [1380/1500], Loss: 0.001078\n",
      "Epoch [1400/1500], Loss: 0.001078\n",
      "Epoch [1420/1500], Loss: 0.001078\n",
      "Epoch [1440/1500], Loss: 0.001078\n",
      "Epoch [1460/1500], Loss: 0.001078\n",
      "Epoch [1480/1500], Loss: 0.001078\n",
      "Epoch [1500/1500], Loss: 0.001078\n",
      "tensor(0.0177, device='cuda:0')\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.950336 for selected strength\n",
      "We have a total strength of 3.998864 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.519777\n",
      "Epoch [40/1500], Loss: 0.463985\n",
      "Epoch [60/1500], Loss: 0.443166\n",
      "Epoch [80/1500], Loss: 0.414471\n",
      "Epoch [100/1500], Loss: 0.381774\n",
      "Epoch [120/1500], Loss: 0.359073\n",
      "Epoch [140/1500], Loss: 0.332383\n",
      "Epoch [160/1500], Loss: 0.308536\n",
      "Epoch [180/1500], Loss: 0.278994\n",
      "Epoch [200/1500], Loss: 0.261917\n",
      "Epoch [220/1500], Loss: 0.235320\n",
      "Epoch [240/1500], Loss: 0.214347\n",
      "Epoch [260/1500], Loss: 0.195311\n",
      "Epoch [280/1500], Loss: 0.174073\n",
      "Epoch [300/1500], Loss: 0.157172\n",
      "Epoch [320/1500], Loss: 0.129863\n",
      "Epoch [340/1500], Loss: 0.120676\n",
      "Epoch [360/1500], Loss: 0.112903\n",
      "Epoch [380/1500], Loss: 0.104751\n",
      "Epoch [400/1500], Loss: 0.092829\n",
      "Epoch [420/1500], Loss: 0.083847\n",
      "Epoch [440/1500], Loss: 0.073705\n",
      "Epoch [460/1500], Loss: 0.066189\n",
      "Epoch [480/1500], Loss: 0.056111\n",
      "Epoch [500/1500], Loss: 0.046997\n",
      "Epoch [520/1500], Loss: 0.039393\n",
      "Epoch [540/1500], Loss: 0.032059\n",
      "Epoch [560/1500], Loss: 0.025526\n",
      "Epoch [580/1500], Loss: 0.021266\n",
      "Epoch [600/1500], Loss: 0.017486\n",
      "Epoch [620/1500], Loss: 0.013856\n",
      "Epoch [640/1500], Loss: 0.012130\n",
      "Epoch [660/1500], Loss: 0.010283\n",
      "Epoch [680/1500], Loss: 0.008892\n",
      "Epoch [700/1500], Loss: 0.007650\n",
      "Epoch [720/1500], Loss: 0.006810\n",
      "Epoch [740/1500], Loss: 0.005619\n",
      "Epoch [760/1500], Loss: 0.005487\n",
      "Epoch [780/1500], Loss: 0.004688\n",
      "Epoch [800/1500], Loss: 0.004739\n",
      "Epoch [820/1500], Loss: 0.003628\n",
      "Epoch [840/1500], Loss: 0.003988\n",
      "Epoch [860/1500], Loss: 0.004610\n",
      "Epoch [880/1500], Loss: 0.003643\n",
      "Epoch [900/1500], Loss: 0.002883\n",
      "Epoch [920/1500], Loss: 0.002199\n",
      "Epoch [940/1500], Loss: 0.001887\n",
      "Epoch [960/1500], Loss: 0.002770\n",
      "Epoch [980/1500], Loss: 0.002341\n",
      "Epoch [1000/1500], Loss: 0.001516\n",
      "Epoch [1020/1500], Loss: 0.002218\n",
      "Epoch [1040/1500], Loss: 0.002176\n",
      "Epoch [1060/1500], Loss: 0.001827\n",
      "Epoch [1080/1500], Loss: 0.001434\n",
      "Epoch [1100/1500], Loss: 0.001824\n",
      "Epoch [1120/1500], Loss: 0.001420\n",
      "Epoch [1140/1500], Loss: 0.001231\n",
      "Epoch [1160/1500], Loss: 0.001544\n",
      "Epoch [1180/1500], Loss: 0.001442\n",
      "Epoch [1200/1500], Loss: 0.001617\n",
      "Epoch [1220/1500], Loss: 0.000730\n",
      "Epoch [1240/1500], Loss: 0.000657\n",
      "Epoch [1260/1500], Loss: 0.000634\n",
      "Epoch [1280/1500], Loss: 0.000626\n",
      "Epoch [1300/1500], Loss: 0.000618\n",
      "Epoch [1320/1500], Loss: 0.000601\n",
      "Epoch [1340/1500], Loss: 0.000603\n",
      "Epoch [1360/1500], Loss: 0.000599\n",
      "Epoch [1380/1500], Loss: 0.000603\n",
      "Epoch [1400/1500], Loss: 0.000600\n",
      "Epoch [1420/1500], Loss: 0.000597\n",
      "Epoch [1440/1500], Loss: 0.000599\n",
      "Epoch [1460/1500], Loss: 0.000602\n",
      "Epoch [1480/1500], Loss: 0.000599\n",
      "Epoch [1500/1500], Loss: 0.000598\n",
      "tensor(0.0101, device='cuda:0')\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.605379 for selected strength\n",
      "We have a total strength of 2.807371 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.509575\n",
      "Epoch [40/1500], Loss: 0.465819\n",
      "Epoch [60/1500], Loss: 0.443038\n",
      "Epoch [80/1500], Loss: 0.413252\n",
      "Epoch [100/1500], Loss: 0.384878\n",
      "Epoch [120/1500], Loss: 0.359151\n",
      "Epoch [140/1500], Loss: 0.329728\n",
      "Epoch [160/1500], Loss: 0.304482\n",
      "Epoch [180/1500], Loss: 0.277781\n",
      "Epoch [200/1500], Loss: 0.258237\n",
      "Epoch [220/1500], Loss: 0.233703\n",
      "Epoch [240/1500], Loss: 0.212890\n",
      "Epoch [260/1500], Loss: 0.190983\n",
      "Epoch [280/1500], Loss: 0.170724\n",
      "Epoch [300/1500], Loss: 0.153691\n",
      "Epoch [320/1500], Loss: 0.126108\n",
      "Epoch [340/1500], Loss: 0.116663\n",
      "Epoch [360/1500], Loss: 0.108801\n",
      "Epoch [380/1500], Loss: 0.098348\n",
      "Epoch [400/1500], Loss: 0.090644\n",
      "Epoch [420/1500], Loss: 0.080415\n",
      "Epoch [440/1500], Loss: 0.071191\n",
      "Epoch [460/1500], Loss: 0.061782\n",
      "Epoch [480/1500], Loss: 0.052114\n",
      "Epoch [500/1500], Loss: 0.044460\n",
      "Epoch [520/1500], Loss: 0.037570\n",
      "Epoch [540/1500], Loss: 0.030705\n",
      "Epoch [560/1500], Loss: 0.025906\n",
      "Epoch [580/1500], Loss: 0.021724\n",
      "Epoch [600/1500], Loss: 0.018595\n",
      "Epoch [620/1500], Loss: 0.015243\n",
      "Epoch [640/1500], Loss: 0.013567\n",
      "Epoch [660/1500], Loss: 0.011316\n",
      "Epoch [680/1500], Loss: 0.010584\n",
      "Epoch [700/1500], Loss: 0.009810\n",
      "Epoch [720/1500], Loss: 0.009030\n",
      "Epoch [740/1500], Loss: 0.007345\n",
      "Epoch [760/1500], Loss: 0.006261\n",
      "Epoch [780/1500], Loss: 0.007299\n",
      "Epoch [800/1500], Loss: 0.005216\n",
      "Epoch [820/1500], Loss: 0.004728\n",
      "Epoch [840/1500], Loss: 0.004643\n",
      "Epoch [860/1500], Loss: 0.004423\n",
      "Epoch [880/1500], Loss: 0.005462\n",
      "Epoch [900/1500], Loss: 0.005020\n",
      "Epoch [920/1500], Loss: 0.002669\n",
      "Epoch [940/1500], Loss: 0.002447\n",
      "Epoch [960/1500], Loss: 0.003007\n",
      "Epoch [980/1500], Loss: 0.002789\n",
      "Epoch [1000/1500], Loss: 0.002397\n",
      "Epoch [1020/1500], Loss: 0.002794\n",
      "Epoch [1040/1500], Loss: 0.002408\n",
      "Epoch [1060/1500], Loss: 0.001640\n",
      "Epoch [1080/1500], Loss: 0.001669\n",
      "Epoch [1100/1500], Loss: 0.001801\n",
      "Epoch [1120/1500], Loss: 0.001979\n",
      "Epoch [1140/1500], Loss: 0.001725\n",
      "Epoch [1160/1500], Loss: 0.001629\n",
      "Epoch [1180/1500], Loss: 0.001689\n",
      "Epoch [1200/1500], Loss: 0.001612\n",
      "Epoch [1220/1500], Loss: 0.000705\n",
      "Epoch [1240/1500], Loss: 0.000558\n",
      "Epoch [1260/1500], Loss: 0.000513\n",
      "Epoch [1280/1500], Loss: 0.000513\n",
      "Epoch [1300/1500], Loss: 0.000511\n",
      "Epoch [1320/1500], Loss: 0.000503\n",
      "Epoch [1340/1500], Loss: 0.000513\n",
      "Epoch [1360/1500], Loss: 0.000507\n",
      "Epoch [1380/1500], Loss: 0.000514\n",
      "Epoch [1400/1500], Loss: 0.000499\n",
      "Epoch [1420/1500], Loss: 0.000490\n",
      "Epoch [1440/1500], Loss: 0.000485\n",
      "Epoch [1460/1500], Loss: 0.000485\n",
      "Epoch [1480/1500], Loss: 0.000485\n",
      "Epoch [1500/1500], Loss: 0.000485\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.580099 for selected strength\n",
      "We have a total strength of 3.028975 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.512063\n",
      "Epoch [40/1500], Loss: 0.468978\n",
      "Epoch [60/1500], Loss: 0.450692\n",
      "Epoch [80/1500], Loss: 0.414986\n",
      "Epoch [100/1500], Loss: 0.392766\n",
      "Epoch [120/1500], Loss: 0.366507\n",
      "Epoch [140/1500], Loss: 0.340800\n",
      "Epoch [160/1500], Loss: 0.316053\n",
      "Epoch [180/1500], Loss: 0.292234\n",
      "Epoch [200/1500], Loss: 0.269110\n",
      "Epoch [220/1500], Loss: 0.251591\n",
      "Epoch [240/1500], Loss: 0.228287\n",
      "Epoch [260/1500], Loss: 0.209519\n",
      "Epoch [280/1500], Loss: 0.190258\n",
      "Epoch [300/1500], Loss: 0.172779\n",
      "Epoch [320/1500], Loss: 0.143158\n",
      "Epoch [340/1500], Loss: 0.132295\n",
      "Epoch [360/1500], Loss: 0.125117\n",
      "Epoch [380/1500], Loss: 0.116826\n",
      "Epoch [400/1500], Loss: 0.105334\n",
      "Epoch [420/1500], Loss: 0.097799\n",
      "Epoch [440/1500], Loss: 0.088857\n",
      "Epoch [460/1500], Loss: 0.078289\n",
      "Epoch [480/1500], Loss: 0.070110\n",
      "Epoch [500/1500], Loss: 0.060636\n",
      "Epoch [520/1500], Loss: 0.050668\n",
      "Epoch [540/1500], Loss: 0.042317\n",
      "Epoch [560/1500], Loss: 0.035490\n",
      "Epoch [580/1500], Loss: 0.029114\n",
      "Epoch [600/1500], Loss: 0.023270\n",
      "Epoch [620/1500], Loss: 0.017703\n",
      "Epoch [640/1500], Loss: 0.015335\n",
      "Epoch [660/1500], Loss: 0.012830\n",
      "Epoch [680/1500], Loss: 0.011174\n",
      "Epoch [700/1500], Loss: 0.009676\n",
      "Epoch [720/1500], Loss: 0.008047\n",
      "Epoch [740/1500], Loss: 0.006859\n",
      "Epoch [760/1500], Loss: 0.006063\n",
      "Epoch [780/1500], Loss: 0.005540\n",
      "Epoch [800/1500], Loss: 0.004339\n",
      "Epoch [820/1500], Loss: 0.004028\n",
      "Epoch [840/1500], Loss: 0.004212\n",
      "Epoch [860/1500], Loss: 0.003669\n",
      "Epoch [880/1500], Loss: 0.003874\n",
      "Epoch [900/1500], Loss: 0.003569\n",
      "Epoch [920/1500], Loss: 0.002114\n",
      "Epoch [940/1500], Loss: 0.002527\n",
      "Epoch [960/1500], Loss: 0.002361\n",
      "Epoch [980/1500], Loss: 0.001854\n",
      "Epoch [1000/1500], Loss: 0.002325\n",
      "Epoch [1020/1500], Loss: 0.001966\n",
      "Epoch [1040/1500], Loss: 0.001982\n",
      "Epoch [1060/1500], Loss: 0.002208\n",
      "Epoch [1080/1500], Loss: 0.002280\n",
      "Epoch [1100/1500], Loss: 0.001764\n",
      "Epoch [1120/1500], Loss: 0.001985\n",
      "Epoch [1140/1500], Loss: 0.001524\n",
      "Epoch [1160/1500], Loss: 0.001386\n",
      "Epoch [1180/1500], Loss: 0.001911\n",
      "Epoch [1200/1500], Loss: 0.001650\n",
      "Epoch [1220/1500], Loss: 0.001190\n",
      "Epoch [1240/1500], Loss: 0.001060\n",
      "Epoch [1260/1500], Loss: 0.001038\n",
      "Epoch [1280/1500], Loss: 0.001035\n",
      "Epoch [1300/1500], Loss: 0.001035\n",
      "Epoch [1320/1500], Loss: 0.001035\n",
      "Epoch [1340/1500], Loss: 0.001035\n",
      "Epoch [1360/1500], Loss: 0.001035\n",
      "Epoch [1380/1500], Loss: 0.001035\n",
      "Epoch [1400/1500], Loss: 0.001035\n",
      "Epoch [1420/1500], Loss: 0.001035\n",
      "Epoch [1440/1500], Loss: 0.001035\n",
      "Epoch [1460/1500], Loss: 0.001035\n",
      "Epoch [1480/1500], Loss: 0.001035\n",
      "Epoch [1500/1500], Loss: 0.001035\n",
      "tensor(0.0150, device='cuda:0')\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.040003 for selected strength\n",
      "We have a total strength of 4.197521 for all the columns\n",
      " 25%|███████████                                 | 1/4 [03:29<10:27, 209.19s/it][3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.507227\n",
      "Epoch [40/1500], Loss: 0.473672\n",
      "Epoch [60/1500], Loss: 0.444291\n",
      "Epoch [80/1500], Loss: 0.407059\n",
      "Epoch [100/1500], Loss: 0.377637\n",
      "Epoch [120/1500], Loss: 0.357180\n",
      "Epoch [140/1500], Loss: 0.329160\n",
      "Epoch [160/1500], Loss: 0.301928\n",
      "Epoch [180/1500], Loss: 0.281468\n",
      "Epoch [200/1500], Loss: 0.253198\n",
      "Epoch [220/1500], Loss: 0.227606\n",
      "Epoch [240/1500], Loss: 0.208345\n",
      "Epoch [260/1500], Loss: 0.186174\n",
      "Epoch [280/1500], Loss: 0.166405\n",
      "Epoch [300/1500], Loss: 0.147006\n",
      "Epoch [320/1500], Loss: 0.122267\n",
      "Epoch [340/1500], Loss: 0.111556\n",
      "Epoch [360/1500], Loss: 0.104720\n",
      "Epoch [380/1500], Loss: 0.095374\n",
      "Epoch [400/1500], Loss: 0.083303\n",
      "Epoch [420/1500], Loss: 0.074476\n",
      "Epoch [440/1500], Loss: 0.066876\n",
      "Epoch [460/1500], Loss: 0.057027\n",
      "Epoch [480/1500], Loss: 0.047856\n",
      "Epoch [500/1500], Loss: 0.040245\n",
      "Epoch [520/1500], Loss: 0.032834\n",
      "Epoch [540/1500], Loss: 0.026766\n",
      "Epoch [560/1500], Loss: 0.021689\n",
      "Epoch [580/1500], Loss: 0.017741\n",
      "Epoch [600/1500], Loss: 0.016127\n",
      "Epoch [620/1500], Loss: 0.012175\n",
      "Epoch [640/1500], Loss: 0.010098\n",
      "Epoch [660/1500], Loss: 0.008725\n",
      "Epoch [680/1500], Loss: 0.007379\n",
      "Epoch [700/1500], Loss: 0.007060\n",
      "Epoch [720/1500], Loss: 0.006126\n",
      "Epoch [740/1500], Loss: 0.005720\n",
      "Epoch [760/1500], Loss: 0.005733\n",
      "Epoch [780/1500], Loss: 0.004565\n",
      "Epoch [800/1500], Loss: 0.004776\n",
      "Epoch [820/1500], Loss: 0.005207\n",
      "Epoch [840/1500], Loss: 0.003103\n",
      "Epoch [860/1500], Loss: 0.003187\n",
      "Epoch [880/1500], Loss: 0.003007\n",
      "Epoch [900/1500], Loss: 0.003261\n",
      "Epoch [920/1500], Loss: 0.001981\n",
      "Epoch [940/1500], Loss: 0.001948\n",
      "Epoch [960/1500], Loss: 0.002438\n",
      "Epoch [980/1500], Loss: 0.001721\n",
      "Epoch [1000/1500], Loss: 0.002340\n",
      "Epoch [1020/1500], Loss: 0.001982\n",
      "Epoch [1040/1500], Loss: 0.001411\n",
      "Epoch [1060/1500], Loss: 0.002173\n",
      "Epoch [1080/1500], Loss: 0.001725\n",
      "Epoch [1100/1500], Loss: 0.002318\n",
      "Epoch [1120/1500], Loss: 0.001521\n",
      "Epoch [1140/1500], Loss: 0.001503\n",
      "Epoch [1160/1500], Loss: 0.001575\n",
      "Epoch [1180/1500], Loss: 0.001976\n",
      "Epoch [1200/1500], Loss: 0.001220\n",
      "Epoch [1220/1500], Loss: 0.001021\n",
      "Epoch [1240/1500], Loss: 0.000927\n",
      "Epoch [1260/1500], Loss: 0.000916\n",
      "Epoch [1280/1500], Loss: 0.000902\n",
      "Epoch [1300/1500], Loss: 0.000900\n",
      "Epoch [1320/1500], Loss: 0.000900\n",
      "Epoch [1340/1500], Loss: 0.000900\n",
      "Epoch [1360/1500], Loss: 0.000900\n",
      "Epoch [1380/1500], Loss: 0.000900\n",
      "Epoch [1400/1500], Loss: 0.000900\n",
      "Epoch [1420/1500], Loss: 0.000900\n",
      "Epoch [1440/1500], Loss: 0.000900\n",
      "Epoch [1460/1500], Loss: 0.000900\n",
      "Epoch [1480/1500], Loss: 0.000900\n",
      "Epoch [1500/1500], Loss: 0.000900\n",
      "tensor(0.0216, device='cuda:0')\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.707065 for selected strength\n",
      "We have a total strength of 3.480739 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.513460\n",
      "Epoch [40/1500], Loss: 0.476283\n",
      "Epoch [60/1500], Loss: 0.448216\n",
      "Epoch [80/1500], Loss: 0.418801\n",
      "Epoch [100/1500], Loss: 0.387893\n",
      "Epoch [120/1500], Loss: 0.364147\n",
      "Epoch [140/1500], Loss: 0.341274\n",
      "Epoch [160/1500], Loss: 0.315061\n",
      "Epoch [180/1500], Loss: 0.287271\n",
      "Epoch [200/1500], Loss: 0.267940\n",
      "Epoch [220/1500], Loss: 0.244080\n",
      "Epoch [240/1500], Loss: 0.224501\n",
      "Epoch [260/1500], Loss: 0.202308\n",
      "Epoch [280/1500], Loss: 0.184092\n",
      "Epoch [300/1500], Loss: 0.164946\n",
      "Epoch [320/1500], Loss: 0.136793\n",
      "Epoch [340/1500], Loss: 0.124204\n",
      "Epoch [360/1500], Loss: 0.117671\n",
      "Epoch [380/1500], Loss: 0.108682\n",
      "Epoch [400/1500], Loss: 0.099951\n",
      "Epoch [420/1500], Loss: 0.090545\n",
      "Epoch [440/1500], Loss: 0.081110\n",
      "Epoch [460/1500], Loss: 0.072190\n",
      "Epoch [480/1500], Loss: 0.062488\n",
      "Epoch [500/1500], Loss: 0.054385\n",
      "Epoch [520/1500], Loss: 0.047345\n",
      "Epoch [540/1500], Loss: 0.038686\n",
      "Epoch [560/1500], Loss: 0.031767\n",
      "Epoch [580/1500], Loss: 0.026335\n",
      "Epoch [600/1500], Loss: 0.021146\n",
      "Epoch [620/1500], Loss: 0.016315\n",
      "Epoch [640/1500], Loss: 0.014244\n",
      "Epoch [660/1500], Loss: 0.012573\n",
      "Epoch [680/1500], Loss: 0.010929\n",
      "Epoch [700/1500], Loss: 0.009135\n",
      "Epoch [720/1500], Loss: 0.008130\n",
      "Epoch [740/1500], Loss: 0.007022\n",
      "Epoch [760/1500], Loss: 0.005675\n",
      "Epoch [780/1500], Loss: 0.005915\n",
      "Epoch [800/1500], Loss: 0.005898\n",
      "Epoch [820/1500], Loss: 0.005351\n",
      "Epoch [840/1500], Loss: 0.003873\n",
      "Epoch [860/1500], Loss: 0.003741\n",
      "Epoch [880/1500], Loss: 0.004030\n",
      "Epoch [900/1500], Loss: 0.003707\n",
      "Epoch [920/1500], Loss: 0.002492\n",
      "Epoch [940/1500], Loss: 0.002696\n",
      "Epoch [960/1500], Loss: 0.001841\n",
      "Epoch [980/1500], Loss: 0.001938\n",
      "Epoch [1000/1500], Loss: 0.002446\n",
      "Epoch [1020/1500], Loss: 0.002194\n",
      "Epoch [1040/1500], Loss: 0.001834\n",
      "Epoch [1060/1500], Loss: 0.001924\n",
      "Epoch [1080/1500], Loss: 0.002092\n",
      "Epoch [1100/1500], Loss: 0.001542\n",
      "Epoch [1120/1500], Loss: 0.002277\n",
      "Epoch [1140/1500], Loss: 0.001728\n",
      "Epoch [1160/1500], Loss: 0.001701\n",
      "Epoch [1180/1500], Loss: 0.001678\n",
      "Epoch [1200/1500], Loss: 0.001791\n",
      "Epoch [1220/1500], Loss: 0.001415\n",
      "Epoch [1240/1500], Loss: 0.001337\n",
      "Epoch [1260/1500], Loss: 0.001284\n",
      "Epoch [1280/1500], Loss: 0.001272\n",
      "Epoch [1300/1500], Loss: 0.001269\n",
      "Epoch [1320/1500], Loss: 0.001269\n",
      "Epoch [1340/1500], Loss: 0.001269\n",
      "Epoch [1360/1500], Loss: 0.001269\n",
      "Epoch [1380/1500], Loss: 0.001268\n",
      "Epoch [1400/1500], Loss: 0.001268\n",
      "Epoch [1420/1500], Loss: 0.001268\n",
      "Epoch [1440/1500], Loss: 0.001268\n",
      "Epoch [1460/1500], Loss: 0.001268\n",
      "Epoch [1480/1500], Loss: 0.001268\n",
      "Epoch [1500/1500], Loss: 0.001268\n",
      "tensor(0.0389, device='cuda:0')\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.068989 for selected strength\n",
      "We have a total strength of 4.625931 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.508458\n",
      "Epoch [40/1500], Loss: 0.472190\n",
      "Epoch [60/1500], Loss: 0.444169\n",
      "Epoch [80/1500], Loss: 0.418948\n",
      "Epoch [100/1500], Loss: 0.394637\n",
      "Epoch [120/1500], Loss: 0.364317\n",
      "Epoch [140/1500], Loss: 0.343151\n",
      "Epoch [160/1500], Loss: 0.317117\n",
      "Epoch [180/1500], Loss: 0.293485\n",
      "Epoch [200/1500], Loss: 0.271435\n",
      "Epoch [220/1500], Loss: 0.250353\n",
      "Epoch [240/1500], Loss: 0.226418\n",
      "Epoch [260/1500], Loss: 0.210242\n",
      "Epoch [280/1500], Loss: 0.188320\n",
      "Epoch [300/1500], Loss: 0.171893\n",
      "Epoch [320/1500], Loss: 0.145291\n",
      "Epoch [340/1500], Loss: 0.131024\n",
      "Epoch [360/1500], Loss: 0.126460\n",
      "Epoch [380/1500], Loss: 0.115996\n",
      "Epoch [400/1500], Loss: 0.107068\n",
      "Epoch [420/1500], Loss: 0.098491\n",
      "Epoch [440/1500], Loss: 0.088011\n",
      "Epoch [460/1500], Loss: 0.078458\n",
      "Epoch [480/1500], Loss: 0.068479\n",
      "Epoch [500/1500], Loss: 0.059305\n",
      "Epoch [520/1500], Loss: 0.051024\n",
      "Epoch [540/1500], Loss: 0.044057\n",
      "Epoch [560/1500], Loss: 0.036375\n",
      "Epoch [580/1500], Loss: 0.029919\n",
      "Epoch [600/1500], Loss: 0.023977\n",
      "Epoch [620/1500], Loss: 0.018696\n",
      "Epoch [640/1500], Loss: 0.016564\n",
      "Epoch [660/1500], Loss: 0.013695\n",
      "Epoch [680/1500], Loss: 0.012159\n",
      "Epoch [700/1500], Loss: 0.010885\n",
      "Epoch [720/1500], Loss: 0.009295\n",
      "Epoch [740/1500], Loss: 0.008227\n",
      "Epoch [760/1500], Loss: 0.007087\n",
      "Epoch [780/1500], Loss: 0.005864\n",
      "Epoch [800/1500], Loss: 0.004951\n",
      "Epoch [820/1500], Loss: 0.005695\n",
      "Epoch [840/1500], Loss: 0.004677\n",
      "Epoch [860/1500], Loss: 0.003704\n",
      "Epoch [880/1500], Loss: 0.003946\n",
      "Epoch [900/1500], Loss: 0.004630\n",
      "Epoch [920/1500], Loss: 0.002645\n",
      "Epoch [940/1500], Loss: 0.002626\n",
      "Epoch [960/1500], Loss: 0.002596\n",
      "Epoch [980/1500], Loss: 0.002307\n",
      "Epoch [1000/1500], Loss: 0.002374\n",
      "Epoch [1020/1500], Loss: 0.002155\n",
      "Epoch [1040/1500], Loss: 0.002822\n",
      "Epoch [1060/1500], Loss: 0.002325\n",
      "Epoch [1080/1500], Loss: 0.002281\n",
      "Epoch [1100/1500], Loss: 0.002125\n",
      "Epoch [1120/1500], Loss: 0.002349\n",
      "Epoch [1140/1500], Loss: 0.001923\n",
      "Epoch [1160/1500], Loss: 0.001613\n",
      "Epoch [1180/1500], Loss: 0.002124\n",
      "Epoch [1200/1500], Loss: 0.002115\n",
      "Epoch [1220/1500], Loss: 0.001567\n",
      "Epoch [1240/1500], Loss: 0.001448\n",
      "Epoch [1260/1500], Loss: 0.001389\n",
      "Epoch [1280/1500], Loss: 0.001378\n",
      "Epoch [1300/1500], Loss: 0.001365\n",
      "Epoch [1320/1500], Loss: 0.001358\n",
      "Epoch [1340/1500], Loss: 0.001356\n",
      "Epoch [1360/1500], Loss: 0.001355\n",
      "Epoch [1380/1500], Loss: 0.001355\n",
      "Epoch [1400/1500], Loss: 0.001354\n",
      "Epoch [1420/1500], Loss: 0.001354\n",
      "Epoch [1440/1500], Loss: 0.001354\n",
      "Epoch [1460/1500], Loss: 0.001354\n",
      "Epoch [1480/1500], Loss: 0.001354\n",
      "Epoch [1500/1500], Loss: 0.001354\n",
      "tensor(0.0404, device='cuda:0')\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.302884 for selected strength\n",
      "We have a total strength of 5.029862 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.505390\n",
      "Epoch [40/1500], Loss: 0.463359\n",
      "Epoch [60/1500], Loss: 0.434709\n",
      "Epoch [80/1500], Loss: 0.398252\n",
      "Epoch [100/1500], Loss: 0.368983\n",
      "Epoch [120/1500], Loss: 0.338568\n",
      "Epoch [140/1500], Loss: 0.310606\n",
      "Epoch [160/1500], Loss: 0.281596\n",
      "Epoch [180/1500], Loss: 0.256796\n",
      "Epoch [200/1500], Loss: 0.231742\n",
      "Epoch [220/1500], Loss: 0.206244\n",
      "Epoch [240/1500], Loss: 0.185740\n",
      "Epoch [260/1500], Loss: 0.163762\n",
      "Epoch [280/1500], Loss: 0.144738\n",
      "Epoch [300/1500], Loss: 0.126118\n",
      "Epoch [320/1500], Loss: 0.103350\n",
      "Epoch [340/1500], Loss: 0.093452\n",
      "Epoch [360/1500], Loss: 0.085041\n",
      "Epoch [380/1500], Loss: 0.076173\n",
      "Epoch [400/1500], Loss: 0.066334\n",
      "Epoch [420/1500], Loss: 0.057308\n",
      "Epoch [440/1500], Loss: 0.049524\n",
      "Epoch [460/1500], Loss: 0.040476\n",
      "Epoch [480/1500], Loss: 0.033160\n",
      "Epoch [500/1500], Loss: 0.027222\n",
      "Epoch [520/1500], Loss: 0.021200\n",
      "Epoch [540/1500], Loss: 0.017470\n",
      "Epoch [560/1500], Loss: 0.014055\n",
      "Epoch [580/1500], Loss: 0.012773\n",
      "Epoch [600/1500], Loss: 0.009656\n",
      "Epoch [620/1500], Loss: 0.008437\n",
      "Epoch [640/1500], Loss: 0.006791\n",
      "Epoch [660/1500], Loss: 0.006697\n",
      "Epoch [680/1500], Loss: 0.005817\n",
      "Epoch [700/1500], Loss: 0.004990\n",
      "Epoch [720/1500], Loss: 0.004827\n",
      "Epoch [740/1500], Loss: 0.004057\n",
      "Epoch [760/1500], Loss: 0.005126\n",
      "Epoch [780/1500], Loss: 0.004712\n",
      "Epoch [800/1500], Loss: 0.003769\n",
      "Epoch [820/1500], Loss: 0.003593\n",
      "Epoch [840/1500], Loss: 0.003978\n",
      "Epoch [860/1500], Loss: 0.002786\n",
      "Epoch [880/1500], Loss: 0.002207\n",
      "Epoch [900/1500], Loss: 0.003729\n",
      "Epoch [920/1500], Loss: 0.001812\n",
      "Epoch [940/1500], Loss: 0.001854\n",
      "Epoch [960/1500], Loss: 0.001931\n",
      "Epoch [980/1500], Loss: 0.001683\n",
      "Epoch [1000/1500], Loss: 0.002151\n",
      "Epoch [1020/1500], Loss: 0.001416\n",
      "Epoch [1040/1500], Loss: 0.001688\n",
      "Epoch [1060/1500], Loss: 0.001550\n",
      "Epoch [1080/1500], Loss: 0.001817\n",
      "Epoch [1100/1500], Loss: 0.001607\n",
      "Epoch [1120/1500], Loss: 0.001599\n",
      "Epoch [1140/1500], Loss: 0.001448\n",
      "Epoch [1160/1500], Loss: 0.001159\n",
      "Epoch [1180/1500], Loss: 0.001648\n",
      "Epoch [1200/1500], Loss: 0.001316\n",
      "Epoch [1220/1500], Loss: 0.000962\n",
      "Epoch [1240/1500], Loss: 0.000918\n",
      "Epoch [1260/1500], Loss: 0.000906\n",
      "Epoch [1280/1500], Loss: 0.000891\n",
      "Epoch [1300/1500], Loss: 0.000889\n",
      "Epoch [1320/1500], Loss: 0.000886\n",
      "Epoch [1340/1500], Loss: 0.000885\n",
      "Epoch [1360/1500], Loss: 0.000885\n",
      "Epoch [1380/1500], Loss: 0.000885\n",
      "Epoch [1400/1500], Loss: 0.000885\n",
      "Epoch [1420/1500], Loss: 0.000885\n",
      "Epoch [1440/1500], Loss: 0.000885\n",
      "Epoch [1460/1500], Loss: 0.000885\n",
      "Epoch [1480/1500], Loss: 0.000885\n",
      "Epoch [1500/1500], Loss: 0.000885\n",
      "tensor(0.0145, device='cuda:0')\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.830112 for selected strength\n",
      "We have a total strength of 3.533805 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.500507\n",
      "Epoch [40/1500], Loss: 0.467648\n",
      "Epoch [60/1500], Loss: 0.434432\n",
      "Epoch [80/1500], Loss: 0.408845\n",
      "Epoch [100/1500], Loss: 0.376720\n",
      "Epoch [120/1500], Loss: 0.354329\n",
      "Epoch [140/1500], Loss: 0.323685\n",
      "Epoch [160/1500], Loss: 0.296395\n",
      "Epoch [180/1500], Loss: 0.273074\n",
      "Epoch [200/1500], Loss: 0.250242\n",
      "Epoch [220/1500], Loss: 0.225461\n",
      "Epoch [240/1500], Loss: 0.204522\n",
      "Epoch [260/1500], Loss: 0.181129\n",
      "Epoch [280/1500], Loss: 0.162632\n",
      "Epoch [300/1500], Loss: 0.143914\n",
      "Epoch [320/1500], Loss: 0.118379\n",
      "Epoch [340/1500], Loss: 0.108186\n",
      "Epoch [360/1500], Loss: 0.099967\n",
      "Epoch [380/1500], Loss: 0.090508\n",
      "Epoch [400/1500], Loss: 0.081097\n",
      "Epoch [420/1500], Loss: 0.070729\n",
      "Epoch [440/1500], Loss: 0.062689\n",
      "Epoch [460/1500], Loss: 0.053890\n",
      "Epoch [480/1500], Loss: 0.045365\n",
      "Epoch [500/1500], Loss: 0.037487\n",
      "Epoch [520/1500], Loss: 0.031027\n",
      "Epoch [540/1500], Loss: 0.023912\n",
      "Epoch [560/1500], Loss: 0.019878\n",
      "Epoch [580/1500], Loss: 0.016675\n",
      "Epoch [600/1500], Loss: 0.012979\n",
      "Epoch [620/1500], Loss: 0.011311\n",
      "Epoch [640/1500], Loss: 0.009648\n",
      "Epoch [660/1500], Loss: 0.008555\n",
      "Epoch [680/1500], Loss: 0.007136\n",
      "Epoch [700/1500], Loss: 0.006241\n",
      "Epoch [720/1500], Loss: 0.006268\n",
      "Epoch [740/1500], Loss: 0.004477\n",
      "Epoch [760/1500], Loss: 0.004312\n",
      "Epoch [780/1500], Loss: 0.004970\n",
      "Epoch [800/1500], Loss: 0.003420\n",
      "Epoch [820/1500], Loss: 0.004998\n",
      "Epoch [840/1500], Loss: 0.004047\n",
      "Epoch [860/1500], Loss: 0.004503\n",
      "Epoch [880/1500], Loss: 0.003969\n",
      "Epoch [900/1500], Loss: 0.003577\n",
      "Epoch [920/1500], Loss: 0.002189\n",
      "Epoch [940/1500], Loss: 0.002362\n",
      "Epoch [960/1500], Loss: 0.002164\n",
      "Epoch [980/1500], Loss: 0.001720\n",
      "Epoch [1000/1500], Loss: 0.001628\n",
      "Epoch [1020/1500], Loss: 0.001684\n",
      "Epoch [1040/1500], Loss: 0.001594\n",
      "Epoch [1060/1500], Loss: 0.001744\n",
      "Epoch [1080/1500], Loss: 0.001781\n",
      "Epoch [1100/1500], Loss: 0.001570\n",
      "Epoch [1120/1500], Loss: 0.001667\n",
      "Epoch [1140/1500], Loss: 0.001580\n",
      "Epoch [1160/1500], Loss: 0.001340\n",
      "Epoch [1180/1500], Loss: 0.001529\n",
      "Epoch [1200/1500], Loss: 0.001316\n",
      "Epoch [1220/1500], Loss: 0.001039\n",
      "Epoch [1240/1500], Loss: 0.000929\n",
      "Epoch [1260/1500], Loss: 0.000916\n",
      "Epoch [1280/1500], Loss: 0.000885\n",
      "Epoch [1300/1500], Loss: 0.000898\n",
      "Epoch [1320/1500], Loss: 0.000879\n",
      "Epoch [1340/1500], Loss: 0.000876\n",
      "Epoch [1360/1500], Loss: 0.000875\n",
      "Epoch [1380/1500], Loss: 0.000875\n",
      "Epoch [1400/1500], Loss: 0.000875\n",
      "Epoch [1420/1500], Loss: 0.000875\n",
      "Epoch [1440/1500], Loss: 0.000875\n",
      "Epoch [1460/1500], Loss: 0.000875\n",
      "Epoch [1480/1500], Loss: 0.000875\n",
      "Epoch [1500/1500], Loss: 0.000875\n",
      "tensor(0.0207, device='cuda:0')\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.691366 for selected strength\n",
      "We have a total strength of 3.346871 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.506809\n",
      "Epoch [40/1500], Loss: 0.463981\n",
      "Epoch [60/1500], Loss: 0.442208\n",
      "Epoch [80/1500], Loss: 0.410620\n",
      "Epoch [100/1500], Loss: 0.386446\n",
      "Epoch [120/1500], Loss: 0.354373\n",
      "Epoch [140/1500], Loss: 0.329554\n",
      "Epoch [160/1500], Loss: 0.303813\n",
      "Epoch [180/1500], Loss: 0.282031\n",
      "Epoch [200/1500], Loss: 0.255711\n",
      "Epoch [220/1500], Loss: 0.232162\n",
      "Epoch [240/1500], Loss: 0.212549\n",
      "Epoch [260/1500], Loss: 0.194599\n",
      "Epoch [280/1500], Loss: 0.170888\n",
      "Epoch [300/1500], Loss: 0.154378\n",
      "Epoch [320/1500], Loss: 0.127494\n",
      "Epoch [340/1500], Loss: 0.116359\n",
      "Epoch [360/1500], Loss: 0.108223\n",
      "Epoch [380/1500], Loss: 0.100530\n",
      "Epoch [400/1500], Loss: 0.089707\n",
      "Epoch [420/1500], Loss: 0.080423\n",
      "Epoch [440/1500], Loss: 0.072177\n",
      "Epoch [460/1500], Loss: 0.062615\n",
      "Epoch [480/1500], Loss: 0.053293\n",
      "Epoch [500/1500], Loss: 0.045475\n",
      "Epoch [520/1500], Loss: 0.038046\n",
      "Epoch [540/1500], Loss: 0.030131\n",
      "Epoch [560/1500], Loss: 0.024028\n",
      "Epoch [580/1500], Loss: 0.019450\n",
      "Epoch [600/1500], Loss: 0.015809\n",
      "Epoch [620/1500], Loss: 0.012539\n",
      "Epoch [640/1500], Loss: 0.010746\n",
      "Epoch [660/1500], Loss: 0.009103\n",
      "Epoch [680/1500], Loss: 0.007492\n",
      "Epoch [700/1500], Loss: 0.006876\n",
      "Epoch [720/1500], Loss: 0.005783\n",
      "Epoch [740/1500], Loss: 0.005488\n",
      "Epoch [760/1500], Loss: 0.004134\n",
      "Epoch [780/1500], Loss: 0.005034\n",
      "Epoch [800/1500], Loss: 0.004300\n",
      "Epoch [820/1500], Loss: 0.003222\n",
      "Epoch [840/1500], Loss: 0.004185\n",
      "Epoch [860/1500], Loss: 0.003807\n",
      "Epoch [880/1500], Loss: 0.003342\n",
      "Epoch [900/1500], Loss: 0.003040\n",
      "Epoch [920/1500], Loss: 0.001671\n",
      "Epoch [940/1500], Loss: 0.002288\n",
      "Epoch [960/1500], Loss: 0.002258\n",
      "Epoch [980/1500], Loss: 0.001628\n",
      "Epoch [1000/1500], Loss: 0.001800\n",
      "Epoch [1020/1500], Loss: 0.001905\n",
      "Epoch [1040/1500], Loss: 0.001421\n",
      "Epoch [1060/1500], Loss: 0.001850\n",
      "Epoch [1080/1500], Loss: 0.001851\n",
      "Epoch [1100/1500], Loss: 0.001753\n",
      "Epoch [1120/1500], Loss: 0.002074\n",
      "Epoch [1140/1500], Loss: 0.001755\n",
      "Epoch [1160/1500], Loss: 0.001446\n",
      "Epoch [1180/1500], Loss: 0.001575\n",
      "Epoch [1200/1500], Loss: 0.001783\n",
      "Epoch [1220/1500], Loss: 0.001173\n",
      "Epoch [1240/1500], Loss: 0.001073\n",
      "Epoch [1260/1500], Loss: 0.001052\n",
      "Epoch [1280/1500], Loss: 0.001051\n",
      "Epoch [1300/1500], Loss: 0.001046\n",
      "Epoch [1320/1500], Loss: 0.001040\n",
      "Epoch [1340/1500], Loss: 0.001025\n",
      "Epoch [1360/1500], Loss: 0.001023\n",
      "Epoch [1380/1500], Loss: 0.001023\n",
      "Epoch [1400/1500], Loss: 0.001023\n",
      "Epoch [1420/1500], Loss: 0.001022\n",
      "Epoch [1440/1500], Loss: 0.001022\n",
      "Epoch [1460/1500], Loss: 0.001022\n",
      "Epoch [1480/1500], Loss: 0.001022\n",
      "Epoch [1500/1500], Loss: 0.001022\n",
      "tensor(0.0496, device='cuda:0')\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.945082 for selected strength\n",
      "We have a total strength of 3.892884 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.514670\n",
      "Epoch [40/1500], Loss: 0.469001\n",
      "Epoch [60/1500], Loss: 0.442538\n",
      "Epoch [80/1500], Loss: 0.420016\n",
      "Epoch [100/1500], Loss: 0.387639\n",
      "Epoch [120/1500], Loss: 0.355792\n",
      "Epoch [140/1500], Loss: 0.326082\n",
      "Epoch [160/1500], Loss: 0.305598\n",
      "Epoch [180/1500], Loss: 0.276881\n",
      "Epoch [200/1500], Loss: 0.254641\n",
      "Epoch [220/1500], Loss: 0.230052\n",
      "Epoch [240/1500], Loss: 0.208575\n",
      "Epoch [260/1500], Loss: 0.187576\n",
      "Epoch [280/1500], Loss: 0.165864\n",
      "Epoch [300/1500], Loss: 0.149089\n",
      "Epoch [320/1500], Loss: 0.122900\n",
      "Epoch [340/1500], Loss: 0.111734\n",
      "Epoch [360/1500], Loss: 0.103573\n",
      "Epoch [380/1500], Loss: 0.093507\n",
      "Epoch [400/1500], Loss: 0.083752\n",
      "Epoch [420/1500], Loss: 0.073941\n",
      "Epoch [440/1500], Loss: 0.065119\n",
      "Epoch [460/1500], Loss: 0.056464\n",
      "Epoch [480/1500], Loss: 0.047643\n",
      "Epoch [500/1500], Loss: 0.038991\n",
      "Epoch [520/1500], Loss: 0.031452\n",
      "Epoch [540/1500], Loss: 0.025305\n",
      "Epoch [560/1500], Loss: 0.020842\n",
      "Epoch [580/1500], Loss: 0.016796\n",
      "Epoch [600/1500], Loss: 0.014602\n",
      "Epoch [620/1500], Loss: 0.011479\n",
      "Epoch [640/1500], Loss: 0.009577\n",
      "Epoch [660/1500], Loss: 0.008315\n",
      "Epoch [680/1500], Loss: 0.007117\n",
      "Epoch [700/1500], Loss: 0.006634\n",
      "Epoch [720/1500], Loss: 0.005368\n",
      "Epoch [740/1500], Loss: 0.005648\n",
      "Epoch [760/1500], Loss: 0.004863\n",
      "Epoch [780/1500], Loss: 0.004747\n",
      "Epoch [800/1500], Loss: 0.004966\n",
      "Epoch [820/1500], Loss: 0.004018\n",
      "Epoch [840/1500], Loss: 0.003883\n",
      "Epoch [860/1500], Loss: 0.004132\n",
      "Epoch [880/1500], Loss: 0.003611\n",
      "Epoch [900/1500], Loss: 0.002432\n",
      "Epoch [920/1500], Loss: 0.001760\n",
      "Epoch [940/1500], Loss: 0.001985\n",
      "Epoch [960/1500], Loss: 0.002518\n",
      "Epoch [980/1500], Loss: 0.002044\n",
      "Epoch [1000/1500], Loss: 0.001487\n",
      "Epoch [1020/1500], Loss: 0.001540\n",
      "Epoch [1040/1500], Loss: 0.001662\n",
      "Epoch [1060/1500], Loss: 0.001669\n",
      "Epoch [1080/1500], Loss: 0.001642\n",
      "Epoch [1100/1500], Loss: 0.001821\n",
      "Epoch [1120/1500], Loss: 0.001499\n",
      "Epoch [1140/1500], Loss: 0.001555\n",
      "Epoch [1160/1500], Loss: 0.001502\n",
      "Epoch [1180/1500], Loss: 0.001737\n",
      "Epoch [1200/1500], Loss: 0.001497\n",
      "Epoch [1220/1500], Loss: 0.001315\n",
      "Epoch [1240/1500], Loss: 0.001258\n",
      "Epoch [1260/1500], Loss: 0.001245\n",
      "Epoch [1280/1500], Loss: 0.001243\n",
      "Epoch [1300/1500], Loss: 0.001243\n",
      "Epoch [1320/1500], Loss: 0.001243\n",
      "Epoch [1340/1500], Loss: 0.001243\n",
      "Epoch [1360/1500], Loss: 0.001243\n",
      "Epoch [1380/1500], Loss: 0.001243\n",
      "Epoch [1400/1500], Loss: 0.001243\n",
      "Epoch [1420/1500], Loss: 0.001243\n",
      "Epoch [1440/1500], Loss: 0.001243\n",
      "Epoch [1460/1500], Loss: 0.001243\n",
      "Epoch [1480/1500], Loss: 0.001243\n",
      "Epoch [1500/1500], Loss: 0.001243\n",
      "tensor(0.0214, device='cuda:0')\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.750261 for selected strength\n",
      "We have a total strength of 3.684752 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.506703\n",
      "Epoch [40/1500], Loss: 0.467233\n",
      "Epoch [60/1500], Loss: 0.436778\n",
      "Epoch [80/1500], Loss: 0.411223\n",
      "Epoch [100/1500], Loss: 0.385796\n",
      "Epoch [120/1500], Loss: 0.350836\n",
      "Epoch [140/1500], Loss: 0.324611\n",
      "Epoch [160/1500], Loss: 0.299136\n",
      "Epoch [180/1500], Loss: 0.277008\n",
      "Epoch [200/1500], Loss: 0.252902\n",
      "Epoch [220/1500], Loss: 0.229942\n",
      "Epoch [240/1500], Loss: 0.209043\n",
      "Epoch [260/1500], Loss: 0.187803\n",
      "Epoch [280/1500], Loss: 0.166687\n",
      "Epoch [300/1500], Loss: 0.147568\n",
      "Epoch [320/1500], Loss: 0.121190\n",
      "Epoch [340/1500], Loss: 0.110796\n",
      "Epoch [360/1500], Loss: 0.102960\n",
      "Epoch [380/1500], Loss: 0.094181\n",
      "Epoch [400/1500], Loss: 0.084018\n",
      "Epoch [420/1500], Loss: 0.074466\n",
      "Epoch [440/1500], Loss: 0.065224\n",
      "Epoch [460/1500], Loss: 0.056452\n",
      "Epoch [480/1500], Loss: 0.047881\n",
      "Epoch [500/1500], Loss: 0.039130\n",
      "Epoch [520/1500], Loss: 0.031971\n",
      "Epoch [540/1500], Loss: 0.025973\n",
      "Epoch [560/1500], Loss: 0.020353\n",
      "Epoch [580/1500], Loss: 0.016840\n",
      "Epoch [600/1500], Loss: 0.013524\n",
      "Epoch [620/1500], Loss: 0.011015\n",
      "Epoch [640/1500], Loss: 0.009224\n",
      "Epoch [660/1500], Loss: 0.008156\n",
      "Epoch [680/1500], Loss: 0.007060\n",
      "Epoch [700/1500], Loss: 0.006077\n",
      "Epoch [720/1500], Loss: 0.005438\n",
      "Epoch [740/1500], Loss: 0.004358\n",
      "Epoch [760/1500], Loss: 0.004076\n",
      "Epoch [780/1500], Loss: 0.004393\n",
      "Epoch [800/1500], Loss: 0.003384\n",
      "Epoch [820/1500], Loss: 0.003238\n",
      "Epoch [840/1500], Loss: 0.003574\n",
      "Epoch [860/1500], Loss: 0.002682\n",
      "Epoch [880/1500], Loss: 0.003546\n",
      "Epoch [900/1500], Loss: 0.002671\n",
      "Epoch [920/1500], Loss: 0.001870\n",
      "Epoch [940/1500], Loss: 0.002094\n",
      "Epoch [960/1500], Loss: 0.001623\n",
      "Epoch [980/1500], Loss: 0.002263\n",
      "Epoch [1000/1500], Loss: 0.002283\n",
      "Epoch [1020/1500], Loss: 0.002036\n",
      "Epoch [1040/1500], Loss: 0.002007\n",
      "Epoch [1060/1500], Loss: 0.001530\n",
      "Epoch [1080/1500], Loss: 0.001810\n",
      "Epoch [1100/1500], Loss: 0.001502\n",
      "Epoch [1120/1500], Loss: 0.001533\n",
      "Epoch [1140/1500], Loss: 0.001657\n",
      "Epoch [1160/1500], Loss: 0.002075\n",
      "Epoch [1180/1500], Loss: 0.001983\n",
      "Epoch [1200/1500], Loss: 0.001413\n",
      "Epoch [1220/1500], Loss: 0.001480\n",
      "Epoch [1240/1500], Loss: 0.001406\n",
      "Epoch [1260/1500], Loss: 0.001377\n",
      "Epoch [1280/1500], Loss: 0.001366\n",
      "Epoch [1300/1500], Loss: 0.001365\n",
      "Epoch [1320/1500], Loss: 0.001365\n",
      "Epoch [1340/1500], Loss: 0.001365\n",
      "Epoch [1360/1500], Loss: 0.001365\n",
      "Epoch [1380/1500], Loss: 0.001365\n",
      "Epoch [1400/1500], Loss: 0.001365\n",
      "Epoch [1420/1500], Loss: 0.001365\n",
      "Epoch [1440/1500], Loss: 0.001365\n",
      "Epoch [1460/1500], Loss: 0.001365\n",
      "Epoch [1480/1500], Loss: 0.001365\n",
      "Epoch [1500/1500], Loss: 0.001365\n",
      "tensor(0.0226, device='cuda:0')\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.047659 for selected strength\n",
      "We have a total strength of 4.179643 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.513802\n",
      "Epoch [40/1500], Loss: 0.463172\n",
      "Epoch [60/1500], Loss: 0.433112\n",
      "Epoch [80/1500], Loss: 0.407233\n",
      "Epoch [100/1500], Loss: 0.375437\n",
      "Epoch [120/1500], Loss: 0.347576\n",
      "Epoch [140/1500], Loss: 0.314608\n",
      "Epoch [160/1500], Loss: 0.290460\n",
      "Epoch [180/1500], Loss: 0.263331\n",
      "Epoch [200/1500], Loss: 0.239529\n",
      "Epoch [220/1500], Loss: 0.215549\n",
      "Epoch [240/1500], Loss: 0.192579\n",
      "Epoch [260/1500], Loss: 0.172341\n",
      "Epoch [280/1500], Loss: 0.151943\n",
      "Epoch [300/1500], Loss: 0.133469\n",
      "Epoch [320/1500], Loss: 0.109936\n",
      "Epoch [340/1500], Loss: 0.100350\n",
      "Epoch [360/1500], Loss: 0.091033\n",
      "Epoch [380/1500], Loss: 0.081563\n",
      "Epoch [400/1500], Loss: 0.071917\n",
      "Epoch [420/1500], Loss: 0.062626\n",
      "Epoch [440/1500], Loss: 0.053897\n",
      "Epoch [460/1500], Loss: 0.045775\n",
      "Epoch [480/1500], Loss: 0.036892\n",
      "Epoch [500/1500], Loss: 0.030543\n",
      "Epoch [520/1500], Loss: 0.024383\n",
      "Epoch [540/1500], Loss: 0.018968\n",
      "Epoch [560/1500], Loss: 0.015337\n",
      "Epoch [580/1500], Loss: 0.012866\n",
      "Epoch [600/1500], Loss: 0.010162\n",
      "Epoch [620/1500], Loss: 0.008565\n",
      "Epoch [640/1500], Loss: 0.007783\n",
      "Epoch [660/1500], Loss: 0.006324\n",
      "Epoch [680/1500], Loss: 0.005600\n",
      "Epoch [700/1500], Loss: 0.005233\n",
      "Epoch [720/1500], Loss: 0.005297\n",
      "Epoch [740/1500], Loss: 0.003891\n",
      "Epoch [760/1500], Loss: 0.004593\n",
      "Epoch [780/1500], Loss: 0.004045\n",
      "Epoch [800/1500], Loss: 0.003182\n",
      "Epoch [820/1500], Loss: 0.003968\n",
      "Epoch [840/1500], Loss: 0.004259\n",
      "Epoch [860/1500], Loss: 0.003682\n",
      "Epoch [880/1500], Loss: 0.003056\n",
      "Epoch [900/1500], Loss: 0.002676\n",
      "Epoch [920/1500], Loss: 0.001573\n",
      "Epoch [940/1500], Loss: 0.002130\n",
      "Epoch [960/1500], Loss: 0.001624\n",
      "Epoch [980/1500], Loss: 0.001668\n",
      "Epoch [1000/1500], Loss: 0.001689\n",
      "Epoch [1020/1500], Loss: 0.001551\n",
      "Epoch [1040/1500], Loss: 0.001433\n",
      "Epoch [1060/1500], Loss: 0.001813\n",
      "Epoch [1080/1500], Loss: 0.001703\n",
      "Epoch [1100/1500], Loss: 0.001641\n",
      "Epoch [1120/1500], Loss: 0.001451\n",
      "Epoch [1140/1500], Loss: 0.001119\n",
      "Epoch [1160/1500], Loss: 0.001386\n",
      "Epoch [1180/1500], Loss: 0.001156\n",
      "Epoch [1200/1500], Loss: 0.001270\n",
      "Epoch [1220/1500], Loss: 0.001073\n",
      "Epoch [1240/1500], Loss: 0.001014\n",
      "Epoch [1260/1500], Loss: 0.001002\n",
      "Epoch [1280/1500], Loss: 0.000994\n",
      "Epoch [1300/1500], Loss: 0.000981\n",
      "Epoch [1320/1500], Loss: 0.000980\n",
      "Epoch [1340/1500], Loss: 0.000980\n",
      "Epoch [1360/1500], Loss: 0.000979\n",
      "Epoch [1380/1500], Loss: 0.000979\n",
      "Epoch [1400/1500], Loss: 0.000979\n",
      "Epoch [1420/1500], Loss: 0.000979\n",
      "Epoch [1440/1500], Loss: 0.000979\n",
      "Epoch [1460/1500], Loss: 0.000979\n",
      "Epoch [1480/1500], Loss: 0.000979\n",
      "Epoch [1500/1500], Loss: 0.000979\n",
      "tensor(0.0320, device='cuda:0')\n",
      "tensor(0.0264, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.873741 for selected strength\n",
      "We have a total strength of 3.562618 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.530542\n",
      "Epoch [40/1500], Loss: 0.466632\n",
      "Epoch [60/1500], Loss: 0.440253\n",
      "Epoch [80/1500], Loss: 0.409991\n",
      "Epoch [100/1500], Loss: 0.381807\n",
      "Epoch [120/1500], Loss: 0.356418\n",
      "Epoch [140/1500], Loss: 0.330068\n",
      "Epoch [160/1500], Loss: 0.303552\n",
      "Epoch [180/1500], Loss: 0.280459\n",
      "Epoch [200/1500], Loss: 0.258314\n",
      "Epoch [220/1500], Loss: 0.235150\n",
      "Epoch [240/1500], Loss: 0.213877\n",
      "Epoch [260/1500], Loss: 0.192893\n",
      "Epoch [280/1500], Loss: 0.173573\n",
      "Epoch [300/1500], Loss: 0.154003\n",
      "Epoch [320/1500], Loss: 0.127436\n",
      "Epoch [340/1500], Loss: 0.117547\n",
      "Epoch [360/1500], Loss: 0.110920\n",
      "Epoch [380/1500], Loss: 0.100259\n",
      "Epoch [400/1500], Loss: 0.089337\n",
      "Epoch [420/1500], Loss: 0.080180\n",
      "Epoch [440/1500], Loss: 0.071850\n",
      "Epoch [460/1500], Loss: 0.063098\n",
      "Epoch [480/1500], Loss: 0.054417\n",
      "Epoch [500/1500], Loss: 0.045692\n",
      "Epoch [520/1500], Loss: 0.037749\n",
      "Epoch [540/1500], Loss: 0.031226\n",
      "Epoch [560/1500], Loss: 0.025766\n",
      "Epoch [580/1500], Loss: 0.021767\n",
      "Epoch [600/1500], Loss: 0.018129\n",
      "Epoch [620/1500], Loss: 0.015434\n",
      "Epoch [640/1500], Loss: 0.013466\n",
      "Epoch [660/1500], Loss: 0.011710\n",
      "Epoch [680/1500], Loss: 0.010299\n",
      "Epoch [700/1500], Loss: 0.009568\n",
      "Epoch [720/1500], Loss: 0.007986\n",
      "Epoch [740/1500], Loss: 0.007129\n",
      "Epoch [760/1500], Loss: 0.006534\n",
      "Epoch [780/1500], Loss: 0.006453\n",
      "Epoch [800/1500], Loss: 0.005068\n",
      "Epoch [820/1500], Loss: 0.005699\n",
      "Epoch [840/1500], Loss: 0.005055\n",
      "Epoch [860/1500], Loss: 0.004965\n",
      "Epoch [880/1500], Loss: 0.005083\n",
      "Epoch [900/1500], Loss: 0.003156\n",
      "Epoch [920/1500], Loss: 0.002616\n",
      "Epoch [940/1500], Loss: 0.002946\n",
      "Epoch [960/1500], Loss: 0.002458\n",
      "Epoch [980/1500], Loss: 0.002320\n",
      "Epoch [1000/1500], Loss: 0.001744\n",
      "Epoch [1020/1500], Loss: 0.001929\n",
      "Epoch [1040/1500], Loss: 0.001880\n",
      "Epoch [1060/1500], Loss: 0.002477\n",
      "Epoch [1080/1500], Loss: 0.001677\n",
      "Epoch [1100/1500], Loss: 0.001902\n",
      "Epoch [1120/1500], Loss: 0.002234\n",
      "Epoch [1140/1500], Loss: 0.001570\n",
      "Epoch [1160/1500], Loss: 0.001829\n",
      "Epoch [1180/1500], Loss: 0.001642\n",
      "Epoch [1200/1500], Loss: 0.001462\n",
      "Epoch [1220/1500], Loss: 0.001517\n",
      "Epoch [1240/1500], Loss: 0.001409\n",
      "Epoch [1260/1500], Loss: 0.001372\n",
      "Epoch [1280/1500], Loss: 0.001367\n",
      "Epoch [1300/1500], Loss: 0.001366\n",
      "Epoch [1320/1500], Loss: 0.001366\n",
      "Epoch [1340/1500], Loss: 0.001366\n",
      "Epoch [1360/1500], Loss: 0.001366\n",
      "Epoch [1380/1500], Loss: 0.001366\n",
      "Epoch [1400/1500], Loss: 0.001366\n",
      "Epoch [1420/1500], Loss: 0.001366\n",
      "Epoch [1440/1500], Loss: 0.001366\n",
      "Epoch [1460/1500], Loss: 0.001366\n",
      "Epoch [1480/1500], Loss: 0.001366\n",
      "Epoch [1500/1500], Loss: 0.001366\n",
      "tensor(0.0214, device='cuda:0')\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.064151 for selected strength\n",
      "We have a total strength of 4.688538 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.502716\n",
      "Epoch [40/1500], Loss: 0.468042\n",
      "Epoch [60/1500], Loss: 0.438491\n",
      "Epoch [80/1500], Loss: 0.413011\n",
      "Epoch [100/1500], Loss: 0.381486\n",
      "Epoch [120/1500], Loss: 0.352834\n",
      "Epoch [140/1500], Loss: 0.331810\n",
      "Epoch [160/1500], Loss: 0.307289\n",
      "Epoch [180/1500], Loss: 0.286451\n",
      "Epoch [200/1500], Loss: 0.258336\n",
      "Epoch [220/1500], Loss: 0.235656\n",
      "Epoch [240/1500], Loss: 0.215957\n",
      "Epoch [260/1500], Loss: 0.194172\n",
      "Epoch [280/1500], Loss: 0.176898\n",
      "Epoch [300/1500], Loss: 0.157764\n",
      "Epoch [320/1500], Loss: 0.129875\n",
      "Epoch [340/1500], Loss: 0.119430\n",
      "Epoch [360/1500], Loss: 0.114444\n",
      "Epoch [380/1500], Loss: 0.103225\n",
      "Epoch [400/1500], Loss: 0.093780\n",
      "Epoch [420/1500], Loss: 0.086588\n",
      "Epoch [440/1500], Loss: 0.076368\n",
      "Epoch [460/1500], Loss: 0.064913\n",
      "Epoch [480/1500], Loss: 0.055747\n",
      "Epoch [500/1500], Loss: 0.047279\n",
      "Epoch [520/1500], Loss: 0.039050\n",
      "Epoch [540/1500], Loss: 0.033352\n",
      "Epoch [560/1500], Loss: 0.026004\n",
      "Epoch [580/1500], Loss: 0.021558\n",
      "Epoch [600/1500], Loss: 0.017126\n",
      "Epoch [620/1500], Loss: 0.013877\n",
      "Epoch [640/1500], Loss: 0.011873\n",
      "Epoch [660/1500], Loss: 0.010136\n",
      "Epoch [680/1500], Loss: 0.008850\n",
      "Epoch [700/1500], Loss: 0.007695\n",
      "Epoch [720/1500], Loss: 0.006886\n",
      "Epoch [740/1500], Loss: 0.006467\n",
      "Epoch [760/1500], Loss: 0.006498\n",
      "Epoch [780/1500], Loss: 0.004873\n",
      "Epoch [800/1500], Loss: 0.004347\n",
      "Epoch [820/1500], Loss: 0.004790\n",
      "Epoch [840/1500], Loss: 0.003156\n",
      "Epoch [860/1500], Loss: 0.003014\n",
      "Epoch [880/1500], Loss: 0.004457\n",
      "Epoch [900/1500], Loss: 0.002879\n",
      "Epoch [920/1500], Loss: 0.002102\n",
      "Epoch [940/1500], Loss: 0.002200\n",
      "Epoch [960/1500], Loss: 0.001839\n",
      "Epoch [980/1500], Loss: 0.002331\n",
      "Epoch [1000/1500], Loss: 0.002169\n",
      "Epoch [1020/1500], Loss: 0.002197\n",
      "Epoch [1040/1500], Loss: 0.001688\n",
      "Epoch [1060/1500], Loss: 0.002129\n",
      "Epoch [1080/1500], Loss: 0.002283\n",
      "Epoch [1100/1500], Loss: 0.001607\n",
      "Epoch [1120/1500], Loss: 0.001862\n",
      "Epoch [1140/1500], Loss: 0.001968\n",
      "Epoch [1160/1500], Loss: 0.001764\n",
      "Epoch [1180/1500], Loss: 0.001879\n",
      "Epoch [1200/1500], Loss: 0.001686\n",
      "Epoch [1220/1500], Loss: 0.001577\n",
      "Epoch [1240/1500], Loss: 0.001479\n",
      "Epoch [1260/1500], Loss: 0.001454\n",
      "Epoch [1280/1500], Loss: 0.001437\n",
      "Epoch [1300/1500], Loss: 0.001429\n",
      "Epoch [1320/1500], Loss: 0.001416\n",
      "Epoch [1340/1500], Loss: 0.001408\n",
      "Epoch [1360/1500], Loss: 0.001407\n",
      "Epoch [1380/1500], Loss: 0.001407\n",
      "Epoch [1400/1500], Loss: 0.001406\n",
      "Epoch [1420/1500], Loss: 0.001406\n",
      "Epoch [1440/1500], Loss: 0.001406\n",
      "Epoch [1460/1500], Loss: 0.001406\n",
      "Epoch [1480/1500], Loss: 0.001406\n",
      "Epoch [1500/1500], Loss: 0.001406\n",
      "tensor(0.0291, device='cuda:0')\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.227954 for selected strength\n",
      "We have a total strength of 4.671751 for all the columns\n",
      "[3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.500178\n",
      "Epoch [40/1500], Loss: 0.462265\n",
      "Epoch [60/1500], Loss: 0.447258\n",
      "Epoch [80/1500], Loss: 0.409558\n",
      "Epoch [100/1500], Loss: 0.384231\n",
      "Epoch [120/1500], Loss: 0.351690\n",
      "Epoch [140/1500], Loss: 0.321339\n",
      "Epoch [160/1500], Loss: 0.299127\n",
      "Epoch [180/1500], Loss: 0.270655\n",
      "Epoch [200/1500], Loss: 0.246819\n",
      "Epoch [220/1500], Loss: 0.223308\n",
      "Epoch [240/1500], Loss: 0.201283\n",
      "Epoch [260/1500], Loss: 0.179547\n",
      "Epoch [280/1500], Loss: 0.161115\n",
      "Epoch [300/1500], Loss: 0.140132\n",
      "Epoch [320/1500], Loss: 0.117060\n",
      "Epoch [340/1500], Loss: 0.108993\n",
      "Epoch [360/1500], Loss: 0.097689\n",
      "Epoch [380/1500], Loss: 0.087780\n",
      "Epoch [400/1500], Loss: 0.078191\n",
      "Epoch [420/1500], Loss: 0.069333\n",
      "Epoch [440/1500], Loss: 0.059256\n",
      "Epoch [460/1500], Loss: 0.050718\n",
      "Epoch [480/1500], Loss: 0.042324\n",
      "Epoch [500/1500], Loss: 0.034517\n",
      "Epoch [520/1500], Loss: 0.027162\n",
      "Epoch [540/1500], Loss: 0.021786\n",
      "Epoch [560/1500], Loss: 0.017562\n",
      "Epoch [580/1500], Loss: 0.014353\n",
      "Epoch [600/1500], Loss: 0.013154\n",
      "Epoch [620/1500], Loss: 0.009596\n",
      "Epoch [640/1500], Loss: 0.008322\n",
      "Epoch [660/1500], Loss: 0.007409\n",
      "Epoch [680/1500], Loss: 0.006319\n",
      "Epoch [700/1500], Loss: 0.005338\n",
      "Epoch [720/1500], Loss: 0.005569\n",
      "Epoch [740/1500], Loss: 0.004952\n",
      "Epoch [760/1500], Loss: 0.003855\n",
      "Epoch [780/1500], Loss: 0.004794\n",
      "Epoch [800/1500], Loss: 0.004093\n",
      "Epoch [820/1500], Loss: 0.002445\n",
      "Epoch [840/1500], Loss: 0.003524\n",
      "Epoch [860/1500], Loss: 0.003110\n",
      "Epoch [880/1500], Loss: 0.002840\n",
      "Epoch [900/1500], Loss: 0.003439\n",
      "Epoch [920/1500], Loss: 0.001829\n",
      "Epoch [940/1500], Loss: 0.002037\n",
      "Epoch [960/1500], Loss: 0.001825\n",
      "Epoch [980/1500], Loss: 0.001950\n",
      "Epoch [1000/1500], Loss: 0.001629\n",
      "Epoch [1020/1500], Loss: 0.001975\n",
      "Epoch [1040/1500], Loss: 0.001445\n",
      "Epoch [1060/1500], Loss: 0.001622\n",
      "Epoch [1080/1500], Loss: 0.001913\n",
      "Epoch [1100/1500], Loss: 0.001846\n",
      "Epoch [1120/1500], Loss: 0.001743\n",
      "Epoch [1140/1500], Loss: 0.001805\n",
      "Epoch [1160/1500], Loss: 0.001411\n",
      "Epoch [1180/1500], Loss: 0.001808\n",
      "Epoch [1200/1500], Loss: 0.001555\n",
      "Epoch [1220/1500], Loss: 0.001404\n",
      "Epoch [1240/1500], Loss: 0.001332\n",
      "Epoch [1260/1500], Loss: 0.001319\n",
      "Epoch [1280/1500], Loss: 0.001308\n",
      "Epoch [1300/1500], Loss: 0.001307\n",
      "Epoch [1320/1500], Loss: 0.001307\n",
      "Epoch [1340/1500], Loss: 0.001307\n",
      "Epoch [1360/1500], Loss: 0.001307\n",
      "Epoch [1380/1500], Loss: 0.001307\n",
      "Epoch [1400/1500], Loss: 0.001307\n",
      "Epoch [1420/1500], Loss: 0.001307\n",
      "Epoch [1440/1500], Loss: 0.001307\n",
      "Epoch [1460/1500], Loss: 0.001307\n",
      "Epoch [1480/1500], Loss: 0.001307\n",
      "Epoch [1500/1500], Loss: 0.001307\n",
      "tensor(0.0281, device='cuda:0')\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.923080 for selected strength\n",
      "We have a total strength of 3.969113 for all the columns\n",
      " 50%|██████████████████████                      | 2/4 [06:57<06:57, 208.85s/it][3125 2368 1612  856  100]\n",
      "Epoch [20/1500], Loss: 0.508950\n"
     ]
    }
   ],
   "source": [
    "!python compute_complete_text_set.py --device cuda:0 --model ViT-B-32 --texts_per_head 100 --num_of_last_layers 4 --text_descriptions image_descriptions_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/apps/vogtlab/users/vstrozzi/software/anaconda/envs/MT/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Number of layers: 12\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 41.35it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]Epoch [20/1500], Loss: 2.088930\n",
      "Epoch [40/1500], Loss: 1.430712\n",
      "Epoch [60/1500], Loss: 0.972141\n",
      "Epoch [80/1500], Loss: 0.635344\n",
      "Epoch [100/1500], Loss: 0.389819\n",
      "Epoch [120/1500], Loss: 0.227019\n",
      "Epoch [140/1500], Loss: 0.131881\n",
      "Epoch [160/1500], Loss: 0.075046\n",
      "Epoch [180/1500], Loss: 0.042864\n",
      "Epoch [200/1500], Loss: 0.024015\n",
      "Epoch [220/1500], Loss: 0.014911\n",
      "Epoch [240/1500], Loss: 0.007019\n",
      "Epoch [260/1500], Loss: 0.004476\n",
      "Epoch [280/1500], Loss: 0.004681\n",
      "Epoch [300/1500], Loss: 0.002330\n",
      "Epoch [320/1500], Loss: 0.003541\n",
      "Epoch [340/1500], Loss: 0.003774\n",
      "Epoch [360/1500], Loss: 0.002533\n",
      "Epoch [380/1500], Loss: 0.004797\n",
      "Epoch [400/1500], Loss: 0.002225\n",
      "Epoch [420/1500], Loss: 0.004074\n",
      "Epoch [440/1500], Loss: 0.001998\n",
      "Epoch [460/1500], Loss: 0.003773\n",
      "Epoch [480/1500], Loss: 0.002419\n",
      "Epoch [500/1500], Loss: 0.005143\n",
      "Epoch [520/1500], Loss: 0.002550\n",
      "Epoch [540/1500], Loss: 0.001531\n",
      "Epoch [560/1500], Loss: 0.003128\n",
      "Epoch [580/1500], Loss: 0.001946\n",
      "Epoch [600/1500], Loss: 0.004135\n",
      "Epoch [620/1500], Loss: 0.002541\n",
      "Epoch [640/1500], Loss: 0.001874\n",
      "Epoch [660/1500], Loss: 0.003685\n",
      "Epoch [680/1500], Loss: 0.002284\n",
      "Epoch [700/1500], Loss: 0.002093\n",
      "Epoch [720/1500], Loss: 0.003195\n",
      "Epoch [740/1500], Loss: 0.002219\n",
      "Epoch [760/1500], Loss: 0.002104\n",
      "Epoch [780/1500], Loss: 0.002242\n",
      "Epoch [800/1500], Loss: 0.003087\n",
      "Epoch [820/1500], Loss: 0.001833\n",
      "Epoch [840/1500], Loss: 0.004426\n",
      "Epoch [860/1500], Loss: 0.002705\n",
      "Epoch [880/1500], Loss: 0.001970\n",
      "Epoch [900/1500], Loss: 0.004913\n",
      "Epoch [920/1500], Loss: 0.002832\n",
      "Epoch [940/1500], Loss: 0.002160\n",
      "Epoch [960/1500], Loss: 0.001851\n",
      "Epoch [980/1500], Loss: 0.003718\n",
      "Epoch [1000/1500], Loss: 0.002624\n",
      "Epoch [1020/1500], Loss: 0.002194\n",
      "Epoch [1040/1500], Loss: 0.002404\n",
      "Epoch [1060/1500], Loss: 0.002823\n",
      "Epoch [1080/1500], Loss: 0.002414\n",
      "Epoch [1100/1500], Loss: 0.001752\n",
      "Epoch [1120/1500], Loss: 0.001309\n",
      "Epoch [1140/1500], Loss: 0.001315\n",
      "Epoch [1160/1500], Loss: 0.001317\n",
      "Epoch [1180/1500], Loss: 0.001320\n",
      "Epoch [1200/1500], Loss: 0.001289\n",
      "Epoch [1220/1500], Loss: 0.001281\n",
      "Epoch [1240/1500], Loss: 0.001277\n",
      "Epoch [1260/1500], Loss: 0.001266\n",
      "Epoch [1280/1500], Loss: 0.001256\n",
      "Epoch [1300/1500], Loss: 0.001254\n",
      "Epoch [1320/1500], Loss: 0.001241\n",
      "Epoch [1340/1500], Loss: 0.001237\n",
      "Epoch [1360/1500], Loss: 0.001238\n",
      "Epoch [1380/1500], Loss: 0.001232\n",
      "Epoch [1400/1500], Loss: 0.001231\n",
      "Epoch [1420/1500], Loss: 0.001232\n",
      "Epoch [1440/1500], Loss: 0.001232\n",
      "Epoch [1460/1500], Loss: 0.001229\n",
      "Epoch [1480/1500], Loss: 0.001228\n",
      "Epoch [1500/1500], Loss: 0.001230\n",
      "tensor(0.0174, device='cuda:0')\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.267424 for selected strength\n",
      "We have a total strength of 2.474018 for all the columns\n",
      "Epoch [20/1500], Loss: 2.061595\n",
      "Epoch [40/1500], Loss: 1.394618\n",
      "Epoch [60/1500], Loss: 0.930267\n",
      "Epoch [80/1500], Loss: 0.592794\n",
      "Epoch [100/1500], Loss: 0.352501\n",
      "Epoch [120/1500], Loss: 0.199364\n",
      "Epoch [140/1500], Loss: 0.112121\n",
      "Epoch [160/1500], Loss: 0.064097\n",
      "Epoch [180/1500], Loss: 0.036778\n",
      "Epoch [200/1500], Loss: 0.019751\n",
      "Epoch [220/1500], Loss: 0.010883\n",
      "Epoch [240/1500], Loss: 0.007319\n",
      "Epoch [260/1500], Loss: 0.003298\n",
      "Epoch [280/1500], Loss: 0.004243\n",
      "Epoch [300/1500], Loss: 0.001943\n",
      "Epoch [320/1500], Loss: 0.002890\n",
      "Epoch [340/1500], Loss: 0.001389\n",
      "Epoch [360/1500], Loss: 0.003780\n",
      "Epoch [380/1500], Loss: 0.001779\n",
      "Epoch [400/1500], Loss: 0.003471\n",
      "Epoch [420/1500], Loss: 0.002547\n",
      "Epoch [440/1500], Loss: 0.001529\n",
      "Epoch [460/1500], Loss: 0.003954\n",
      "Epoch [480/1500], Loss: 0.001983\n",
      "Epoch [500/1500], Loss: 0.001584\n",
      "Epoch [520/1500], Loss: 0.003826\n",
      "Epoch [540/1500], Loss: 0.001990\n",
      "Epoch [560/1500], Loss: 0.001137\n",
      "Epoch [580/1500], Loss: 0.003149\n",
      "Epoch [600/1500], Loss: 0.001925\n",
      "Epoch [620/1500], Loss: 0.001419\n",
      "Epoch [640/1500], Loss: 0.001755\n",
      "Epoch [660/1500], Loss: 0.003746\n",
      "Epoch [680/1500], Loss: 0.001897\n",
      "Epoch [700/1500], Loss: 0.003031\n",
      "Epoch [720/1500], Loss: 0.001959\n",
      "Epoch [740/1500], Loss: 0.001986\n",
      "Epoch [760/1500], Loss: 0.001335\n",
      "Epoch [780/1500], Loss: 0.005698\n",
      "Epoch [800/1500], Loss: 0.004443\n",
      "Epoch [820/1500], Loss: 0.003594\n",
      "Epoch [840/1500], Loss: 0.003364\n",
      "Epoch [860/1500], Loss: 0.003669\n",
      "Epoch [880/1500], Loss: 0.001629\n",
      "Epoch [900/1500], Loss: 0.002103\n",
      "Epoch [920/1500], Loss: 0.001604\n",
      "Epoch [940/1500], Loss: 0.001304\n",
      "Epoch [960/1500], Loss: 0.003704\n",
      "Epoch [980/1500], Loss: 0.002376\n",
      "Epoch [1000/1500], Loss: 0.003427\n",
      "Epoch [1020/1500], Loss: 0.002097\n",
      "Epoch [1040/1500], Loss: 0.001303\n",
      "Epoch [1060/1500], Loss: 0.004824\n",
      "Epoch [1080/1500], Loss: 0.004009\n",
      "Epoch [1100/1500], Loss: 0.002418\n",
      "Epoch [1120/1500], Loss: 0.000706\n",
      "Epoch [1140/1500], Loss: 0.000708\n",
      "Epoch [1160/1500], Loss: 0.000704\n",
      "Epoch [1180/1500], Loss: 0.000704\n",
      "Epoch [1200/1500], Loss: 0.000705\n",
      "Epoch [1220/1500], Loss: 0.000706\n",
      "Epoch [1240/1500], Loss: 0.000705\n",
      "Epoch [1260/1500], Loss: 0.000704\n",
      "Epoch [1280/1500], Loss: 0.000705\n",
      "Epoch [1300/1500], Loss: 0.000705\n",
      "Epoch [1320/1500], Loss: 0.000705\n",
      "Epoch [1340/1500], Loss: 0.000705\n",
      "Epoch [1360/1500], Loss: 0.000705\n",
      "Epoch [1380/1500], Loss: 0.000705\n",
      "Epoch [1400/1500], Loss: 0.000705\n",
      "Epoch [1420/1500], Loss: 0.000705\n",
      "Epoch [1440/1500], Loss: 0.000705\n",
      "Epoch [1460/1500], Loss: 0.000705\n",
      "Epoch [1480/1500], Loss: 0.000706\n",
      "Epoch [1500/1500], Loss: 0.000705\n",
      "tensor(0.0141, device='cuda:0')\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.098092 for selected strength\n",
      "We have a total strength of 0.624296 for all the columns\n",
      "Epoch [20/1500], Loss: 2.069576\n",
      "Epoch [40/1500], Loss: 1.409655\n",
      "Epoch [60/1500], Loss: 0.952248\n",
      "Epoch [80/1500], Loss: 0.615559\n",
      "Epoch [100/1500], Loss: 0.371510\n",
      "Epoch [120/1500], Loss: 0.211566\n",
      "Epoch [140/1500], Loss: 0.120102\n",
      "Epoch [160/1500], Loss: 0.067260\n",
      "Epoch [180/1500], Loss: 0.037390\n",
      "Epoch [200/1500], Loss: 0.021206\n",
      "Epoch [220/1500], Loss: 0.012378\n",
      "Epoch [240/1500], Loss: 0.005696\n",
      "Epoch [260/1500], Loss: 0.003808\n",
      "Epoch [280/1500], Loss: 0.003324\n",
      "Epoch [300/1500], Loss: 0.002019\n",
      "Epoch [320/1500], Loss: 0.003666\n",
      "Epoch [340/1500], Loss: 0.001775\n",
      "Epoch [360/1500], Loss: 0.002839\n",
      "Epoch [380/1500], Loss: 0.002043\n",
      "Epoch [400/1500], Loss: 0.004417\n",
      "Epoch [420/1500], Loss: 0.002138\n",
      "Epoch [440/1500], Loss: 0.002492\n",
      "Epoch [460/1500], Loss: 0.002565\n",
      "Epoch [480/1500], Loss: 0.001614\n",
      "Epoch [500/1500], Loss: 0.004139\n",
      "Epoch [520/1500], Loss: 0.001920\n",
      "Epoch [540/1500], Loss: 0.002336\n",
      "Epoch [560/1500], Loss: 0.002806\n",
      "Epoch [580/1500], Loss: 0.001759\n",
      "Epoch [600/1500], Loss: 0.004408\n",
      "Epoch [620/1500], Loss: 0.002691\n",
      "Epoch [640/1500], Loss: 0.001899\n",
      "Epoch [660/1500], Loss: 0.002117\n",
      "Epoch [680/1500], Loss: 0.002562\n",
      "Epoch [700/1500], Loss: 0.001770\n",
      "Epoch [720/1500], Loss: 0.003464\n",
      "Epoch [740/1500], Loss: 0.003516\n",
      "Epoch [760/1500], Loss: 0.002049\n",
      "Epoch [780/1500], Loss: 0.001526\n",
      "Epoch [800/1500], Loss: 0.003969\n",
      "Epoch [820/1500], Loss: 0.002355\n",
      "Epoch [840/1500], Loss: 0.001479\n",
      "Epoch [860/1500], Loss: 0.003336\n",
      "Epoch [880/1500], Loss: 0.002676\n",
      "Epoch [900/1500], Loss: 0.001538\n",
      "Epoch [920/1500], Loss: 0.004583\n",
      "Epoch [940/1500], Loss: 0.003115\n",
      "Epoch [960/1500], Loss: 0.002028\n",
      "Epoch [980/1500], Loss: 0.001555\n",
      "Epoch [1000/1500], Loss: 0.003372\n",
      "Epoch [1020/1500], Loss: 0.002711\n",
      "Epoch [1040/1500], Loss: 0.001997\n",
      "Epoch [1060/1500], Loss: 0.001644\n",
      "Epoch [1080/1500], Loss: 0.003921\n",
      "Epoch [1100/1500], Loss: 0.002877\n",
      "Epoch [1120/1500], Loss: 0.001009\n",
      "Epoch [1140/1500], Loss: 0.001009\n",
      "Epoch [1160/1500], Loss: 0.001007\n",
      "Epoch [1180/1500], Loss: 0.001007\n",
      "Epoch [1200/1500], Loss: 0.001007\n",
      "Epoch [1220/1500], Loss: 0.001007\n",
      "Epoch [1240/1500], Loss: 0.001007\n",
      "Epoch [1260/1500], Loss: 0.001007\n",
      "Epoch [1280/1500], Loss: 0.001007\n",
      "Epoch [1300/1500], Loss: 0.001007\n",
      "Epoch [1320/1500], Loss: 0.001008\n",
      "Epoch [1340/1500], Loss: 0.001008\n",
      "Epoch [1360/1500], Loss: 0.001008\n",
      "Epoch [1380/1500], Loss: 0.001008\n",
      "Epoch [1400/1500], Loss: 0.001009\n",
      "Epoch [1420/1500], Loss: 0.001008\n",
      "Epoch [1440/1500], Loss: 0.001008\n",
      "Epoch [1460/1500], Loss: 0.001008\n",
      "Epoch [1480/1500], Loss: 0.001008\n",
      "Epoch [1500/1500], Loss: 0.001009\n",
      "tensor(0.0109, device='cuda:0')\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.141178 for selected strength\n",
      "We have a total strength of 0.869080 for all the columns\n",
      "Epoch [20/1500], Loss: 2.071206\n",
      "Epoch [40/1500], Loss: 1.407646\n",
      "Epoch [60/1500], Loss: 0.946482\n",
      "Epoch [80/1500], Loss: 0.609731\n",
      "Epoch [100/1500], Loss: 0.367451\n",
      "Epoch [120/1500], Loss: 0.210869\n",
      "Epoch [140/1500], Loss: 0.121255\n",
      "Epoch [160/1500], Loss: 0.070313\n",
      "Epoch [180/1500], Loss: 0.040445\n",
      "Epoch [200/1500], Loss: 0.024511\n",
      "Epoch [220/1500], Loss: 0.012813\n",
      "Epoch [240/1500], Loss: 0.007022\n",
      "Epoch [260/1500], Loss: 0.006338\n",
      "Epoch [280/1500], Loss: 0.002784\n",
      "Epoch [300/1500], Loss: 0.005020\n",
      "Epoch [320/1500], Loss: 0.002594\n",
      "Epoch [340/1500], Loss: 0.003660\n",
      "Epoch [360/1500], Loss: 0.003589\n",
      "Epoch [380/1500], Loss: 0.001303\n",
      "Epoch [400/1500], Loss: 0.002595\n",
      "Epoch [420/1500], Loss: 0.003023\n",
      "Epoch [440/1500], Loss: 0.001937\n",
      "Epoch [460/1500], Loss: 0.004305\n",
      "Epoch [480/1500], Loss: 0.002833\n",
      "Epoch [500/1500], Loss: 0.002053\n",
      "Epoch [520/1500], Loss: 0.001306\n",
      "Epoch [540/1500], Loss: 0.003718\n",
      "Epoch [560/1500], Loss: 0.003402\n",
      "Epoch [580/1500], Loss: 0.001950\n",
      "Epoch [600/1500], Loss: 0.001951\n",
      "Epoch [620/1500], Loss: 0.002912\n",
      "Epoch [640/1500], Loss: 0.003806\n",
      "Epoch [660/1500], Loss: 0.003484\n",
      "Epoch [680/1500], Loss: 0.003369\n",
      "Epoch [700/1500], Loss: 0.002205\n",
      "Epoch [720/1500], Loss: 0.001920\n",
      "Epoch [740/1500], Loss: 0.003004\n",
      "Epoch [760/1500], Loss: 0.002798\n",
      "Epoch [780/1500], Loss: 0.004926\n",
      "Epoch [800/1500], Loss: 0.002588\n",
      "Epoch [820/1500], Loss: 0.001434\n",
      "Epoch [840/1500], Loss: 0.001336\n",
      "Epoch [860/1500], Loss: 0.003245\n",
      "Epoch [880/1500], Loss: 0.005617\n",
      "Epoch [900/1500], Loss: 0.002976\n",
      "Epoch [920/1500], Loss: 0.001879\n",
      "Epoch [940/1500], Loss: 0.001192\n",
      "Epoch [960/1500], Loss: 0.001902\n",
      "Epoch [980/1500], Loss: 0.001742\n",
      "Epoch [1000/1500], Loss: 0.005349\n",
      "Epoch [1020/1500], Loss: 0.005475\n",
      "Epoch [1040/1500], Loss: 0.002567\n",
      "Epoch [1060/1500], Loss: 0.003380\n",
      "Epoch [1080/1500], Loss: 0.003473\n",
      "Epoch [1100/1500], Loss: 0.002129\n",
      "Epoch [1120/1500], Loss: 0.000723\n",
      "Epoch [1140/1500], Loss: 0.000721\n",
      "Epoch [1160/1500], Loss: 0.000721\n",
      "Epoch [1180/1500], Loss: 0.000720\n",
      "Epoch [1200/1500], Loss: 0.000721\n",
      "Epoch [1220/1500], Loss: 0.000720\n",
      "Epoch [1240/1500], Loss: 0.000720\n",
      "Epoch [1260/1500], Loss: 0.000721\n",
      "Epoch [1280/1500], Loss: 0.000721\n",
      "Epoch [1300/1500], Loss: 0.000721\n",
      "Epoch [1320/1500], Loss: 0.000721\n",
      "Epoch [1340/1500], Loss: 0.000721\n",
      "Epoch [1360/1500], Loss: 0.000721\n",
      "Epoch [1380/1500], Loss: 0.000721\n",
      "Epoch [1400/1500], Loss: 0.000721\n",
      "Epoch [1420/1500], Loss: 0.000721\n",
      "Epoch [1440/1500], Loss: 0.000721\n",
      "Epoch [1460/1500], Loss: 0.000721\n",
      "Epoch [1480/1500], Loss: 0.000722\n",
      "Epoch [1500/1500], Loss: 0.000722\n",
      "tensor(0.0127, device='cuda:0')\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.110458 for selected strength\n",
      "We have a total strength of 0.649937 for all the columns\n",
      "Epoch [20/1500], Loss: 2.063892\n",
      "Epoch [40/1500], Loss: 1.394141\n",
      "Epoch [60/1500], Loss: 0.924671\n",
      "Epoch [80/1500], Loss: 0.581828\n",
      "Epoch [100/1500], Loss: 0.339385\n",
      "Epoch [120/1500], Loss: 0.187696\n",
      "Epoch [140/1500], Loss: 0.104977\n",
      "Epoch [160/1500], Loss: 0.059178\n",
      "Epoch [180/1500], Loss: 0.033500\n",
      "Epoch [200/1500], Loss: 0.018877\n",
      "Epoch [220/1500], Loss: 0.011954\n",
      "Epoch [240/1500], Loss: 0.005544\n",
      "Epoch [260/1500], Loss: 0.004854\n",
      "Epoch [280/1500], Loss: 0.002312\n",
      "Epoch [300/1500], Loss: 0.002507\n",
      "Epoch [320/1500], Loss: 0.001900\n",
      "Epoch [340/1500], Loss: 0.003246\n",
      "Epoch [360/1500], Loss: 0.001632\n",
      "Epoch [380/1500], Loss: 0.002401\n",
      "Epoch [400/1500], Loss: 0.001488\n",
      "Epoch [420/1500], Loss: 0.005634\n",
      "Epoch [440/1500], Loss: 0.003074\n",
      "Epoch [460/1500], Loss: 0.002470\n",
      "Epoch [480/1500], Loss: 0.001423\n",
      "Epoch [500/1500], Loss: 0.002689\n",
      "Epoch [520/1500], Loss: 0.001557\n",
      "Epoch [540/1500], Loss: 0.004244\n",
      "Epoch [560/1500], Loss: 0.001859\n",
      "Epoch [580/1500], Loss: 0.001305\n",
      "Epoch [600/1500], Loss: 0.001557\n",
      "Epoch [620/1500], Loss: 0.004477\n",
      "Epoch [640/1500], Loss: 0.002743\n",
      "Epoch [660/1500], Loss: 0.001664\n",
      "Epoch [680/1500], Loss: 0.001379\n",
      "Epoch [700/1500], Loss: 0.003545\n",
      "Epoch [720/1500], Loss: 0.002916\n",
      "Epoch [740/1500], Loss: 0.003109\n",
      "Epoch [760/1500], Loss: 0.001405\n",
      "Epoch [780/1500], Loss: 0.002841\n",
      "Epoch [800/1500], Loss: 0.001936\n",
      "Epoch [820/1500], Loss: 0.002983\n",
      "Epoch [840/1500], Loss: 0.002721\n",
      "Epoch [860/1500], Loss: 0.001994\n",
      "Epoch [880/1500], Loss: 0.001388\n",
      "Epoch [900/1500], Loss: 0.004149\n",
      "Epoch [920/1500], Loss: 0.002787\n",
      "Epoch [940/1500], Loss: 0.001602\n",
      "Epoch [960/1500], Loss: 0.001836\n",
      "Epoch [980/1500], Loss: 0.001552\n",
      "Epoch [1000/1500], Loss: 0.002735\n",
      "Epoch [1020/1500], Loss: 0.004270\n",
      "Epoch [1040/1500], Loss: 0.003443\n",
      "Epoch [1060/1500], Loss: 0.002659\n",
      "Epoch [1080/1500], Loss: 0.002165\n",
      "Epoch [1100/1500], Loss: 0.001963\n",
      "Epoch [1120/1500], Loss: 0.000696\n",
      "Epoch [1140/1500], Loss: 0.000701\n",
      "Epoch [1160/1500], Loss: 0.000699\n",
      "Epoch [1180/1500], Loss: 0.000697\n",
      "Epoch [1200/1500], Loss: 0.000696\n",
      "Epoch [1220/1500], Loss: 0.000698\n",
      "Epoch [1240/1500], Loss: 0.000701\n",
      "Epoch [1260/1500], Loss: 0.000700\n",
      "Epoch [1280/1500], Loss: 0.000696\n",
      "Epoch [1300/1500], Loss: 0.000698\n",
      "Epoch [1320/1500], Loss: 0.000697\n",
      "Epoch [1340/1500], Loss: 0.000697\n",
      "Epoch [1360/1500], Loss: 0.000703\n",
      "Epoch [1380/1500], Loss: 0.000698\n",
      "Epoch [1400/1500], Loss: 0.000703\n",
      "Epoch [1420/1500], Loss: 0.000701\n",
      "Epoch [1440/1500], Loss: 0.000700\n",
      "Epoch [1460/1500], Loss: 0.000700\n",
      "Epoch [1480/1500], Loss: 0.000700\n",
      "Epoch [1500/1500], Loss: 0.000699\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.111044 for selected strength\n",
      "We have a total strength of 0.788968 for all the columns\n",
      "Epoch [20/1500], Loss: 2.096219\n",
      "Epoch [40/1500], Loss: 1.447312\n",
      "Epoch [60/1500], Loss: 0.992805\n",
      "Epoch [80/1500], Loss: 0.654761\n",
      "Epoch [100/1500], Loss: 0.404280\n",
      "Epoch [120/1500], Loss: 0.233142\n",
      "Epoch [140/1500], Loss: 0.130709\n",
      "Epoch [160/1500], Loss: 0.071564\n",
      "Epoch [180/1500], Loss: 0.038275\n",
      "Epoch [200/1500], Loss: 0.020169\n",
      "Epoch [220/1500], Loss: 0.011452\n",
      "Epoch [240/1500], Loss: 0.007066\n",
      "Epoch [260/1500], Loss: 0.005652\n",
      "Epoch [280/1500], Loss: 0.002800\n",
      "Epoch [300/1500], Loss: 0.002703\n",
      "Epoch [320/1500], Loss: 0.003576\n",
      "Epoch [340/1500], Loss: 0.002117\n",
      "Epoch [360/1500], Loss: 0.002547\n",
      "Epoch [380/1500], Loss: 0.003434\n",
      "Epoch [400/1500], Loss: 0.002155\n",
      "Epoch [420/1500], Loss: 0.002995\n",
      "Epoch [440/1500], Loss: 0.002107\n",
      "Epoch [460/1500], Loss: 0.002812\n",
      "Epoch [480/1500], Loss: 0.003057\n",
      "Epoch [500/1500], Loss: 0.002710\n",
      "Epoch [520/1500], Loss: 0.002479\n",
      "Epoch [540/1500], Loss: 0.002530\n",
      "Epoch [560/1500], Loss: 0.003128\n",
      "Epoch [580/1500], Loss: 0.002765\n",
      "Epoch [600/1500], Loss: 0.002087\n",
      "Epoch [620/1500], Loss: 0.003042\n",
      "Epoch [640/1500], Loss: 0.002214\n",
      "Epoch [660/1500], Loss: 0.003645\n",
      "Epoch [680/1500], Loss: 0.002449\n",
      "Epoch [700/1500], Loss: 0.002217\n",
      "Epoch [720/1500], Loss: 0.003003\n",
      "Epoch [740/1500], Loss: 0.002306\n",
      "Epoch [760/1500], Loss: 0.004602\n",
      "Epoch [780/1500], Loss: 0.002623\n",
      "Epoch [800/1500], Loss: 0.002056\n",
      "Epoch [820/1500], Loss: 0.003262\n",
      "Epoch [840/1500], Loss: 0.002549\n",
      "Epoch [860/1500], Loss: 0.002210\n",
      "Epoch [880/1500], Loss: 0.003123\n",
      "Epoch [900/1500], Loss: 0.002288\n",
      "Epoch [920/1500], Loss: 0.002986\n",
      "Epoch [940/1500], Loss: 0.003175\n",
      "Epoch [960/1500], Loss: 0.002303\n",
      "Epoch [980/1500], Loss: 0.001980\n",
      "Epoch [1000/1500], Loss: 0.003334\n",
      "Epoch [1020/1500], Loss: 0.002446\n",
      "Epoch [1040/1500], Loss: 0.002071\n",
      "Epoch [1060/1500], Loss: 0.003175\n",
      "Epoch [1080/1500], Loss: 0.002670\n",
      "Epoch [1100/1500], Loss: 0.002181\n",
      "Epoch [1120/1500], Loss: 0.001633\n",
      "Epoch [1140/1500], Loss: 0.001621\n",
      "Epoch [1160/1500], Loss: 0.001622\n",
      "Epoch [1180/1500], Loss: 0.001612\n",
      "Epoch [1200/1500], Loss: 0.001611\n",
      "Epoch [1220/1500], Loss: 0.001611\n",
      "Epoch [1240/1500], Loss: 0.001612\n",
      "Epoch [1260/1500], Loss: 0.001612\n",
      "Epoch [1280/1500], Loss: 0.001609\n",
      "Epoch [1300/1500], Loss: 0.001609\n",
      "Epoch [1320/1500], Loss: 0.001609\n",
      "Epoch [1340/1500], Loss: 0.001608\n",
      "Epoch [1360/1500], Loss: 0.001609\n",
      "Epoch [1380/1500], Loss: 0.001608\n",
      "Epoch [1400/1500], Loss: 0.001608\n",
      "Epoch [1420/1500], Loss: 0.001608\n",
      "Epoch [1440/1500], Loss: 0.001608\n",
      "Epoch [1460/1500], Loss: 0.001609\n",
      "Epoch [1480/1500], Loss: 0.001608\n",
      "Epoch [1500/1500], Loss: 0.001608\n",
      "tensor(0.0197, device='cuda:0')\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.332889 for selected strength\n",
      "We have a total strength of 2.193497 for all the columns\n",
      "Epoch [20/1500], Loss: 2.090978\n",
      "Epoch [40/1500], Loss: 1.437329\n",
      "Epoch [60/1500], Loss: 0.981707\n",
      "Epoch [80/1500], Loss: 0.645498\n",
      "Epoch [100/1500], Loss: 0.398558\n",
      "Epoch [120/1500], Loss: 0.232203\n",
      "Epoch [140/1500], Loss: 0.132928\n",
      "Epoch [160/1500], Loss: 0.075207\n",
      "Epoch [180/1500], Loss: 0.041829\n",
      "Epoch [200/1500], Loss: 0.022792\n",
      "Epoch [220/1500], Loss: 0.012687\n",
      "Epoch [240/1500], Loss: 0.007446\n",
      "Epoch [260/1500], Loss: 0.006563\n",
      "Epoch [280/1500], Loss: 0.002988\n",
      "Epoch [300/1500], Loss: 0.002656\n",
      "Epoch [320/1500], Loss: 0.003383\n",
      "Epoch [340/1500], Loss: 0.001886\n",
      "Epoch [360/1500], Loss: 0.002544\n",
      "Epoch [380/1500], Loss: 0.002548\n",
      "Epoch [400/1500], Loss: 0.002608\n",
      "Epoch [420/1500], Loss: 0.003930\n",
      "Epoch [440/1500], Loss: 0.002364\n",
      "Epoch [460/1500], Loss: 0.004499\n",
      "Epoch [480/1500], Loss: 0.002429\n",
      "Epoch [500/1500], Loss: 0.002863\n",
      "Epoch [520/1500], Loss: 0.003013\n",
      "Epoch [540/1500], Loss: 0.001798\n",
      "Epoch [560/1500], Loss: 0.003386\n",
      "Epoch [580/1500], Loss: 0.002060\n",
      "Epoch [600/1500], Loss: 0.004537\n",
      "Epoch [620/1500], Loss: 0.002950\n",
      "Epoch [640/1500], Loss: 0.002109\n",
      "Epoch [660/1500], Loss: 0.003583\n",
      "Epoch [680/1500], Loss: 0.002158\n",
      "Epoch [700/1500], Loss: 0.002518\n",
      "Epoch [720/1500], Loss: 0.003053\n",
      "Epoch [740/1500], Loss: 0.001919\n",
      "Epoch [760/1500], Loss: 0.002934\n",
      "Epoch [780/1500], Loss: 0.003362\n",
      "Epoch [800/1500], Loss: 0.002306\n",
      "Epoch [820/1500], Loss: 0.002254\n",
      "Epoch [840/1500], Loss: 0.003235\n",
      "Epoch [860/1500], Loss: 0.002714\n",
      "Epoch [880/1500], Loss: 0.001816\n",
      "Epoch [900/1500], Loss: 0.003885\n",
      "Epoch [920/1500], Loss: 0.002382\n",
      "Epoch [940/1500], Loss: 0.001610\n",
      "Epoch [960/1500], Loss: 0.004502\n",
      "Epoch [980/1500], Loss: 0.003342\n",
      "Epoch [1000/1500], Loss: 0.002006\n",
      "Epoch [1020/1500], Loss: 0.002037\n",
      "Epoch [1040/1500], Loss: 0.004043\n",
      "Epoch [1060/1500], Loss: 0.002636\n",
      "Epoch [1080/1500], Loss: 0.002333\n",
      "Epoch [1100/1500], Loss: 0.001630\n",
      "Epoch [1120/1500], Loss: 0.001565\n",
      "Epoch [1140/1500], Loss: 0.001480\n",
      "Epoch [1160/1500], Loss: 0.001374\n",
      "Epoch [1180/1500], Loss: 0.001292\n",
      "Epoch [1200/1500], Loss: 0.001271\n",
      "Epoch [1220/1500], Loss: 0.001248\n",
      "Epoch [1240/1500], Loss: 0.001224\n",
      "Epoch [1260/1500], Loss: 0.001201\n",
      "Epoch [1280/1500], Loss: 0.001195\n",
      "Epoch [1300/1500], Loss: 0.001187\n",
      "Epoch [1320/1500], Loss: 0.001177\n",
      "Epoch [1340/1500], Loss: 0.001169\n",
      "Epoch [1360/1500], Loss: 0.001163\n",
      "Epoch [1380/1500], Loss: 0.001165\n",
      "Epoch [1400/1500], Loss: 0.001161\n",
      "Epoch [1420/1500], Loss: 0.001158\n",
      "Epoch [1440/1500], Loss: 0.001157\n",
      "Epoch [1460/1500], Loss: 0.001152\n",
      "Epoch [1480/1500], Loss: 0.001148\n",
      "Epoch [1500/1500], Loss: 0.001149\n",
      "tensor(0.0239, device='cuda:0')\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.263765 for selected strength\n",
      "We have a total strength of 2.158428 for all the columns\n",
      "Epoch [20/1500], Loss: 2.068962\n",
      "Epoch [40/1500], Loss: 1.413370\n",
      "Epoch [60/1500], Loss: 0.962300\n",
      "Epoch [80/1500], Loss: 0.629668\n",
      "Epoch [100/1500], Loss: 0.388541\n",
      "Epoch [120/1500], Loss: 0.230500\n",
      "Epoch [140/1500], Loss: 0.136504\n",
      "Epoch [160/1500], Loss: 0.080445\n",
      "Epoch [180/1500], Loss: 0.047057\n",
      "Epoch [200/1500], Loss: 0.027254\n",
      "Epoch [220/1500], Loss: 0.015802\n",
      "Epoch [240/1500], Loss: 0.010491\n",
      "Epoch [260/1500], Loss: 0.004888\n",
      "Epoch [280/1500], Loss: 0.004817\n",
      "Epoch [300/1500], Loss: 0.002132\n",
      "Epoch [320/1500], Loss: 0.002992\n",
      "Epoch [340/1500], Loss: 0.001759\n",
      "Epoch [360/1500], Loss: 0.003174\n",
      "Epoch [380/1500], Loss: 0.002037\n",
      "Epoch [400/1500], Loss: 0.004826\n",
      "Epoch [420/1500], Loss: 0.002471\n",
      "Epoch [440/1500], Loss: 0.001381\n",
      "Epoch [460/1500], Loss: 0.003563\n",
      "Epoch [480/1500], Loss: 0.002281\n",
      "Epoch [500/1500], Loss: 0.001793\n",
      "Epoch [520/1500], Loss: 0.002032\n",
      "Epoch [540/1500], Loss: 0.002126\n",
      "Epoch [560/1500], Loss: 0.001487\n",
      "Epoch [580/1500], Loss: 0.004207\n",
      "Epoch [600/1500], Loss: 0.002361\n",
      "Epoch [620/1500], Loss: 0.001713\n",
      "Epoch [640/1500], Loss: 0.001459\n",
      "Epoch [660/1500], Loss: 0.003247\n",
      "Epoch [680/1500], Loss: 0.002008\n",
      "Epoch [700/1500], Loss: 0.001563\n",
      "Epoch [720/1500], Loss: 0.004930\n",
      "Epoch [740/1500], Loss: 0.002763\n",
      "Epoch [760/1500], Loss: 0.002271\n",
      "Epoch [780/1500], Loss: 0.001478\n",
      "Epoch [800/1500], Loss: 0.001805\n",
      "Epoch [820/1500], Loss: 0.001531\n",
      "Epoch [840/1500], Loss: 0.004588\n",
      "Epoch [860/1500], Loss: 0.004105\n",
      "Epoch [880/1500], Loss: 0.002928\n",
      "Epoch [900/1500], Loss: 0.002129\n",
      "Epoch [920/1500], Loss: 0.001466\n",
      "Epoch [940/1500], Loss: 0.001906\n",
      "Epoch [960/1500], Loss: 0.003674\n",
      "Epoch [980/1500], Loss: 0.002924\n",
      "Epoch [1000/1500], Loss: 0.002331\n",
      "Epoch [1020/1500], Loss: 0.002037\n",
      "Epoch [1040/1500], Loss: 0.001721\n",
      "Epoch [1060/1500], Loss: 0.004409\n",
      "Epoch [1080/1500], Loss: 0.004266\n",
      "Epoch [1100/1500], Loss: 0.002480\n",
      "Epoch [1120/1500], Loss: 0.000847\n",
      "Epoch [1140/1500], Loss: 0.000848\n",
      "Epoch [1160/1500], Loss: 0.000847\n",
      "Epoch [1180/1500], Loss: 0.000846\n",
      "Epoch [1200/1500], Loss: 0.000847\n",
      "Epoch [1220/1500], Loss: 0.000848\n",
      "Epoch [1240/1500], Loss: 0.000847\n",
      "Epoch [1260/1500], Loss: 0.000847\n",
      "Epoch [1280/1500], Loss: 0.000849\n",
      "Epoch [1300/1500], Loss: 0.000848\n",
      "Epoch [1320/1500], Loss: 0.000848\n",
      "Epoch [1340/1500], Loss: 0.000847\n",
      "Epoch [1360/1500], Loss: 0.000847\n",
      "Epoch [1380/1500], Loss: 0.000848\n",
      "Epoch [1400/1500], Loss: 0.000848\n",
      "Epoch [1420/1500], Loss: 0.000849\n",
      "Epoch [1440/1500], Loss: 0.000848\n",
      "Epoch [1460/1500], Loss: 0.000848\n",
      "Epoch [1480/1500], Loss: 0.000848\n",
      "Epoch [1500/1500], Loss: 0.000849\n",
      "tensor(0.0097, device='cuda:0')\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.117942 for selected strength\n",
      "We have a total strength of 0.754497 for all the columns\n",
      "Epoch [20/1500], Loss: 2.091746\n",
      "Epoch [40/1500], Loss: 1.441253\n",
      "Epoch [60/1500], Loss: 0.986700\n",
      "Epoch [80/1500], Loss: 0.649898\n",
      "Epoch [100/1500], Loss: 0.400780\n",
      "Epoch [120/1500], Loss: 0.229903\n",
      "Epoch [140/1500], Loss: 0.126938\n",
      "Epoch [160/1500], Loss: 0.067957\n",
      "Epoch [180/1500], Loss: 0.035546\n",
      "Epoch [200/1500], Loss: 0.018308\n",
      "Epoch [220/1500], Loss: 0.009699\n",
      "Epoch [240/1500], Loss: 0.005879\n",
      "Epoch [260/1500], Loss: 0.004677\n",
      "Epoch [280/1500], Loss: 0.003582\n",
      "Epoch [300/1500], Loss: 0.002341\n",
      "Epoch [320/1500], Loss: 0.002862\n",
      "Epoch [340/1500], Loss: 0.003891\n",
      "Epoch [360/1500], Loss: 0.002045\n",
      "Epoch [380/1500], Loss: 0.002950\n",
      "Epoch [400/1500], Loss: 0.002063\n",
      "Epoch [420/1500], Loss: 0.002740\n",
      "Epoch [440/1500], Loss: 0.002414\n",
      "Epoch [460/1500], Loss: 0.002528\n",
      "Epoch [480/1500], Loss: 0.002408\n",
      "Epoch [500/1500], Loss: 0.002764\n",
      "Epoch [520/1500], Loss: 0.001858\n",
      "Epoch [540/1500], Loss: 0.002922\n",
      "Epoch [560/1500], Loss: 0.001932\n",
      "Epoch [580/1500], Loss: 0.003302\n",
      "Epoch [600/1500], Loss: 0.002271\n",
      "Epoch [620/1500], Loss: 0.003453\n",
      "Epoch [640/1500], Loss: 0.002376\n",
      "Epoch [660/1500], Loss: 0.001933\n",
      "Epoch [680/1500], Loss: 0.003135\n",
      "Epoch [700/1500], Loss: 0.002395\n",
      "Epoch [720/1500], Loss: 0.002021\n",
      "Epoch [740/1500], Loss: 0.003199\n",
      "Epoch [760/1500], Loss: 0.002193\n",
      "Epoch [780/1500], Loss: 0.003757\n",
      "Epoch [800/1500], Loss: 0.002768\n",
      "Epoch [820/1500], Loss: 0.002086\n",
      "Epoch [840/1500], Loss: 0.003483\n",
      "Epoch [860/1500], Loss: 0.002376\n",
      "Epoch [880/1500], Loss: 0.003593\n",
      "Epoch [900/1500], Loss: 0.002959\n",
      "Epoch [920/1500], Loss: 0.002221\n",
      "Epoch [940/1500], Loss: 0.004149\n",
      "Epoch [960/1500], Loss: 0.002758\n",
      "Epoch [980/1500], Loss: 0.002065\n",
      "Epoch [1000/1500], Loss: 0.003579\n",
      "Epoch [1020/1500], Loss: 0.002835\n",
      "Epoch [1040/1500], Loss: 0.002118\n",
      "Epoch [1060/1500], Loss: 0.004153\n",
      "Epoch [1080/1500], Loss: 0.002675\n",
      "Epoch [1100/1500], Loss: 0.002094\n",
      "Epoch [1120/1500], Loss: 0.001498\n",
      "Epoch [1140/1500], Loss: 0.001487\n",
      "Epoch [1160/1500], Loss: 0.001486\n",
      "Epoch [1180/1500], Loss: 0.001485\n",
      "Epoch [1200/1500], Loss: 0.001485\n",
      "Epoch [1220/1500], Loss: 0.001485\n",
      "Epoch [1240/1500], Loss: 0.001484\n",
      "Epoch [1260/1500], Loss: 0.001484\n",
      "Epoch [1280/1500], Loss: 0.001484\n",
      "Epoch [1300/1500], Loss: 0.001485\n",
      "Epoch [1320/1500], Loss: 0.001485\n",
      "Epoch [1340/1500], Loss: 0.001483\n",
      "Epoch [1360/1500], Loss: 0.001483\n",
      "Epoch [1380/1500], Loss: 0.001484\n",
      "Epoch [1400/1500], Loss: 0.001483\n",
      "Epoch [1420/1500], Loss: 0.001482\n",
      "Epoch [1440/1500], Loss: 0.001483\n",
      "Epoch [1460/1500], Loss: 0.001483\n",
      "Epoch [1480/1500], Loss: 0.001483\n",
      "Epoch [1500/1500], Loss: 0.001482\n",
      "tensor(0.0177, device='cuda:0')\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.311749 for selected strength\n",
      "We have a total strength of 1.696193 for all the columns\n",
      "Epoch [20/1500], Loss: 2.076621\n",
      "Epoch [40/1500], Loss: 1.409864\n",
      "Epoch [60/1500], Loss: 0.945203\n",
      "Epoch [80/1500], Loss: 0.605118\n",
      "Epoch [100/1500], Loss: 0.360090\n",
      "Epoch [120/1500], Loss: 0.201294\n",
      "Epoch [140/1500], Loss: 0.112384\n",
      "Epoch [160/1500], Loss: 0.062378\n",
      "Epoch [180/1500], Loss: 0.034548\n",
      "Epoch [200/1500], Loss: 0.019057\n",
      "Epoch [220/1500], Loss: 0.011706\n",
      "Epoch [240/1500], Loss: 0.005429\n",
      "Epoch [260/1500], Loss: 0.003991\n",
      "Epoch [280/1500], Loss: 0.002468\n",
      "Epoch [300/1500], Loss: 0.002093\n",
      "Epoch [320/1500], Loss: 0.002771\n",
      "Epoch [340/1500], Loss: 0.002266\n",
      "Epoch [360/1500], Loss: 0.001611\n",
      "Epoch [380/1500], Loss: 0.002917\n",
      "Epoch [400/1500], Loss: 0.003255\n",
      "Epoch [420/1500], Loss: 0.001607\n",
      "Epoch [440/1500], Loss: 0.004066\n",
      "Epoch [460/1500], Loss: 0.002237\n",
      "Epoch [480/1500], Loss: 0.001848\n",
      "Epoch [500/1500], Loss: 0.001463\n",
      "Epoch [520/1500], Loss: 0.002886\n",
      "Epoch [540/1500], Loss: 0.002524\n",
      "Epoch [560/1500], Loss: 0.001527\n",
      "Epoch [580/1500], Loss: 0.003774\n",
      "Epoch [600/1500], Loss: 0.002499\n",
      "Epoch [620/1500], Loss: 0.001717\n",
      "Epoch [640/1500], Loss: 0.003940\n",
      "Epoch [660/1500], Loss: 0.003312\n",
      "Epoch [680/1500], Loss: 0.002005\n",
      "Epoch [700/1500], Loss: 0.001599\n",
      "Epoch [720/1500], Loss: 0.002052\n",
      "Epoch [740/1500], Loss: 0.003510\n",
      "Epoch [760/1500], Loss: 0.002032\n",
      "Epoch [780/1500], Loss: 0.001697\n",
      "Epoch [800/1500], Loss: 0.001705\n",
      "Epoch [820/1500], Loss: 0.003746\n",
      "Epoch [840/1500], Loss: 0.002392\n",
      "Epoch [860/1500], Loss: 0.001901\n",
      "Epoch [880/1500], Loss: 0.001543\n",
      "Epoch [900/1500], Loss: 0.003521\n",
      "Epoch [920/1500], Loss: 0.003884\n",
      "Epoch [940/1500], Loss: 0.002197\n",
      "Epoch [960/1500], Loss: 0.001619\n",
      "Epoch [980/1500], Loss: 0.001978\n",
      "Epoch [1000/1500], Loss: 0.002887\n",
      "Epoch [1020/1500], Loss: 0.002794\n",
      "Epoch [1040/1500], Loss: 0.001904\n",
      "Epoch [1060/1500], Loss: 0.001766\n",
      "Epoch [1080/1500], Loss: 0.001661\n",
      "Epoch [1100/1500], Loss: 0.003699\n",
      "Epoch [1120/1500], Loss: 0.000906\n",
      "Epoch [1140/1500], Loss: 0.000870\n",
      "Epoch [1160/1500], Loss: 0.000842\n",
      "Epoch [1180/1500], Loss: 0.000830\n",
      "Epoch [1200/1500], Loss: 0.000826\n",
      "Epoch [1220/1500], Loss: 0.000820\n",
      "Epoch [1240/1500], Loss: 0.000820\n",
      "Epoch [1260/1500], Loss: 0.000819\n",
      "Epoch [1280/1500], Loss: 0.000818\n",
      "Epoch [1300/1500], Loss: 0.000817\n",
      "Epoch [1320/1500], Loss: 0.000816\n",
      "Epoch [1340/1500], Loss: 0.000815\n",
      "Epoch [1360/1500], Loss: 0.000817\n",
      "Epoch [1380/1500], Loss: 0.000816\n",
      "Epoch [1400/1500], Loss: 0.000815\n",
      "Epoch [1420/1500], Loss: 0.000817\n",
      "Epoch [1440/1500], Loss: 0.000816\n",
      "Epoch [1460/1500], Loss: 0.000815\n",
      "Epoch [1480/1500], Loss: 0.000816\n",
      "Epoch [1500/1500], Loss: 0.000816\n",
      "tensor(0.0101, device='cuda:0')\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.091954 for selected strength\n",
      "We have a total strength of 0.759380 for all the columns\n",
      "Epoch [20/1500], Loss: 2.067835\n",
      "Epoch [40/1500], Loss: 1.405612\n",
      "Epoch [60/1500], Loss: 0.947239\n",
      "Epoch [80/1500], Loss: 0.612573\n",
      "Epoch [100/1500], Loss: 0.373261\n",
      "Epoch [120/1500], Loss: 0.217755\n",
      "Epoch [140/1500], Loss: 0.127774\n",
      "Epoch [160/1500], Loss: 0.074703\n",
      "Epoch [180/1500], Loss: 0.043512\n",
      "Epoch [200/1500], Loss: 0.025926\n",
      "Epoch [220/1500], Loss: 0.015698\n",
      "Epoch [240/1500], Loss: 0.007698\n",
      "Epoch [260/1500], Loss: 0.006230\n",
      "Epoch [280/1500], Loss: 0.003534\n",
      "Epoch [300/1500], Loss: 0.002558\n",
      "Epoch [320/1500], Loss: 0.001571\n",
      "Epoch [340/1500], Loss: 0.003821\n",
      "Epoch [360/1500], Loss: 0.001368\n",
      "Epoch [380/1500], Loss: 0.003300\n",
      "Epoch [400/1500], Loss: 0.002112\n",
      "Epoch [420/1500], Loss: 0.001593\n",
      "Epoch [440/1500], Loss: 0.003975\n",
      "Epoch [460/1500], Loss: 0.002732\n",
      "Epoch [480/1500], Loss: 0.001595\n",
      "Epoch [500/1500], Loss: 0.001577\n",
      "Epoch [520/1500], Loss: 0.004138\n",
      "Epoch [540/1500], Loss: 0.002815\n",
      "Epoch [560/1500], Loss: 0.001805\n",
      "Epoch [580/1500], Loss: 0.004395\n",
      "Epoch [600/1500], Loss: 0.003507\n",
      "Epoch [620/1500], Loss: 0.002793\n",
      "Epoch [640/1500], Loss: 0.002857\n",
      "Epoch [660/1500], Loss: 0.002032\n",
      "Epoch [680/1500], Loss: 0.002192\n",
      "Epoch [700/1500], Loss: 0.006193\n",
      "Epoch [720/1500], Loss: 0.003207\n",
      "Epoch [740/1500], Loss: 0.002267\n",
      "Epoch [760/1500], Loss: 0.001753\n",
      "Epoch [780/1500], Loss: 0.001844\n",
      "Epoch [800/1500], Loss: 0.001458\n",
      "Epoch [820/1500], Loss: 0.006031\n",
      "Epoch [840/1500], Loss: 0.003683\n",
      "Epoch [860/1500], Loss: 0.002135\n",
      "Epoch [880/1500], Loss: 0.002006\n",
      "Epoch [900/1500], Loss: 0.002210\n",
      "Epoch [920/1500], Loss: 0.003598\n",
      "Epoch [940/1500], Loss: 0.003211\n",
      "Epoch [960/1500], Loss: 0.002562\n",
      "Epoch [980/1500], Loss: 0.001084\n",
      "Epoch [1000/1500], Loss: 0.001793\n",
      "Epoch [1020/1500], Loss: 0.003401\n",
      "Epoch [1040/1500], Loss: 0.003805\n",
      "Epoch [1060/1500], Loss: 0.002593\n",
      "Epoch [1080/1500], Loss: 0.002257\n",
      "Epoch [1100/1500], Loss: 0.001520\n",
      "Epoch [1120/1500], Loss: 0.000690\n",
      "Epoch [1140/1500], Loss: 0.000689\n",
      "Epoch [1160/1500], Loss: 0.000689\n",
      "Epoch [1180/1500], Loss: 0.000688\n",
      "Epoch [1200/1500], Loss: 0.000690\n",
      "Epoch [1220/1500], Loss: 0.000689\n",
      "Epoch [1240/1500], Loss: 0.000689\n",
      "Epoch [1260/1500], Loss: 0.000690\n",
      "Epoch [1280/1500], Loss: 0.000689\n",
      "Epoch [1300/1500], Loss: 0.000689\n",
      "Epoch [1320/1500], Loss: 0.000689\n",
      "Epoch [1340/1500], Loss: 0.000689\n",
      "Epoch [1360/1500], Loss: 0.000690\n",
      "Epoch [1380/1500], Loss: 0.000690\n",
      "Epoch [1400/1500], Loss: 0.000690\n",
      "Epoch [1420/1500], Loss: 0.000689\n",
      "Epoch [1440/1500], Loss: 0.000690\n",
      "Epoch [1460/1500], Loss: 0.000690\n",
      "Epoch [1480/1500], Loss: 0.000690\n",
      "Epoch [1500/1500], Loss: 0.000690\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.099450 for selected strength\n",
      "We have a total strength of 0.486078 for all the columns\n",
      "Epoch [20/1500], Loss: 2.096352\n",
      "Epoch [40/1500], Loss: 1.454816\n",
      "Epoch [60/1500], Loss: 1.005127\n",
      "Epoch [80/1500], Loss: 0.669867\n",
      "Epoch [100/1500], Loss: 0.419849\n",
      "Epoch [120/1500], Loss: 0.247063\n",
      "Epoch [140/1500], Loss: 0.140126\n",
      "Epoch [160/1500], Loss: 0.079546\n",
      "Epoch [180/1500], Loss: 0.044511\n",
      "Epoch [200/1500], Loss: 0.025022\n",
      "Epoch [220/1500], Loss: 0.015256\n",
      "Epoch [240/1500], Loss: 0.007696\n",
      "Epoch [260/1500], Loss: 0.004662\n",
      "Epoch [280/1500], Loss: 0.003666\n",
      "Epoch [300/1500], Loss: 0.003987\n",
      "Epoch [320/1500], Loss: 0.003128\n",
      "Epoch [340/1500], Loss: 0.002122\n",
      "Epoch [360/1500], Loss: 0.002911\n",
      "Epoch [380/1500], Loss: 0.002502\n",
      "Epoch [400/1500], Loss: 0.002467\n",
      "Epoch [420/1500], Loss: 0.004267\n",
      "Epoch [440/1500], Loss: 0.002500\n",
      "Epoch [460/1500], Loss: 0.004074\n",
      "Epoch [480/1500], Loss: 0.002150\n",
      "Epoch [500/1500], Loss: 0.003498\n",
      "Epoch [520/1500], Loss: 0.002331\n",
      "Epoch [540/1500], Loss: 0.004567\n",
      "Epoch [560/1500], Loss: 0.002588\n",
      "Epoch [580/1500], Loss: 0.002035\n",
      "Epoch [600/1500], Loss: 0.003101\n",
      "Epoch [620/1500], Loss: 0.002069\n",
      "Epoch [640/1500], Loss: 0.003612\n",
      "Epoch [660/1500], Loss: 0.002353\n",
      "Epoch [680/1500], Loss: 0.003644\n",
      "Epoch [700/1500], Loss: 0.002801\n",
      "Epoch [720/1500], Loss: 0.001910\n",
      "Epoch [740/1500], Loss: 0.003250\n",
      "Epoch [760/1500], Loss: 0.002448\n",
      "Epoch [780/1500], Loss: 0.003341\n",
      "Epoch [800/1500], Loss: 0.002779\n",
      "Epoch [820/1500], Loss: 0.002168\n",
      "Epoch [840/1500], Loss: 0.004175\n",
      "Epoch [860/1500], Loss: 0.002594\n",
      "Epoch [880/1500], Loss: 0.001921\n",
      "Epoch [900/1500], Loss: 0.004182\n",
      "Epoch [920/1500], Loss: 0.002398\n",
      "Epoch [940/1500], Loss: 0.002046\n",
      "Epoch [960/1500], Loss: 0.003376\n",
      "Epoch [980/1500], Loss: 0.002434\n",
      "Epoch [1000/1500], Loss: 0.001957\n",
      "Epoch [1020/1500], Loss: 0.002889\n",
      "Epoch [1040/1500], Loss: 0.002517\n",
      "Epoch [1060/1500], Loss: 0.001964\n",
      "Epoch [1080/1500], Loss: 0.003419\n",
      "Epoch [1100/1500], Loss: 0.002868\n",
      "Epoch [1120/1500], Loss: 0.001472\n",
      "Epoch [1140/1500], Loss: 0.001463\n",
      "Epoch [1160/1500], Loss: 0.001462\n",
      "Epoch [1180/1500], Loss: 0.001461\n",
      "Epoch [1200/1500], Loss: 0.001463\n",
      "Epoch [1220/1500], Loss: 0.001461\n",
      "Epoch [1240/1500], Loss: 0.001461\n",
      "Epoch [1260/1500], Loss: 0.001461\n",
      "Epoch [1280/1500], Loss: 0.001461\n",
      "Epoch [1300/1500], Loss: 0.001461\n",
      "Epoch [1320/1500], Loss: 0.001461\n",
      "Epoch [1340/1500], Loss: 0.001461\n",
      "Epoch [1360/1500], Loss: 0.001461\n",
      "Epoch [1380/1500], Loss: 0.001461\n",
      "Epoch [1400/1500], Loss: 0.001461\n",
      "Epoch [1420/1500], Loss: 0.001461\n",
      "Epoch [1440/1500], Loss: 0.001461\n",
      "Epoch [1460/1500], Loss: 0.001461\n",
      "Epoch [1480/1500], Loss: 0.001461\n",
      "Epoch [1500/1500], Loss: 0.001460\n",
      "tensor(0.0150, device='cuda:0')\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.266303 for selected strength\n",
      "We have a total strength of 1.180915 for all the columns\n",
      " 25%|███████████▎                                 | 1/4 [01:28<04:26, 88.98s/it]Epoch [20/1500], Loss: 2.064240\n",
      "Epoch [40/1500], Loss: 1.393862\n",
      "Epoch [60/1500], Loss: 0.931789\n",
      "Epoch [80/1500], Loss: 0.595874\n",
      "Epoch [100/1500], Loss: 0.354742\n",
      "Epoch [120/1500], Loss: 0.198526\n",
      "Epoch [140/1500], Loss: 0.109414\n",
      "Epoch [160/1500], Loss: 0.059371\n",
      "Epoch [180/1500], Loss: 0.031771\n",
      "Epoch [200/1500], Loss: 0.016302\n",
      "Epoch [220/1500], Loss: 0.008585\n",
      "Epoch [240/1500], Loss: 0.005459\n",
      "Epoch [260/1500], Loss: 0.005389\n",
      "Epoch [280/1500], Loss: 0.002337\n",
      "Epoch [300/1500], Loss: 0.002806\n",
      "Epoch [320/1500], Loss: 0.001881\n",
      "Epoch [340/1500], Loss: 0.002839\n",
      "Epoch [360/1500], Loss: 0.001629\n",
      "Epoch [380/1500], Loss: 0.002192\n",
      "Epoch [400/1500], Loss: 0.001744\n",
      "Epoch [420/1500], Loss: 0.002507\n",
      "Epoch [440/1500], Loss: 0.001996\n",
      "Epoch [460/1500], Loss: 0.002548\n",
      "Epoch [480/1500], Loss: 0.001606\n",
      "Epoch [500/1500], Loss: 0.003013\n",
      "Epoch [520/1500], Loss: 0.001954\n",
      "Epoch [540/1500], Loss: 0.004391\n",
      "Epoch [560/1500], Loss: 0.002302\n",
      "Epoch [580/1500], Loss: 0.001779\n",
      "Epoch [600/1500], Loss: 0.002773\n",
      "Epoch [620/1500], Loss: 0.001933\n",
      "Epoch [640/1500], Loss: 0.002573\n",
      "Epoch [660/1500], Loss: 0.002301\n",
      "Epoch [680/1500], Loss: 0.001857\n",
      "Epoch [700/1500], Loss: 0.003697\n",
      "Epoch [720/1500], Loss: 0.002550\n",
      "Epoch [740/1500], Loss: 0.001534\n",
      "Epoch [760/1500], Loss: 0.003381\n",
      "Epoch [780/1500], Loss: 0.002513\n",
      "Epoch [800/1500], Loss: 0.001812\n",
      "Epoch [820/1500], Loss: 0.003601\n",
      "Epoch [840/1500], Loss: 0.002461\n",
      "Epoch [860/1500], Loss: 0.001857\n",
      "Epoch [880/1500], Loss: 0.004555\n",
      "Epoch [900/1500], Loss: 0.002883\n",
      "Epoch [920/1500], Loss: 0.001851\n",
      "Epoch [940/1500], Loss: 0.004572\n",
      "Epoch [960/1500], Loss: 0.003159\n",
      "Epoch [980/1500], Loss: 0.002257\n",
      "Epoch [1000/1500], Loss: 0.001591\n",
      "Epoch [1020/1500], Loss: 0.003653\n",
      "Epoch [1040/1500], Loss: 0.002825\n",
      "Epoch [1060/1500], Loss: 0.002082\n",
      "Epoch [1080/1500], Loss: 0.001608\n",
      "Epoch [1100/1500], Loss: 0.003239\n",
      "Epoch [1120/1500], Loss: 0.001212\n",
      "Epoch [1140/1500], Loss: 0.001194\n",
      "Epoch [1160/1500], Loss: 0.001177\n",
      "Epoch [1180/1500], Loss: 0.001178\n",
      "Epoch [1200/1500], Loss: 0.001175\n",
      "Epoch [1220/1500], Loss: 0.001178\n",
      "Epoch [1240/1500], Loss: 0.001173\n",
      "Epoch [1260/1500], Loss: 0.001175\n",
      "Epoch [1280/1500], Loss: 0.001175\n",
      "Epoch [1300/1500], Loss: 0.001173\n",
      "Epoch [1320/1500], Loss: 0.001173\n",
      "Epoch [1340/1500], Loss: 0.001172\n",
      "Epoch [1360/1500], Loss: 0.001173\n",
      "Epoch [1380/1500], Loss: 0.001173\n",
      "Epoch [1400/1500], Loss: 0.001173\n",
      "Epoch [1420/1500], Loss: 0.001173\n",
      "Epoch [1440/1500], Loss: 0.001173\n",
      "Epoch [1460/1500], Loss: 0.001173\n",
      "Epoch [1480/1500], Loss: 0.001173\n",
      "Epoch [1500/1500], Loss: 0.001173\n",
      "tensor(0.0216, device='cuda:0')\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.178476 for selected strength\n",
      "We have a total strength of 1.081351 for all the columns\n",
      "Epoch [20/1500], Loss: 2.092977\n",
      "Epoch [40/1500], Loss: 1.442760\n",
      "Epoch [60/1500], Loss: 0.991403\n",
      "Epoch [80/1500], Loss: 0.658493\n",
      "Epoch [100/1500], Loss: 0.413209\n",
      "Epoch [120/1500], Loss: 0.246375\n",
      "Epoch [140/1500], Loss: 0.144868\n",
      "Epoch [160/1500], Loss: 0.084549\n",
      "Epoch [180/1500], Loss: 0.049056\n",
      "Epoch [200/1500], Loss: 0.028232\n",
      "Epoch [220/1500], Loss: 0.016727\n",
      "Epoch [240/1500], Loss: 0.010209\n",
      "Epoch [260/1500], Loss: 0.007897\n",
      "Epoch [280/1500], Loss: 0.003817\n",
      "Epoch [300/1500], Loss: 0.003073\n",
      "Epoch [320/1500], Loss: 0.003301\n",
      "Epoch [340/1500], Loss: 0.004985\n",
      "Epoch [360/1500], Loss: 0.002486\n",
      "Epoch [380/1500], Loss: 0.003112\n",
      "Epoch [400/1500], Loss: 0.003071\n",
      "Epoch [420/1500], Loss: 0.002654\n",
      "Epoch [440/1500], Loss: 0.003667\n",
      "Epoch [460/1500], Loss: 0.002154\n",
      "Epoch [480/1500], Loss: 0.003180\n",
      "Epoch [500/1500], Loss: 0.002204\n",
      "Epoch [520/1500], Loss: 0.003386\n",
      "Epoch [540/1500], Loss: 0.002133\n",
      "Epoch [560/1500], Loss: 0.003034\n",
      "Epoch [580/1500], Loss: 0.002782\n",
      "Epoch [600/1500], Loss: 0.003219\n",
      "Epoch [620/1500], Loss: 0.002187\n",
      "Epoch [640/1500], Loss: 0.004149\n",
      "Epoch [660/1500], Loss: 0.002409\n",
      "Epoch [680/1500], Loss: 0.003784\n",
      "Epoch [700/1500], Loss: 0.002314\n",
      "Epoch [720/1500], Loss: 0.003595\n",
      "Epoch [740/1500], Loss: 0.002433\n",
      "Epoch [760/1500], Loss: 0.003552\n",
      "Epoch [780/1500], Loss: 0.002656\n",
      "Epoch [800/1500], Loss: 0.002233\n",
      "Epoch [820/1500], Loss: 0.003004\n",
      "Epoch [840/1500], Loss: 0.002234\n",
      "Epoch [860/1500], Loss: 0.004010\n",
      "Epoch [880/1500], Loss: 0.002684\n",
      "Epoch [900/1500], Loss: 0.002636\n",
      "Epoch [920/1500], Loss: 0.003285\n",
      "Epoch [940/1500], Loss: 0.002194\n",
      "Epoch [960/1500], Loss: 0.003859\n",
      "Epoch [980/1500], Loss: 0.002381\n",
      "Epoch [1000/1500], Loss: 0.003966\n",
      "Epoch [1020/1500], Loss: 0.002924\n",
      "Epoch [1040/1500], Loss: 0.002254\n",
      "Epoch [1060/1500], Loss: 0.003942\n",
      "Epoch [1080/1500], Loss: 0.003388\n",
      "Epoch [1100/1500], Loss: 0.002590\n",
      "Epoch [1120/1500], Loss: 0.001744\n",
      "Epoch [1140/1500], Loss: 0.001732\n",
      "Epoch [1160/1500], Loss: 0.001728\n",
      "Epoch [1180/1500], Loss: 0.001726\n",
      "Epoch [1200/1500], Loss: 0.001726\n",
      "Epoch [1220/1500], Loss: 0.001726\n",
      "Epoch [1240/1500], Loss: 0.001726\n",
      "Epoch [1260/1500], Loss: 0.001726\n",
      "Epoch [1280/1500], Loss: 0.001727\n",
      "Epoch [1300/1500], Loss: 0.001725\n",
      "Epoch [1320/1500], Loss: 0.001727\n",
      "Epoch [1340/1500], Loss: 0.001725\n",
      "Epoch [1360/1500], Loss: 0.001723\n",
      "Epoch [1380/1500], Loss: 0.001723\n",
      "Epoch [1400/1500], Loss: 0.001723\n",
      "Epoch [1420/1500], Loss: 0.001723\n",
      "Epoch [1440/1500], Loss: 0.001723\n",
      "Epoch [1460/1500], Loss: 0.001723\n",
      "Epoch [1480/1500], Loss: 0.001723\n",
      "Epoch [1500/1500], Loss: 0.001722\n",
      "tensor(0.0389, device='cuda:0')\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.339860 for selected strength\n",
      "We have a total strength of 1.553811 for all the columns\n",
      "Epoch [20/1500], Loss: 2.099105\n",
      "Epoch [40/1500], Loss: 1.450346\n",
      "Epoch [60/1500], Loss: 1.002008\n",
      "Epoch [80/1500], Loss: 0.668760\n",
      "Epoch [100/1500], Loss: 0.422510\n",
      "Epoch [120/1500], Loss: 0.254748\n",
      "Epoch [140/1500], Loss: 0.152307\n",
      "Epoch [160/1500], Loss: 0.090044\n",
      "Epoch [180/1500], Loss: 0.053233\n",
      "Epoch [200/1500], Loss: 0.031026\n",
      "Epoch [220/1500], Loss: 0.018548\n",
      "Epoch [240/1500], Loss: 0.010018\n",
      "Epoch [260/1500], Loss: 0.006093\n",
      "Epoch [280/1500], Loss: 0.004447\n",
      "Epoch [300/1500], Loss: 0.003602\n",
      "Epoch [320/1500], Loss: 0.005259\n",
      "Epoch [340/1500], Loss: 0.002376\n",
      "Epoch [360/1500], Loss: 0.003319\n",
      "Epoch [380/1500], Loss: 0.002290\n",
      "Epoch [400/1500], Loss: 0.002782\n",
      "Epoch [420/1500], Loss: 0.004769\n",
      "Epoch [440/1500], Loss: 0.002490\n",
      "Epoch [460/1500], Loss: 0.003508\n",
      "Epoch [480/1500], Loss: 0.002366\n",
      "Epoch [500/1500], Loss: 0.003667\n",
      "Epoch [520/1500], Loss: 0.002565\n",
      "Epoch [540/1500], Loss: 0.004360\n",
      "Epoch [560/1500], Loss: 0.003029\n",
      "Epoch [580/1500], Loss: 0.002164\n",
      "Epoch [600/1500], Loss: 0.003153\n",
      "Epoch [620/1500], Loss: 0.002208\n",
      "Epoch [640/1500], Loss: 0.003876\n",
      "Epoch [660/1500], Loss: 0.002598\n",
      "Epoch [680/1500], Loss: 0.002224\n",
      "Epoch [700/1500], Loss: 0.003164\n",
      "Epoch [720/1500], Loss: 0.002445\n",
      "Epoch [740/1500], Loss: 0.004760\n",
      "Epoch [760/1500], Loss: 0.002948\n",
      "Epoch [780/1500], Loss: 0.002393\n",
      "Epoch [800/1500], Loss: 0.003664\n",
      "Epoch [820/1500], Loss: 0.002614\n",
      "Epoch [840/1500], Loss: 0.002347\n",
      "Epoch [860/1500], Loss: 0.003278\n",
      "Epoch [880/1500], Loss: 0.002309\n",
      "Epoch [900/1500], Loss: 0.003822\n",
      "Epoch [920/1500], Loss: 0.002979\n",
      "Epoch [940/1500], Loss: 0.002181\n",
      "Epoch [960/1500], Loss: 0.003868\n",
      "Epoch [980/1500], Loss: 0.002649\n",
      "Epoch [1000/1500], Loss: 0.002362\n",
      "Epoch [1020/1500], Loss: 0.004307\n",
      "Epoch [1040/1500], Loss: 0.002981\n",
      "Epoch [1060/1500], Loss: 0.002228\n",
      "Epoch [1080/1500], Loss: 0.004476\n",
      "Epoch [1100/1500], Loss: 0.003374\n",
      "Epoch [1120/1500], Loss: 0.001873\n",
      "Epoch [1140/1500], Loss: 0.001858\n",
      "Epoch [1160/1500], Loss: 0.001855\n",
      "Epoch [1180/1500], Loss: 0.001855\n",
      "Epoch [1200/1500], Loss: 0.001855\n",
      "Epoch [1220/1500], Loss: 0.001855\n",
      "Epoch [1240/1500], Loss: 0.001855\n",
      "Epoch [1260/1500], Loss: 0.001855\n",
      "Epoch [1280/1500], Loss: 0.001855\n",
      "Epoch [1300/1500], Loss: 0.001856\n",
      "Epoch [1320/1500], Loss: 0.001855\n",
      "Epoch [1340/1500], Loss: 0.001855\n",
      "Epoch [1360/1500], Loss: 0.001855\n",
      "Epoch [1380/1500], Loss: 0.001855\n",
      "Epoch [1400/1500], Loss: 0.001855\n",
      "Epoch [1420/1500], Loss: 0.001855\n",
      "Epoch [1440/1500], Loss: 0.001855\n",
      "Epoch [1460/1500], Loss: 0.001855\n",
      "Epoch [1480/1500], Loss: 0.001855\n",
      "Epoch [1500/1500], Loss: 0.001855\n",
      "tensor(0.0404, device='cuda:0')\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.295689 for selected strength\n",
      "We have a total strength of 1.344453 for all the columns\n",
      "Epoch [20/1500], Loss: 2.046141\n",
      "Epoch [40/1500], Loss: 1.365667\n",
      "Epoch [60/1500], Loss: 0.891892\n",
      "Epoch [80/1500], Loss: 0.551440\n",
      "Epoch [100/1500], Loss: 0.313669\n",
      "Epoch [120/1500], Loss: 0.169268\n",
      "Epoch [140/1500], Loss: 0.092317\n",
      "Epoch [160/1500], Loss: 0.049883\n",
      "Epoch [180/1500], Loss: 0.026904\n",
      "Epoch [200/1500], Loss: 0.014479\n",
      "Epoch [220/1500], Loss: 0.008253\n",
      "Epoch [240/1500], Loss: 0.006223\n",
      "Epoch [260/1500], Loss: 0.002995\n",
      "Epoch [280/1500], Loss: 0.002791\n",
      "Epoch [300/1500], Loss: 0.003171\n",
      "Epoch [320/1500], Loss: 0.001756\n",
      "Epoch [340/1500], Loss: 0.002521\n",
      "Epoch [360/1500], Loss: 0.002242\n",
      "Epoch [380/1500], Loss: 0.002005\n",
      "Epoch [400/1500], Loss: 0.003741\n",
      "Epoch [420/1500], Loss: 0.001910\n",
      "Epoch [440/1500], Loss: 0.003108\n",
      "Epoch [460/1500], Loss: 0.001961\n",
      "Epoch [480/1500], Loss: 0.003921\n",
      "Epoch [500/1500], Loss: 0.001944\n",
      "Epoch [520/1500], Loss: 0.002960\n",
      "Epoch [540/1500], Loss: 0.001842\n",
      "Epoch [560/1500], Loss: 0.002988\n",
      "Epoch [580/1500], Loss: 0.001895\n",
      "Epoch [600/1500], Loss: 0.005046\n",
      "Epoch [620/1500], Loss: 0.002351\n",
      "Epoch [640/1500], Loss: 0.001655\n",
      "Epoch [660/1500], Loss: 0.002934\n",
      "Epoch [680/1500], Loss: 0.001737\n",
      "Epoch [700/1500], Loss: 0.003141\n",
      "Epoch [720/1500], Loss: 0.001829\n",
      "Epoch [740/1500], Loss: 0.001834\n",
      "Epoch [760/1500], Loss: 0.002907\n",
      "Epoch [780/1500], Loss: 0.001539\n",
      "Epoch [800/1500], Loss: 0.003210\n",
      "Epoch [820/1500], Loss: 0.002115\n",
      "Epoch [840/1500], Loss: 0.002477\n",
      "Epoch [860/1500], Loss: 0.002467\n",
      "Epoch [880/1500], Loss: 0.001888\n",
      "Epoch [900/1500], Loss: 0.004479\n",
      "Epoch [920/1500], Loss: 0.002606\n",
      "Epoch [940/1500], Loss: 0.001862\n",
      "Epoch [960/1500], Loss: 0.003655\n",
      "Epoch [980/1500], Loss: 0.002500\n",
      "Epoch [1000/1500], Loss: 0.001830\n",
      "Epoch [1020/1500], Loss: 0.004632\n",
      "Epoch [1040/1500], Loss: 0.002907\n",
      "Epoch [1060/1500], Loss: 0.002132\n",
      "Epoch [1080/1500], Loss: 0.002369\n",
      "Epoch [1100/1500], Loss: 0.002725\n",
      "Epoch [1120/1500], Loss: 0.001205\n",
      "Epoch [1140/1500], Loss: 0.001199\n",
      "Epoch [1160/1500], Loss: 0.001200\n",
      "Epoch [1180/1500], Loss: 0.001198\n",
      "Epoch [1200/1500], Loss: 0.001198\n",
      "Epoch [1220/1500], Loss: 0.001198\n",
      "Epoch [1240/1500], Loss: 0.001198\n",
      "Epoch [1260/1500], Loss: 0.001198\n",
      "Epoch [1280/1500], Loss: 0.001198\n",
      "Epoch [1300/1500], Loss: 0.001198\n",
      "Epoch [1320/1500], Loss: 0.001198\n",
      "Epoch [1340/1500], Loss: 0.001198\n",
      "Epoch [1360/1500], Loss: 0.001199\n",
      "Epoch [1380/1500], Loss: 0.001198\n",
      "Epoch [1400/1500], Loss: 0.001199\n",
      "Epoch [1420/1500], Loss: 0.001198\n",
      "Epoch [1440/1500], Loss: 0.001199\n",
      "Epoch [1460/1500], Loss: 0.001199\n",
      "Epoch [1480/1500], Loss: 0.001198\n",
      "Epoch [1500/1500], Loss: 0.001198\n",
      "tensor(0.0145, device='cuda:0')\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.173630 for selected strength\n",
      "We have a total strength of 1.075857 for all the columns\n",
      "Epoch [20/1500], Loss: 2.055864\n",
      "Epoch [40/1500], Loss: 1.380767\n",
      "Epoch [60/1500], Loss: 0.914381\n",
      "Epoch [80/1500], Loss: 0.574655\n",
      "Epoch [100/1500], Loss: 0.333458\n",
      "Epoch [120/1500], Loss: 0.181686\n",
      "Epoch [140/1500], Loss: 0.098103\n",
      "Epoch [160/1500], Loss: 0.053695\n",
      "Epoch [180/1500], Loss: 0.029119\n",
      "Epoch [200/1500], Loss: 0.016141\n",
      "Epoch [220/1500], Loss: 0.007743\n",
      "Epoch [240/1500], Loss: 0.004485\n",
      "Epoch [260/1500], Loss: 0.003439\n",
      "Epoch [280/1500], Loss: 0.004807\n",
      "Epoch [300/1500], Loss: 0.001754\n",
      "Epoch [320/1500], Loss: 0.002204\n",
      "Epoch [340/1500], Loss: 0.001772\n",
      "Epoch [360/1500], Loss: 0.002447\n",
      "Epoch [380/1500], Loss: 0.001571\n",
      "Epoch [400/1500], Loss: 0.002461\n",
      "Epoch [420/1500], Loss: 0.002101\n",
      "Epoch [440/1500], Loss: 0.002330\n",
      "Epoch [460/1500], Loss: 0.002405\n",
      "Epoch [480/1500], Loss: 0.002431\n",
      "Epoch [500/1500], Loss: 0.001584\n",
      "Epoch [520/1500], Loss: 0.002243\n",
      "Epoch [540/1500], Loss: 0.001709\n",
      "Epoch [560/1500], Loss: 0.003216\n",
      "Epoch [580/1500], Loss: 0.001884\n",
      "Epoch [600/1500], Loss: 0.001494\n",
      "Epoch [620/1500], Loss: 0.002627\n",
      "Epoch [640/1500], Loss: 0.001726\n",
      "Epoch [660/1500], Loss: 0.003655\n",
      "Epoch [680/1500], Loss: 0.002181\n",
      "Epoch [700/1500], Loss: 0.001689\n",
      "Epoch [720/1500], Loss: 0.003456\n",
      "Epoch [740/1500], Loss: 0.002230\n",
      "Epoch [760/1500], Loss: 0.001514\n",
      "Epoch [780/1500], Loss: 0.002749\n",
      "Epoch [800/1500], Loss: 0.001694\n",
      "Epoch [820/1500], Loss: 0.003167\n",
      "Epoch [840/1500], Loss: 0.002144\n",
      "Epoch [860/1500], Loss: 0.001493\n",
      "Epoch [880/1500], Loss: 0.003653\n",
      "Epoch [900/1500], Loss: 0.002673\n",
      "Epoch [920/1500], Loss: 0.001927\n",
      "Epoch [940/1500], Loss: 0.001794\n",
      "Epoch [960/1500], Loss: 0.002837\n",
      "Epoch [980/1500], Loss: 0.002230\n",
      "Epoch [1000/1500], Loss: 0.001631\n",
      "Epoch [1020/1500], Loss: 0.003171\n",
      "Epoch [1040/1500], Loss: 0.002091\n",
      "Epoch [1060/1500], Loss: 0.001556\n",
      "Epoch [1080/1500], Loss: 0.004125\n",
      "Epoch [1100/1500], Loss: 0.002790\n",
      "Epoch [1120/1500], Loss: 0.001152\n",
      "Epoch [1140/1500], Loss: 0.001147\n",
      "Epoch [1160/1500], Loss: 0.001147\n",
      "Epoch [1180/1500], Loss: 0.001147\n",
      "Epoch [1200/1500], Loss: 0.001147\n",
      "Epoch [1220/1500], Loss: 0.001147\n",
      "Epoch [1240/1500], Loss: 0.001147\n",
      "Epoch [1260/1500], Loss: 0.001147\n",
      "Epoch [1280/1500], Loss: 0.001147\n",
      "Epoch [1300/1500], Loss: 0.001146\n",
      "Epoch [1320/1500], Loss: 0.001147\n",
      "Epoch [1340/1500], Loss: 0.001147\n",
      "Epoch [1360/1500], Loss: 0.001147\n",
      "Epoch [1380/1500], Loss: 0.001147\n",
      "Epoch [1400/1500], Loss: 0.001147\n",
      "Epoch [1420/1500], Loss: 0.001147\n",
      "Epoch [1440/1500], Loss: 0.001147\n",
      "Epoch [1460/1500], Loss: 0.001147\n",
      "Epoch [1480/1500], Loss: 0.001147\n",
      "Epoch [1500/1500], Loss: 0.001147\n",
      "tensor(0.0207, device='cuda:0')\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.144861 for selected strength\n",
      "We have a total strength of 0.909420 for all the columns\n",
      "Epoch [20/1500], Loss: 2.070316\n",
      "Epoch [40/1500], Loss: 1.391598\n",
      "Epoch [60/1500], Loss: 0.922705\n",
      "Epoch [80/1500], Loss: 0.581375\n",
      "Epoch [100/1500], Loss: 0.337844\n",
      "Epoch [120/1500], Loss: 0.183720\n",
      "Epoch [140/1500], Loss: 0.098113\n",
      "Epoch [160/1500], Loss: 0.052113\n",
      "Epoch [180/1500], Loss: 0.027205\n",
      "Epoch [200/1500], Loss: 0.014096\n",
      "Epoch [220/1500], Loss: 0.007693\n",
      "Epoch [240/1500], Loss: 0.005578\n",
      "Epoch [260/1500], Loss: 0.004929\n",
      "Epoch [280/1500], Loss: 0.002269\n",
      "Epoch [300/1500], Loss: 0.003004\n",
      "Epoch [320/1500], Loss: 0.002176\n",
      "Epoch [340/1500], Loss: 0.002272\n",
      "Epoch [360/1500], Loss: 0.003161\n",
      "Epoch [380/1500], Loss: 0.002065\n",
      "Epoch [400/1500], Loss: 0.003304\n",
      "Epoch [420/1500], Loss: 0.002049\n",
      "Epoch [440/1500], Loss: 0.004193\n",
      "Epoch [460/1500], Loss: 0.002434\n",
      "Epoch [480/1500], Loss: 0.001814\n",
      "Epoch [500/1500], Loss: 0.002827\n",
      "Epoch [520/1500], Loss: 0.001693\n",
      "Epoch [540/1500], Loss: 0.003035\n",
      "Epoch [560/1500], Loss: 0.002049\n",
      "Epoch [580/1500], Loss: 0.004508\n",
      "Epoch [600/1500], Loss: 0.002684\n",
      "Epoch [620/1500], Loss: 0.001889\n",
      "Epoch [640/1500], Loss: 0.003449\n",
      "Epoch [660/1500], Loss: 0.002483\n",
      "Epoch [680/1500], Loss: 0.002047\n",
      "Epoch [700/1500], Loss: 0.003051\n",
      "Epoch [720/1500], Loss: 0.001980\n",
      "Epoch [740/1500], Loss: 0.003594\n",
      "Epoch [760/1500], Loss: 0.002745\n",
      "Epoch [780/1500], Loss: 0.002208\n",
      "Epoch [800/1500], Loss: 0.001964\n",
      "Epoch [820/1500], Loss: 0.003382\n",
      "Epoch [840/1500], Loss: 0.002207\n",
      "Epoch [860/1500], Loss: 0.001805\n",
      "Epoch [880/1500], Loss: 0.003279\n",
      "Epoch [900/1500], Loss: 0.002731\n",
      "Epoch [920/1500], Loss: 0.002256\n",
      "Epoch [940/1500], Loss: 0.002560\n",
      "Epoch [960/1500], Loss: 0.003350\n",
      "Epoch [980/1500], Loss: 0.002565\n",
      "Epoch [1000/1500], Loss: 0.002004\n",
      "Epoch [1020/1500], Loss: 0.004243\n",
      "Epoch [1040/1500], Loss: 0.003120\n",
      "Epoch [1060/1500], Loss: 0.002142\n",
      "Epoch [1080/1500], Loss: 0.001894\n",
      "Epoch [1100/1500], Loss: 0.003500\n",
      "Epoch [1120/1500], Loss: 0.001466\n",
      "Epoch [1140/1500], Loss: 0.001456\n",
      "Epoch [1160/1500], Loss: 0.001454\n",
      "Epoch [1180/1500], Loss: 0.001454\n",
      "Epoch [1200/1500], Loss: 0.001452\n",
      "Epoch [1220/1500], Loss: 0.001452\n",
      "Epoch [1240/1500], Loss: 0.001453\n",
      "Epoch [1260/1500], Loss: 0.001452\n",
      "Epoch [1280/1500], Loss: 0.001451\n",
      "Epoch [1300/1500], Loss: 0.001451\n",
      "Epoch [1320/1500], Loss: 0.001450\n",
      "Epoch [1340/1500], Loss: 0.001451\n",
      "Epoch [1360/1500], Loss: 0.001450\n",
      "Epoch [1380/1500], Loss: 0.001451\n",
      "Epoch [1400/1500], Loss: 0.001451\n",
      "Epoch [1420/1500], Loss: 0.001450\n",
      "Epoch [1440/1500], Loss: 0.001451\n",
      "Epoch [1460/1500], Loss: 0.001451\n",
      "Epoch [1480/1500], Loss: 0.001451\n",
      "Epoch [1500/1500], Loss: 0.001451\n",
      "tensor(0.0496, device='cuda:0')\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.248313 for selected strength\n",
      "We have a total strength of 1.166409 for all the columns\n",
      "Epoch [20/1500], Loss: 2.057302\n",
      "Epoch [40/1500], Loss: 1.389301\n",
      "Epoch [60/1500], Loss: 0.922556\n",
      "Epoch [80/1500], Loss: 0.581092\n",
      "Epoch [100/1500], Loss: 0.337524\n",
      "Epoch [120/1500], Loss: 0.182625\n",
      "Epoch [140/1500], Loss: 0.098078\n",
      "Epoch [160/1500], Loss: 0.052334\n",
      "Epoch [180/1500], Loss: 0.027700\n",
      "Epoch [200/1500], Loss: 0.014656\n",
      "Epoch [220/1500], Loss: 0.008177\n",
      "Epoch [240/1500], Loss: 0.005256\n",
      "Epoch [260/1500], Loss: 0.004068\n",
      "Epoch [280/1500], Loss: 0.002416\n",
      "Epoch [300/1500], Loss: 0.002306\n",
      "Epoch [320/1500], Loss: 0.002648\n",
      "Epoch [340/1500], Loss: 0.002672\n",
      "Epoch [360/1500], Loss: 0.002275\n",
      "Epoch [380/1500], Loss: 0.003242\n",
      "Epoch [400/1500], Loss: 0.001794\n",
      "Epoch [420/1500], Loss: 0.002632\n",
      "Epoch [440/1500], Loss: 0.001932\n",
      "Epoch [460/1500], Loss: 0.002475\n",
      "Epoch [480/1500], Loss: 0.003420\n",
      "Epoch [500/1500], Loss: 0.002296\n",
      "Epoch [520/1500], Loss: 0.002433\n",
      "Epoch [540/1500], Loss: 0.002514\n",
      "Epoch [560/1500], Loss: 0.004177\n",
      "Epoch [580/1500], Loss: 0.002352\n",
      "Epoch [600/1500], Loss: 0.002512\n",
      "Epoch [620/1500], Loss: 0.002884\n",
      "Epoch [640/1500], Loss: 0.002001\n",
      "Epoch [660/1500], Loss: 0.003146\n",
      "Epoch [680/1500], Loss: 0.002084\n",
      "Epoch [700/1500], Loss: 0.003936\n",
      "Epoch [720/1500], Loss: 0.002211\n",
      "Epoch [740/1500], Loss: 0.004249\n",
      "Epoch [760/1500], Loss: 0.002442\n",
      "Epoch [780/1500], Loss: 0.001796\n",
      "Epoch [800/1500], Loss: 0.003164\n",
      "Epoch [820/1500], Loss: 0.001800\n",
      "Epoch [840/1500], Loss: 0.003046\n",
      "Epoch [860/1500], Loss: 0.002373\n",
      "Epoch [880/1500], Loss: 0.001760\n",
      "Epoch [900/1500], Loss: 0.002834\n",
      "Epoch [920/1500], Loss: 0.001917\n",
      "Epoch [940/1500], Loss: 0.004234\n",
      "Epoch [960/1500], Loss: 0.002510\n",
      "Epoch [980/1500], Loss: 0.002224\n",
      "Epoch [1000/1500], Loss: 0.003408\n",
      "Epoch [1020/1500], Loss: 0.002442\n",
      "Epoch [1040/1500], Loss: 0.002359\n",
      "Epoch [1060/1500], Loss: 0.002998\n",
      "Epoch [1080/1500], Loss: 0.002140\n",
      "Epoch [1100/1500], Loss: 0.003967\n",
      "Epoch [1120/1500], Loss: 0.001617\n",
      "Epoch [1140/1500], Loss: 0.001600\n",
      "Epoch [1160/1500], Loss: 0.001588\n",
      "Epoch [1180/1500], Loss: 0.001588\n",
      "Epoch [1200/1500], Loss: 0.001585\n",
      "Epoch [1220/1500], Loss: 0.001585\n",
      "Epoch [1240/1500], Loss: 0.001584\n",
      "Epoch [1260/1500], Loss: 0.001584\n",
      "Epoch [1280/1500], Loss: 0.001584\n",
      "Epoch [1300/1500], Loss: 0.001584\n",
      "Epoch [1320/1500], Loss: 0.001584\n",
      "Epoch [1340/1500], Loss: 0.001584\n",
      "Epoch [1360/1500], Loss: 0.001584\n",
      "Epoch [1380/1500], Loss: 0.001584\n",
      "Epoch [1400/1500], Loss: 0.001584\n",
      "Epoch [1420/1500], Loss: 0.001584\n",
      "Epoch [1440/1500], Loss: 0.001584\n",
      "Epoch [1460/1500], Loss: 0.001585\n",
      "Epoch [1480/1500], Loss: 0.001585\n",
      "Epoch [1500/1500], Loss: 0.001585\n",
      "tensor(0.0214, device='cuda:0')\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.249127 for selected strength\n",
      "We have a total strength of 1.456522 for all the columns\n",
      "Epoch [20/1500], Loss: 2.065765\n",
      "Epoch [40/1500], Loss: 1.401669\n",
      "Epoch [60/1500], Loss: 0.936970\n",
      "Epoch [80/1500], Loss: 0.595433\n",
      "Epoch [100/1500], Loss: 0.350045\n",
      "Epoch [120/1500], Loss: 0.193178\n",
      "Epoch [140/1500], Loss: 0.105791\n",
      "Epoch [160/1500], Loss: 0.057012\n",
      "Epoch [180/1500], Loss: 0.030163\n",
      "Epoch [200/1500], Loss: 0.015819\n",
      "Epoch [220/1500], Loss: 0.008474\n",
      "Epoch [240/1500], Loss: 0.005702\n",
      "Epoch [260/1500], Loss: 0.004789\n",
      "Epoch [280/1500], Loss: 0.002364\n",
      "Epoch [300/1500], Loss: 0.002336\n",
      "Epoch [320/1500], Loss: 0.002797\n",
      "Epoch [340/1500], Loss: 0.004420\n",
      "Epoch [360/1500], Loss: 0.002138\n",
      "Epoch [380/1500], Loss: 0.002721\n",
      "Epoch [400/1500], Loss: 0.003652\n",
      "Epoch [420/1500], Loss: 0.002271\n",
      "Epoch [440/1500], Loss: 0.003219\n",
      "Epoch [460/1500], Loss: 0.002052\n",
      "Epoch [480/1500], Loss: 0.002634\n",
      "Epoch [500/1500], Loss: 0.004026\n",
      "Epoch [520/1500], Loss: 0.002315\n",
      "Epoch [540/1500], Loss: 0.003209\n",
      "Epoch [560/1500], Loss: 0.002262\n",
      "Epoch [580/1500], Loss: 0.003362\n",
      "Epoch [600/1500], Loss: 0.002174\n",
      "Epoch [620/1500], Loss: 0.003241\n",
      "Epoch [640/1500], Loss: 0.002184\n",
      "Epoch [660/1500], Loss: 0.003315\n",
      "Epoch [680/1500], Loss: 0.002079\n",
      "Epoch [700/1500], Loss: 0.003189\n",
      "Epoch [720/1500], Loss: 0.002479\n",
      "Epoch [740/1500], Loss: 0.004475\n",
      "Epoch [760/1500], Loss: 0.002494\n",
      "Epoch [780/1500], Loss: 0.004193\n",
      "Epoch [800/1500], Loss: 0.002614\n",
      "Epoch [820/1500], Loss: 0.002182\n",
      "Epoch [840/1500], Loss: 0.003386\n",
      "Epoch [860/1500], Loss: 0.002180\n",
      "Epoch [880/1500], Loss: 0.003675\n",
      "Epoch [900/1500], Loss: 0.002318\n",
      "Epoch [920/1500], Loss: 0.002369\n",
      "Epoch [940/1500], Loss: 0.002732\n",
      "Epoch [960/1500], Loss: 0.002309\n",
      "Epoch [980/1500], Loss: 0.003043\n",
      "Epoch [1000/1500], Loss: 0.002396\n",
      "Epoch [1020/1500], Loss: 0.002190\n",
      "Epoch [1040/1500], Loss: 0.003495\n",
      "Epoch [1060/1500], Loss: 0.002473\n",
      "Epoch [1080/1500], Loss: 0.002118\n",
      "Epoch [1100/1500], Loss: 0.003548\n",
      "Epoch [1120/1500], Loss: 0.001860\n",
      "Epoch [1140/1500], Loss: 0.001850\n",
      "Epoch [1160/1500], Loss: 0.001848\n",
      "Epoch [1180/1500], Loss: 0.001847\n",
      "Epoch [1200/1500], Loss: 0.001848\n",
      "Epoch [1220/1500], Loss: 0.001847\n",
      "Epoch [1240/1500], Loss: 0.001848\n",
      "Epoch [1260/1500], Loss: 0.001846\n",
      "Epoch [1280/1500], Loss: 0.001847\n",
      "Epoch [1300/1500], Loss: 0.001846\n",
      "Epoch [1320/1500], Loss: 0.001847\n",
      "Epoch [1340/1500], Loss: 0.001846\n",
      "Epoch [1360/1500], Loss: 0.001846\n",
      "Epoch [1380/1500], Loss: 0.001847\n",
      "Epoch [1400/1500], Loss: 0.001846\n",
      "Epoch [1420/1500], Loss: 0.001846\n",
      "Epoch [1440/1500], Loss: 0.001846\n",
      "Epoch [1460/1500], Loss: 0.001846\n",
      "Epoch [1480/1500], Loss: 0.001846\n",
      "Epoch [1500/1500], Loss: 0.001846\n",
      "tensor(0.0226, device='cuda:0')\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.328707 for selected strength\n",
      "We have a total strength of 1.573269 for all the columns\n",
      "Epoch [20/1500], Loss: 2.050928\n",
      "Epoch [40/1500], Loss: 1.377407\n",
      "Epoch [60/1500], Loss: 0.911034\n",
      "Epoch [80/1500], Loss: 0.571430\n",
      "Epoch [100/1500], Loss: 0.330560\n",
      "Epoch [120/1500], Loss: 0.179942\n",
      "Epoch [140/1500], Loss: 0.097767\n",
      "Epoch [160/1500], Loss: 0.053131\n",
      "Epoch [180/1500], Loss: 0.028869\n",
      "Epoch [200/1500], Loss: 0.015380\n",
      "Epoch [220/1500], Loss: 0.008906\n",
      "Epoch [240/1500], Loss: 0.006048\n",
      "Epoch [260/1500], Loss: 0.002999\n",
      "Epoch [280/1500], Loss: 0.002628\n",
      "Epoch [300/1500], Loss: 0.003331\n",
      "Epoch [320/1500], Loss: 0.002420\n",
      "Epoch [340/1500], Loss: 0.001962\n",
      "Epoch [360/1500], Loss: 0.003578\n",
      "Epoch [380/1500], Loss: 0.001786\n",
      "Epoch [400/1500], Loss: 0.002412\n",
      "Epoch [420/1500], Loss: 0.002232\n",
      "Epoch [440/1500], Loss: 0.001997\n",
      "Epoch [460/1500], Loss: 0.003253\n",
      "Epoch [480/1500], Loss: 0.001974\n",
      "Epoch [500/1500], Loss: 0.002956\n",
      "Epoch [520/1500], Loss: 0.001844\n",
      "Epoch [540/1500], Loss: 0.002857\n",
      "Epoch [560/1500], Loss: 0.001878\n",
      "Epoch [580/1500], Loss: 0.003044\n",
      "Epoch [600/1500], Loss: 0.002061\n",
      "Epoch [620/1500], Loss: 0.004103\n",
      "Epoch [640/1500], Loss: 0.002288\n",
      "Epoch [660/1500], Loss: 0.001779\n",
      "Epoch [680/1500], Loss: 0.002682\n",
      "Epoch [700/1500], Loss: 0.001771\n",
      "Epoch [720/1500], Loss: 0.003146\n",
      "Epoch [740/1500], Loss: 0.002231\n",
      "Epoch [760/1500], Loss: 0.001725\n",
      "Epoch [780/1500], Loss: 0.002690\n",
      "Epoch [800/1500], Loss: 0.001883\n",
      "Epoch [820/1500], Loss: 0.003237\n",
      "Epoch [840/1500], Loss: 0.002064\n",
      "Epoch [860/1500], Loss: 0.001721\n",
      "Epoch [880/1500], Loss: 0.002916\n",
      "Epoch [900/1500], Loss: 0.002030\n",
      "Epoch [920/1500], Loss: 0.002077\n",
      "Epoch [940/1500], Loss: 0.002695\n",
      "Epoch [960/1500], Loss: 0.001772\n",
      "Epoch [980/1500], Loss: 0.004221\n",
      "Epoch [1000/1500], Loss: 0.002518\n",
      "Epoch [1020/1500], Loss: 0.002161\n",
      "Epoch [1040/1500], Loss: 0.001722\n",
      "Epoch [1060/1500], Loss: 0.003111\n",
      "Epoch [1080/1500], Loss: 0.002436\n",
      "Epoch [1100/1500], Loss: 0.001770\n",
      "Epoch [1120/1500], Loss: 0.001653\n",
      "Epoch [1140/1500], Loss: 0.001543\n",
      "Epoch [1160/1500], Loss: 0.001464\n",
      "Epoch [1180/1500], Loss: 0.001419\n",
      "Epoch [1200/1500], Loss: 0.001393\n",
      "Epoch [1220/1500], Loss: 0.001372\n",
      "Epoch [1240/1500], Loss: 0.001370\n",
      "Epoch [1260/1500], Loss: 0.001363\n",
      "Epoch [1280/1500], Loss: 0.001357\n",
      "Epoch [1300/1500], Loss: 0.001354\n",
      "Epoch [1320/1500], Loss: 0.001346\n",
      "Epoch [1340/1500], Loss: 0.001345\n",
      "Epoch [1360/1500], Loss: 0.001343\n",
      "Epoch [1380/1500], Loss: 0.001342\n",
      "Epoch [1400/1500], Loss: 0.001341\n",
      "Epoch [1420/1500], Loss: 0.001341\n",
      "Epoch [1440/1500], Loss: 0.001339\n",
      "Epoch [1460/1500], Loss: 0.001340\n",
      "Epoch [1480/1500], Loss: 0.001337\n",
      "Epoch [1500/1500], Loss: 0.001338\n",
      "tensor(0.0320, device='cuda:0')\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.265430 for selected strength\n",
      "We have a total strength of 2.150664 for all the columns\n",
      "Epoch [20/1500], Loss: 2.065584\n",
      "Epoch [40/1500], Loss: 1.397507\n",
      "Epoch [60/1500], Loss: 0.934202\n",
      "Epoch [80/1500], Loss: 0.596046\n",
      "Epoch [100/1500], Loss: 0.354278\n",
      "Epoch [120/1500], Loss: 0.200471\n",
      "Epoch [140/1500], Loss: 0.113382\n",
      "Epoch [160/1500], Loss: 0.065059\n",
      "Epoch [180/1500], Loss: 0.037298\n",
      "Epoch [200/1500], Loss: 0.022163\n",
      "Epoch [220/1500], Loss: 0.012710\n",
      "Epoch [240/1500], Loss: 0.008742\n",
      "Epoch [260/1500], Loss: 0.004310\n",
      "Epoch [280/1500], Loss: 0.003234\n",
      "Epoch [300/1500], Loss: 0.003046\n",
      "Epoch [320/1500], Loss: 0.003327\n",
      "Epoch [340/1500], Loss: 0.002218\n",
      "Epoch [360/1500], Loss: 0.002589\n",
      "Epoch [380/1500], Loss: 0.003394\n",
      "Epoch [400/1500], Loss: 0.002115\n",
      "Epoch [420/1500], Loss: 0.002652\n",
      "Epoch [440/1500], Loss: 0.003791\n",
      "Epoch [460/1500], Loss: 0.002418\n",
      "Epoch [480/1500], Loss: 0.003879\n",
      "Epoch [500/1500], Loss: 0.002427\n",
      "Epoch [520/1500], Loss: 0.003425\n",
      "Epoch [540/1500], Loss: 0.002202\n",
      "Epoch [560/1500], Loss: 0.003199\n",
      "Epoch [580/1500], Loss: 0.002127\n",
      "Epoch [600/1500], Loss: 0.003092\n",
      "Epoch [620/1500], Loss: 0.002206\n",
      "Epoch [640/1500], Loss: 0.003327\n",
      "Epoch [660/1500], Loss: 0.002520\n",
      "Epoch [680/1500], Loss: 0.004499\n",
      "Epoch [700/1500], Loss: 0.002913\n",
      "Epoch [720/1500], Loss: 0.002306\n",
      "Epoch [740/1500], Loss: 0.003064\n",
      "Epoch [760/1500], Loss: 0.002288\n",
      "Epoch [780/1500], Loss: 0.003623\n",
      "Epoch [800/1500], Loss: 0.002432\n",
      "Epoch [820/1500], Loss: 0.002971\n",
      "Epoch [840/1500], Loss: 0.002884\n",
      "Epoch [860/1500], Loss: 0.002287\n",
      "Epoch [880/1500], Loss: 0.003846\n",
      "Epoch [900/1500], Loss: 0.002673\n",
      "Epoch [920/1500], Loss: 0.002777\n",
      "Epoch [940/1500], Loss: 0.002945\n",
      "Epoch [960/1500], Loss: 0.002374\n",
      "Epoch [980/1500], Loss: 0.003933\n",
      "Epoch [1000/1500], Loss: 0.002826\n",
      "Epoch [1020/1500], Loss: 0.002193\n",
      "Epoch [1040/1500], Loss: 0.004399\n",
      "Epoch [1060/1500], Loss: 0.002621\n",
      "Epoch [1080/1500], Loss: 0.002064\n",
      "Epoch [1100/1500], Loss: 0.003667\n",
      "Epoch [1120/1500], Loss: 0.001845\n",
      "Epoch [1140/1500], Loss: 0.001833\n",
      "Epoch [1160/1500], Loss: 0.001831\n",
      "Epoch [1180/1500], Loss: 0.001829\n",
      "Epoch [1200/1500], Loss: 0.001831\n",
      "Epoch [1220/1500], Loss: 0.001830\n",
      "Epoch [1240/1500], Loss: 0.001828\n",
      "Epoch [1260/1500], Loss: 0.001828\n",
      "Epoch [1280/1500], Loss: 0.001829\n",
      "Epoch [1300/1500], Loss: 0.001828\n",
      "Epoch [1320/1500], Loss: 0.001828\n",
      "Epoch [1340/1500], Loss: 0.001828\n",
      "Epoch [1360/1500], Loss: 0.001829\n",
      "Epoch [1380/1500], Loss: 0.001829\n",
      "Epoch [1400/1500], Loss: 0.001828\n",
      "Epoch [1420/1500], Loss: 0.001828\n",
      "Epoch [1440/1500], Loss: 0.001828\n",
      "Epoch [1460/1500], Loss: 0.001828\n",
      "Epoch [1480/1500], Loss: 0.001828\n",
      "Epoch [1500/1500], Loss: 0.001828\n",
      "tensor(0.0214, device='cuda:0')\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.320370 for selected strength\n",
      "We have a total strength of 1.587865 for all the columns\n",
      "Epoch [20/1500], Loss: 2.080463\n",
      "Epoch [40/1500], Loss: 1.425861\n",
      "Epoch [60/1500], Loss: 0.971151\n",
      "Epoch [80/1500], Loss: 0.635175\n",
      "Epoch [100/1500], Loss: 0.389334\n",
      "Epoch [120/1500], Loss: 0.224862\n",
      "Epoch [140/1500], Loss: 0.127275\n",
      "Epoch [160/1500], Loss: 0.071998\n",
      "Epoch [180/1500], Loss: 0.040624\n",
      "Epoch [200/1500], Loss: 0.022851\n",
      "Epoch [220/1500], Loss: 0.013014\n",
      "Epoch [240/1500], Loss: 0.008908\n",
      "Epoch [260/1500], Loss: 0.004804\n",
      "Epoch [280/1500], Loss: 0.003299\n",
      "Epoch [300/1500], Loss: 0.003094\n",
      "Epoch [320/1500], Loss: 0.003777\n",
      "Epoch [340/1500], Loss: 0.002304\n",
      "Epoch [360/1500], Loss: 0.002621\n",
      "Epoch [380/1500], Loss: 0.003431\n",
      "Epoch [400/1500], Loss: 0.002386\n",
      "Epoch [420/1500], Loss: 0.002992\n",
      "Epoch [440/1500], Loss: 0.003554\n",
      "Epoch [460/1500], Loss: 0.002630\n",
      "Epoch [480/1500], Loss: 0.003586\n",
      "Epoch [500/1500], Loss: 0.002355\n",
      "Epoch [520/1500], Loss: 0.003196\n",
      "Epoch [540/1500], Loss: 0.002325\n",
      "Epoch [560/1500], Loss: 0.002996\n",
      "Epoch [580/1500], Loss: 0.002365\n",
      "Epoch [600/1500], Loss: 0.002973\n",
      "Epoch [620/1500], Loss: 0.003734\n",
      "Epoch [640/1500], Loss: 0.002867\n",
      "Epoch [660/1500], Loss: 0.002842\n",
      "Epoch [680/1500], Loss: 0.002860\n",
      "Epoch [700/1500], Loss: 0.002306\n",
      "Epoch [720/1500], Loss: 0.003166\n",
      "Epoch [740/1500], Loss: 0.002416\n",
      "Epoch [760/1500], Loss: 0.003674\n",
      "Epoch [780/1500], Loss: 0.002872\n",
      "Epoch [800/1500], Loss: 0.002393\n",
      "Epoch [820/1500], Loss: 0.003715\n",
      "Epoch [840/1500], Loss: 0.002633\n",
      "Epoch [860/1500], Loss: 0.002358\n",
      "Epoch [880/1500], Loss: 0.003360\n",
      "Epoch [900/1500], Loss: 0.002442\n",
      "Epoch [920/1500], Loss: 0.004275\n",
      "Epoch [940/1500], Loss: 0.002932\n",
      "Epoch [960/1500], Loss: 0.002380\n",
      "Epoch [980/1500], Loss: 0.003907\n",
      "Epoch [1000/1500], Loss: 0.002736\n",
      "Epoch [1020/1500], Loss: 0.002512\n",
      "Epoch [1040/1500], Loss: 0.003745\n",
      "Epoch [1060/1500], Loss: 0.002828\n",
      "Epoch [1080/1500], Loss: 0.002283\n",
      "Epoch [1100/1500], Loss: 0.003448\n",
      "Epoch [1120/1500], Loss: 0.002010\n",
      "Epoch [1140/1500], Loss: 0.001997\n",
      "Epoch [1160/1500], Loss: 0.001992\n",
      "Epoch [1180/1500], Loss: 0.001991\n",
      "Epoch [1200/1500], Loss: 0.001991\n",
      "Epoch [1220/1500], Loss: 0.001991\n",
      "Epoch [1240/1500], Loss: 0.001991\n",
      "Epoch [1260/1500], Loss: 0.001991\n",
      "Epoch [1280/1500], Loss: 0.001991\n",
      "Epoch [1300/1500], Loss: 0.001991\n",
      "Epoch [1320/1500], Loss: 0.001991\n",
      "Epoch [1340/1500], Loss: 0.001991\n",
      "Epoch [1360/1500], Loss: 0.001991\n",
      "Epoch [1380/1500], Loss: 0.001991\n",
      "Epoch [1400/1500], Loss: 0.001992\n",
      "Epoch [1420/1500], Loss: 0.001992\n",
      "Epoch [1440/1500], Loss: 0.001992\n",
      "Epoch [1460/1500], Loss: 0.001992\n",
      "Epoch [1480/1500], Loss: 0.001992\n",
      "Epoch [1500/1500], Loss: 0.001992\n",
      "tensor(0.0291, device='cuda:0')\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.381874 for selected strength\n",
      "We have a total strength of 1.601902 for all the columns\n",
      "Epoch [20/1500], Loss: 2.056622\n",
      "Epoch [40/1500], Loss: 1.382900\n",
      "Epoch [60/1500], Loss: 0.915399\n",
      "Epoch [80/1500], Loss: 0.574330\n",
      "Epoch [100/1500], Loss: 0.331506\n",
      "Epoch [120/1500], Loss: 0.178045\n",
      "Epoch [140/1500], Loss: 0.094500\n",
      "Epoch [160/1500], Loss: 0.049277\n",
      "Epoch [180/1500], Loss: 0.025477\n",
      "Epoch [200/1500], Loss: 0.013191\n",
      "Epoch [220/1500], Loss: 0.007129\n",
      "Epoch [240/1500], Loss: 0.004956\n",
      "Epoch [260/1500], Loss: 0.004477\n",
      "Epoch [280/1500], Loss: 0.002207\n",
      "Epoch [300/1500], Loss: 0.002440\n",
      "Epoch [320/1500], Loss: 0.003175\n",
      "Epoch [340/1500], Loss: 0.001929\n",
      "Epoch [360/1500], Loss: 0.002407\n",
      "Epoch [380/1500], Loss: 0.003195\n",
      "Epoch [400/1500], Loss: 0.002167\n",
      "Epoch [420/1500], Loss: 0.002863\n",
      "Epoch [440/1500], Loss: 0.002061\n",
      "Epoch [460/1500], Loss: 0.002555\n",
      "Epoch [480/1500], Loss: 0.003106\n",
      "Epoch [500/1500], Loss: 0.002292\n",
      "Epoch [520/1500], Loss: 0.004140\n",
      "Epoch [540/1500], Loss: 0.002279\n",
      "Epoch [560/1500], Loss: 0.004105\n",
      "Epoch [580/1500], Loss: 0.002368\n",
      "Epoch [600/1500], Loss: 0.002989\n",
      "Epoch [620/1500], Loss: 0.002323\n",
      "Epoch [640/1500], Loss: 0.002810\n",
      "Epoch [660/1500], Loss: 0.002523\n",
      "Epoch [680/1500], Loss: 0.001973\n",
      "Epoch [700/1500], Loss: 0.002837\n",
      "Epoch [720/1500], Loss: 0.002240\n",
      "Epoch [740/1500], Loss: 0.003172\n",
      "Epoch [760/1500], Loss: 0.002098\n",
      "Epoch [780/1500], Loss: 0.003382\n",
      "Epoch [800/1500], Loss: 0.002290\n",
      "Epoch [820/1500], Loss: 0.002140\n",
      "Epoch [840/1500], Loss: 0.002534\n",
      "Epoch [860/1500], Loss: 0.002080\n",
      "Epoch [880/1500], Loss: 0.003449\n",
      "Epoch [900/1500], Loss: 0.001971\n",
      "Epoch [920/1500], Loss: 0.003274\n",
      "Epoch [940/1500], Loss: 0.002266\n",
      "Epoch [960/1500], Loss: 0.002030\n",
      "Epoch [980/1500], Loss: 0.002922\n",
      "Epoch [1000/1500], Loss: 0.002353\n",
      "Epoch [1020/1500], Loss: 0.002245\n",
      "Epoch [1040/1500], Loss: 0.002824\n",
      "Epoch [1060/1500], Loss: 0.002256\n",
      "Epoch [1080/1500], Loss: 0.002000\n",
      "Epoch [1100/1500], Loss: 0.003650\n",
      "Epoch [1120/1500], Loss: 0.001761\n",
      "Epoch [1140/1500], Loss: 0.001750\n",
      "Epoch [1160/1500], Loss: 0.001749\n",
      "Epoch [1180/1500], Loss: 0.001748\n",
      "Epoch [1200/1500], Loss: 0.001748\n",
      "Epoch [1220/1500], Loss: 0.001747\n",
      "Epoch [1240/1500], Loss: 0.001747\n",
      "Epoch [1260/1500], Loss: 0.001747\n",
      "Epoch [1280/1500], Loss: 0.001747\n",
      "Epoch [1300/1500], Loss: 0.001747\n",
      "Epoch [1320/1500], Loss: 0.001748\n",
      "Epoch [1340/1500], Loss: 0.001748\n",
      "Epoch [1360/1500], Loss: 0.001748\n",
      "Epoch [1380/1500], Loss: 0.001748\n",
      "Epoch [1400/1500], Loss: 0.001748\n",
      "Epoch [1420/1500], Loss: 0.001748\n",
      "Epoch [1440/1500], Loss: 0.001748\n",
      "Epoch [1460/1500], Loss: 0.001748\n",
      "Epoch [1480/1500], Loss: 0.001748\n",
      "Epoch [1500/1500], Loss: 0.001748\n",
      "tensor(0.0281, device='cuda:0')\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.307934 for selected strength\n",
      "We have a total strength of 1.519920 for all the columns\n",
      " 50%|██████████████████████▌                      | 2/4 [02:56<02:55, 87.93s/it]Epoch [20/1500], Loss: 2.063882\n",
      "Epoch [40/1500], Loss: 1.397326\n",
      "Epoch [60/1500], Loss: 0.936194\n",
      "Epoch [80/1500], Loss: 0.598574\n",
      "Epoch [100/1500], Loss: 0.355643\n",
      "Epoch [120/1500], Loss: 0.199722\n",
      "Epoch [140/1500], Loss: 0.110903\n",
      "Epoch [160/1500], Loss: 0.062368\n",
      "Epoch [180/1500], Loss: 0.034651\n",
      "Epoch [200/1500], Loss: 0.019711\n",
      "Epoch [220/1500], Loss: 0.010971\n",
      "Epoch [240/1500], Loss: 0.006147\n",
      "Epoch [260/1500], Loss: 0.004159\n",
      "Epoch [280/1500], Loss: 0.003510\n",
      "Epoch [300/1500], Loss: 0.003908\n",
      "Epoch [320/1500], Loss: 0.002959\n",
      "Epoch [340/1500], Loss: 0.002980\n",
      "Epoch [360/1500], Loss: 0.003963\n",
      "Epoch [380/1500], Loss: 0.002728\n",
      "Epoch [400/1500], Loss: 0.003047\n",
      "Epoch [420/1500], Loss: 0.004992\n",
      "Epoch [440/1500], Loss: 0.002731\n",
      "Epoch [460/1500], Loss: 0.003491\n",
      "Epoch [480/1500], Loss: 0.002654\n",
      "Epoch [500/1500], Loss: 0.003140\n",
      "Epoch [520/1500], Loss: 0.002709\n",
      "Epoch [540/1500], Loss: 0.003123\n",
      "Epoch [560/1500], Loss: 0.002723\n",
      "Epoch [580/1500], Loss: 0.003073\n",
      "Epoch [600/1500], Loss: 0.002858\n",
      "Epoch [620/1500], Loss: 0.003087\n",
      "Epoch [640/1500], Loss: 0.004366\n",
      "Epoch [660/1500], Loss: 0.003094\n",
      "Epoch [680/1500], Loss: 0.003766\n",
      "Epoch [700/1500], Loss: 0.003157\n",
      "Epoch [720/1500], Loss: 0.002633\n",
      "Epoch [740/1500], Loss: 0.003584\n",
      "Epoch [760/1500], Loss: 0.002697\n",
      "Epoch [780/1500], Loss: 0.003940\n",
      "Epoch [800/1500], Loss: 0.003047\n",
      "Epoch [820/1500], Loss: 0.002852\n",
      "Epoch [840/1500], Loss: 0.004007\n",
      "Epoch [860/1500], Loss: 0.002972\n",
      "Epoch [880/1500], Loss: 0.003300\n",
      "Epoch [900/1500], Loss: 0.003303\n",
      "Epoch [920/1500], Loss: 0.002619\n",
      "Epoch [940/1500], Loss: 0.003957\n",
      "Epoch [960/1500], Loss: 0.002883\n",
      "Epoch [980/1500], Loss: 0.004918\n",
      "Epoch [1000/1500], Loss: 0.003630\n",
      "Epoch [1020/1500], Loss: 0.002820\n",
      "Epoch [1040/1500], Loss: 0.005161\n",
      "Epoch [1060/1500], Loss: 0.003425\n",
      "Epoch [1080/1500], Loss: 0.002801\n",
      "Epoch [1100/1500], Loss: 0.003918\n",
      "Epoch [1120/1500], Loss: 0.002791\n",
      "Epoch [1140/1500], Loss: 0.002774\n",
      "Epoch [1160/1500], Loss: 0.002773\n",
      "Epoch [1180/1500], Loss: 0.002772\n",
      "Epoch [1200/1500], Loss: 0.002772\n",
      "Epoch [1220/1500], Loss: 0.002772\n",
      "Epoch [1240/1500], Loss: 0.002772\n",
      "Epoch [1260/1500], Loss: 0.002772\n",
      "Epoch [1280/1500], Loss: 0.002773\n",
      "Epoch [1300/1500], Loss: 0.002773\n",
      "Epoch [1320/1500], Loss: 0.002773\n",
      "Epoch [1340/1500], Loss: 0.002773\n",
      "Epoch [1360/1500], Loss: 0.002773\n",
      "Epoch [1380/1500], Loss: 0.002773\n",
      "Epoch [1400/1500], Loss: 0.002773\n",
      "Epoch [1420/1500], Loss: 0.002773\n",
      "Epoch [1440/1500], Loss: 0.002773\n",
      "Epoch [1460/1500], Loss: 0.002773\n",
      "Epoch [1480/1500], Loss: 0.002773\n",
      "Epoch [1500/1500], Loss: 0.002773\n",
      "tensor(0.0493, device='cuda:0')\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.481245 for selected strength\n",
      "We have a total strength of 1.605818 for all the columns\n",
      "Epoch [20/1500], Loss: 2.055527\n",
      "Epoch [40/1500], Loss: 1.381450\n",
      "Epoch [60/1500], Loss: 0.915808\n",
      "Epoch [80/1500], Loss: 0.576022\n",
      "Epoch [100/1500], Loss: 0.334748\n",
      "Epoch [120/1500], Loss: 0.182064\n",
      "Epoch [140/1500], Loss: 0.098100\n",
      "Epoch [160/1500], Loss: 0.052751\n",
      "Epoch [180/1500], Loss: 0.028400\n",
      "Epoch [200/1500], Loss: 0.015358\n",
      "Epoch [220/1500], Loss: 0.008925\n",
      "Epoch [240/1500], Loss: 0.005437\n",
      "Epoch [260/1500], Loss: 0.003994\n",
      "Epoch [280/1500], Loss: 0.003483\n",
      "Epoch [300/1500], Loss: 0.003884\n",
      "Epoch [320/1500], Loss: 0.003322\n",
      "Epoch [340/1500], Loss: 0.002745\n",
      "Epoch [360/1500], Loss: 0.003216\n",
      "Epoch [380/1500], Loss: 0.004318\n",
      "Epoch [400/1500], Loss: 0.002781\n",
      "Epoch [420/1500], Loss: 0.003452\n",
      "Epoch [440/1500], Loss: 0.002635\n",
      "Epoch [460/1500], Loss: 0.003098\n",
      "Epoch [480/1500], Loss: 0.002812\n",
      "Epoch [500/1500], Loss: 0.002969\n",
      "Epoch [520/1500], Loss: 0.003617\n",
      "Epoch [540/1500], Loss: 0.002831\n",
      "Epoch [560/1500], Loss: 0.004136\n",
      "Epoch [580/1500], Loss: 0.002710\n",
      "Epoch [600/1500], Loss: 0.003662\n",
      "Epoch [620/1500], Loss: 0.002657\n",
      "Epoch [640/1500], Loss: 0.003819\n",
      "Epoch [660/1500], Loss: 0.002942\n",
      "Epoch [680/1500], Loss: 0.004246\n",
      "Epoch [700/1500], Loss: 0.002760\n",
      "Epoch [720/1500], Loss: 0.005042\n",
      "Epoch [740/1500], Loss: 0.002837\n",
      "Epoch [760/1500], Loss: 0.005021\n",
      "Epoch [780/1500], Loss: 0.002838\n",
      "Epoch [800/1500], Loss: 0.004017\n",
      "Epoch [820/1500], Loss: 0.003021\n",
      "Epoch [840/1500], Loss: 0.002729\n",
      "Epoch [860/1500], Loss: 0.003569\n",
      "Epoch [880/1500], Loss: 0.002838\n",
      "Epoch [900/1500], Loss: 0.004927\n",
      "Epoch [920/1500], Loss: 0.003200\n",
      "Epoch [940/1500], Loss: 0.002482\n",
      "Epoch [960/1500], Loss: 0.003701\n",
      "Epoch [980/1500], Loss: 0.002818\n",
      "Epoch [1000/1500], Loss: 0.004133\n",
      "Epoch [1020/1500], Loss: 0.003204\n",
      "Epoch [1040/1500], Loss: 0.002586\n",
      "Epoch [1060/1500], Loss: 0.003899\n",
      "Epoch [1080/1500], Loss: 0.003005\n",
      "Epoch [1100/1500], Loss: 0.002588\n",
      "Epoch [1120/1500], Loss: 0.002601\n",
      "Epoch [1140/1500], Loss: 0.002579\n",
      "Epoch [1160/1500], Loss: 0.002577\n",
      "Epoch [1180/1500], Loss: 0.002577\n",
      "Epoch [1200/1500], Loss: 0.002576\n",
      "Epoch [1220/1500], Loss: 0.002574\n",
      "Epoch [1240/1500], Loss: 0.002573\n",
      "Epoch [1260/1500], Loss: 0.002572\n",
      "Epoch [1280/1500], Loss: 0.002572\n",
      "Epoch [1300/1500], Loss: 0.002574\n",
      "Epoch [1320/1500], Loss: 0.002572\n",
      "Epoch [1340/1500], Loss: 0.002571\n",
      "Epoch [1360/1500], Loss: 0.002571\n",
      "Epoch [1380/1500], Loss: 0.002571\n",
      "Epoch [1400/1500], Loss: 0.002572\n",
      "Epoch [1420/1500], Loss: 0.002572\n",
      "Epoch [1440/1500], Loss: 0.002572\n",
      "Epoch [1460/1500], Loss: 0.002572\n",
      "Epoch [1480/1500], Loss: 0.002572\n",
      "Epoch [1500/1500], Loss: 0.002572\n",
      "tensor(0.0614, device='cuda:0')\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.499791 for selected strength\n",
      "We have a total strength of 3.291394 for all the columns\n",
      "Epoch [20/1500], Loss: 2.056655\n",
      "Epoch [40/1500], Loss: 1.384598\n",
      "Epoch [60/1500], Loss: 0.919891\n",
      "Epoch [80/1500], Loss: 0.581307\n",
      "Epoch [100/1500], Loss: 0.341443\n",
      "Epoch [120/1500], Loss: 0.190146\n",
      "Epoch [140/1500], Loss: 0.106043\n",
      "Epoch [160/1500], Loss: 0.058899\n",
      "Epoch [180/1500], Loss: 0.032557\n",
      "Epoch [200/1500], Loss: 0.018101\n",
      "Epoch [220/1500], Loss: 0.010673\n",
      "Epoch [240/1500], Loss: 0.007165\n",
      "Epoch [260/1500], Loss: 0.005543\n",
      "Epoch [280/1500], Loss: 0.004494\n",
      "Epoch [300/1500], Loss: 0.003486\n",
      "Epoch [320/1500], Loss: 0.003639\n",
      "Epoch [340/1500], Loss: 0.004268\n",
      "Epoch [360/1500], Loss: 0.003236\n",
      "Epoch [380/1500], Loss: 0.003523\n",
      "Epoch [400/1500], Loss: 0.004450\n",
      "Epoch [420/1500], Loss: 0.003215\n",
      "Epoch [440/1500], Loss: 0.003858\n",
      "Epoch [460/1500], Loss: 0.003177\n",
      "Epoch [480/1500], Loss: 0.003813\n",
      "Epoch [500/1500], Loss: 0.003130\n",
      "Epoch [520/1500], Loss: 0.003633\n",
      "Epoch [540/1500], Loss: 0.003184\n",
      "Epoch [560/1500], Loss: 0.003709\n",
      "Epoch [580/1500], Loss: 0.003439\n",
      "Epoch [600/1500], Loss: 0.003439\n",
      "Epoch [620/1500], Loss: 0.004600\n",
      "Epoch [640/1500], Loss: 0.003609\n",
      "Epoch [660/1500], Loss: 0.003341\n",
      "Epoch [680/1500], Loss: 0.003807\n",
      "Epoch [700/1500], Loss: 0.003241\n",
      "Epoch [720/1500], Loss: 0.004299\n",
      "Epoch [740/1500], Loss: 0.003396\n",
      "Epoch [760/1500], Loss: 0.004564\n",
      "Epoch [780/1500], Loss: 0.003578\n",
      "Epoch [800/1500], Loss: 0.003179\n",
      "Epoch [820/1500], Loss: 0.004280\n",
      "Epoch [840/1500], Loss: 0.003384\n",
      "Epoch [860/1500], Loss: 0.005233\n",
      "Epoch [880/1500], Loss: 0.003675\n",
      "Epoch [900/1500], Loss: 0.003576\n",
      "Epoch [920/1500], Loss: 0.003939\n",
      "Epoch [940/1500], Loss: 0.003294\n",
      "Epoch [960/1500], Loss: 0.004433\n",
      "Epoch [980/1500], Loss: 0.003672\n",
      "Epoch [1000/1500], Loss: 0.003252\n",
      "Epoch [1020/1500], Loss: 0.004436\n",
      "Epoch [1040/1500], Loss: 0.003518\n",
      "Epoch [1060/1500], Loss: 0.003338\n",
      "Epoch [1080/1500], Loss: 0.004551\n",
      "Epoch [1100/1500], Loss: 0.003519\n",
      "Epoch [1120/1500], Loss: 0.003595\n",
      "Epoch [1140/1500], Loss: 0.003565\n",
      "Epoch [1160/1500], Loss: 0.003559\n",
      "Epoch [1180/1500], Loss: 0.003558\n",
      "Epoch [1200/1500], Loss: 0.003558\n",
      "Epoch [1220/1500], Loss: 0.003558\n",
      "Epoch [1240/1500], Loss: 0.003558\n",
      "Epoch [1260/1500], Loss: 0.003558\n",
      "Epoch [1280/1500], Loss: 0.003558\n",
      "Epoch [1300/1500], Loss: 0.003558\n",
      "Epoch [1320/1500], Loss: 0.003558\n",
      "Epoch [1340/1500], Loss: 0.003558\n",
      "Epoch [1360/1500], Loss: 0.003558\n",
      "Epoch [1380/1500], Loss: 0.003558\n",
      "Epoch [1400/1500], Loss: 0.003558\n",
      "Epoch [1420/1500], Loss: 0.003558\n",
      "Epoch [1440/1500], Loss: 0.003558\n",
      "Epoch [1460/1500], Loss: 0.003558\n",
      "Epoch [1480/1500], Loss: 0.003558\n",
      "Epoch [1500/1500], Loss: 0.003559\n",
      "tensor(0.0455, device='cuda:0')\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.675503 for selected strength\n",
      "We have a total strength of 2.669977 for all the columns\n",
      "Epoch [20/1500], Loss: 2.119650\n",
      "Epoch [40/1500], Loss: 1.470429\n",
      "Epoch [60/1500], Loss: 1.016938\n",
      "Epoch [80/1500], Loss: 0.680887\n",
      "Epoch [100/1500], Loss: 0.430500\n",
      "Epoch [120/1500], Loss: 0.256929\n",
      "Epoch [140/1500], Loss: 0.148390\n",
      "Epoch [160/1500], Loss: 0.085261\n",
      "Epoch [180/1500], Loss: 0.048872\n",
      "Epoch [200/1500], Loss: 0.027860\n",
      "Epoch [220/1500], Loss: 0.016552\n",
      "Epoch [240/1500], Loss: 0.009048\n",
      "Epoch [260/1500], Loss: 0.005689\n",
      "Epoch [280/1500], Loss: 0.004493\n",
      "Epoch [300/1500], Loss: 0.004165\n",
      "Epoch [320/1500], Loss: 0.005084\n",
      "Epoch [340/1500], Loss: 0.003152\n",
      "Epoch [360/1500], Loss: 0.003826\n",
      "Epoch [380/1500], Loss: 0.003243\n",
      "Epoch [400/1500], Loss: 0.003188\n",
      "Epoch [420/1500], Loss: 0.004334\n",
      "Epoch [440/1500], Loss: 0.003061\n",
      "Epoch [460/1500], Loss: 0.003972\n",
      "Epoch [480/1500], Loss: 0.002954\n",
      "Epoch [500/1500], Loss: 0.004332\n",
      "Epoch [520/1500], Loss: 0.002921\n",
      "Epoch [540/1500], Loss: 0.003897\n",
      "Epoch [560/1500], Loss: 0.003064\n",
      "Epoch [580/1500], Loss: 0.004042\n",
      "Epoch [600/1500], Loss: 0.003220\n",
      "Epoch [620/1500], Loss: 0.003501\n",
      "Epoch [640/1500], Loss: 0.003399\n",
      "Epoch [660/1500], Loss: 0.002978\n",
      "Epoch [680/1500], Loss: 0.003985\n",
      "Epoch [700/1500], Loss: 0.003358\n",
      "Epoch [720/1500], Loss: 0.003114\n",
      "Epoch [740/1500], Loss: 0.003713\n",
      "Epoch [760/1500], Loss: 0.003012\n",
      "Epoch [780/1500], Loss: 0.004158\n",
      "Epoch [800/1500], Loss: 0.003148\n",
      "Epoch [820/1500], Loss: 0.002958\n",
      "Epoch [840/1500], Loss: 0.004490\n",
      "Epoch [860/1500], Loss: 0.003373\n",
      "Epoch [880/1500], Loss: 0.003054\n",
      "Epoch [900/1500], Loss: 0.004670\n",
      "Epoch [920/1500], Loss: 0.003855\n",
      "Epoch [940/1500], Loss: 0.003176\n",
      "Epoch [960/1500], Loss: 0.004812\n",
      "Epoch [980/1500], Loss: 0.003786\n",
      "Epoch [1000/1500], Loss: 0.003229\n",
      "Epoch [1020/1500], Loss: 0.003019\n",
      "Epoch [1040/1500], Loss: 0.003994\n",
      "Epoch [1060/1500], Loss: 0.003242\n",
      "Epoch [1080/1500], Loss: 0.002988\n",
      "Epoch [1100/1500], Loss: 0.004506\n",
      "Epoch [1120/1500], Loss: 0.002960\n",
      "Epoch [1140/1500], Loss: 0.002935\n",
      "Epoch [1160/1500], Loss: 0.002932\n",
      "Epoch [1180/1500], Loss: 0.002932\n",
      "Epoch [1200/1500], Loss: 0.002932\n",
      "Epoch [1220/1500], Loss: 0.002932\n",
      "Epoch [1240/1500], Loss: 0.002932\n",
      "Epoch [1260/1500], Loss: 0.002932\n",
      "Epoch [1280/1500], Loss: 0.002932\n",
      "Epoch [1300/1500], Loss: 0.002932\n",
      "Epoch [1320/1500], Loss: 0.002932\n",
      "Epoch [1340/1500], Loss: 0.002932\n",
      "Epoch [1360/1500], Loss: 0.002932\n",
      "Epoch [1380/1500], Loss: 0.002932\n",
      "Epoch [1400/1500], Loss: 0.002932\n",
      "Epoch [1420/1500], Loss: 0.002932\n",
      "Epoch [1440/1500], Loss: 0.002932\n",
      "Epoch [1460/1500], Loss: 0.002932\n",
      "Epoch [1480/1500], Loss: 0.002932\n",
      "Epoch [1500/1500], Loss: 0.002932\n",
      "tensor(0.0513, device='cuda:0')\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.538768 for selected strength\n",
      "We have a total strength of 1.886787 for all the columns\n",
      "Epoch [20/1500], Loss: 2.064144\n",
      "Epoch [40/1500], Loss: 1.410882\n",
      "Epoch [60/1500], Loss: 0.956206\n",
      "Epoch [80/1500], Loss: 0.621065\n",
      "Epoch [100/1500], Loss: 0.378517\n",
      "Epoch [120/1500], Loss: 0.220538\n",
      "Epoch [140/1500], Loss: 0.129106\n",
      "Epoch [160/1500], Loss: 0.075671\n",
      "Epoch [180/1500], Loss: 0.044311\n",
      "Epoch [200/1500], Loss: 0.025813\n",
      "Epoch [220/1500], Loss: 0.015632\n",
      "Epoch [240/1500], Loss: 0.010684\n",
      "Epoch [260/1500], Loss: 0.008004\n",
      "Epoch [280/1500], Loss: 0.005645\n",
      "Epoch [300/1500], Loss: 0.003970\n",
      "Epoch [320/1500], Loss: 0.003964\n",
      "Epoch [340/1500], Loss: 0.005378\n",
      "Epoch [360/1500], Loss: 0.003522\n",
      "Epoch [380/1500], Loss: 0.003863\n",
      "Epoch [400/1500], Loss: 0.005924\n",
      "Epoch [420/1500], Loss: 0.003548\n",
      "Epoch [440/1500], Loss: 0.004330\n",
      "Epoch [460/1500], Loss: 0.003557\n",
      "Epoch [480/1500], Loss: 0.004407\n",
      "Epoch [500/1500], Loss: 0.003445\n",
      "Epoch [520/1500], Loss: 0.004508\n",
      "Epoch [540/1500], Loss: 0.003557\n",
      "Epoch [560/1500], Loss: 0.004288\n",
      "Epoch [580/1500], Loss: 0.003591\n",
      "Epoch [600/1500], Loss: 0.005468\n",
      "Epoch [620/1500], Loss: 0.003795\n",
      "Epoch [640/1500], Loss: 0.005219\n",
      "Epoch [660/1500], Loss: 0.003650\n",
      "Epoch [680/1500], Loss: 0.005409\n",
      "Epoch [700/1500], Loss: 0.004046\n",
      "Epoch [720/1500], Loss: 0.003494\n",
      "Epoch [740/1500], Loss: 0.004172\n",
      "Epoch [760/1500], Loss: 0.003767\n",
      "Epoch [780/1500], Loss: 0.005032\n",
      "Epoch [800/1500], Loss: 0.003893\n",
      "Epoch [820/1500], Loss: 0.003508\n",
      "Epoch [840/1500], Loss: 0.004285\n",
      "Epoch [860/1500], Loss: 0.003631\n",
      "Epoch [880/1500], Loss: 0.005012\n",
      "Epoch [900/1500], Loss: 0.003804\n",
      "Epoch [920/1500], Loss: 0.003831\n",
      "Epoch [940/1500], Loss: 0.004250\n",
      "Epoch [960/1500], Loss: 0.003654\n",
      "Epoch [980/1500], Loss: 0.005799\n",
      "Epoch [1000/1500], Loss: 0.003985\n",
      "Epoch [1020/1500], Loss: 0.003488\n",
      "Epoch [1040/1500], Loss: 0.004621\n",
      "Epoch [1060/1500], Loss: 0.003595\n",
      "Epoch [1080/1500], Loss: 0.003685\n",
      "Epoch [1100/1500], Loss: 0.004504\n",
      "Epoch [1120/1500], Loss: 0.003859\n",
      "Epoch [1140/1500], Loss: 0.003821\n",
      "Epoch [1160/1500], Loss: 0.003817\n",
      "Epoch [1180/1500], Loss: 0.003816\n",
      "Epoch [1200/1500], Loss: 0.003816\n",
      "Epoch [1220/1500], Loss: 0.003816\n",
      "Epoch [1240/1500], Loss: 0.003816\n",
      "Epoch [1260/1500], Loss: 0.003816\n",
      "Epoch [1280/1500], Loss: 0.003816\n",
      "Epoch [1300/1500], Loss: 0.003816\n",
      "Epoch [1320/1500], Loss: 0.003816\n",
      "Epoch [1340/1500], Loss: 0.003816\n",
      "Epoch [1360/1500], Loss: 0.003816\n",
      "Epoch [1380/1500], Loss: 0.003816\n",
      "Epoch [1400/1500], Loss: 0.003816\n",
      "Epoch [1420/1500], Loss: 0.003816\n",
      "Epoch [1440/1500], Loss: 0.003816\n",
      "Epoch [1460/1500], Loss: 0.003816\n",
      "Epoch [1480/1500], Loss: 0.003817\n",
      "Epoch [1500/1500], Loss: 0.003817\n",
      "tensor(0.0409, device='cuda:0')\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.813650 for selected strength\n",
      "We have a total strength of 2.677775 for all the columns\n",
      "Epoch [20/1500], Loss: 2.085052\n",
      "Epoch [40/1500], Loss: 1.435452\n",
      "Epoch [60/1500], Loss: 0.980653\n",
      "Epoch [80/1500], Loss: 0.643795\n",
      "Epoch [100/1500], Loss: 0.396442\n",
      "Epoch [120/1500], Loss: 0.230303\n",
      "Epoch [140/1500], Loss: 0.131744\n",
      "Epoch [160/1500], Loss: 0.074729\n",
      "Epoch [180/1500], Loss: 0.041263\n",
      "Epoch [200/1500], Loss: 0.022265\n",
      "Epoch [220/1500], Loss: 0.012407\n",
      "Epoch [240/1500], Loss: 0.007025\n",
      "Epoch [260/1500], Loss: 0.004669\n",
      "Epoch [280/1500], Loss: 0.003607\n",
      "Epoch [300/1500], Loss: 0.003502\n",
      "Epoch [320/1500], Loss: 0.003826\n",
      "Epoch [340/1500], Loss: 0.002878\n",
      "Epoch [360/1500], Loss: 0.002853\n",
      "Epoch [380/1500], Loss: 0.003518\n",
      "Epoch [400/1500], Loss: 0.002693\n",
      "Epoch [420/1500], Loss: 0.002949\n",
      "Epoch [440/1500], Loss: 0.003893\n",
      "Epoch [460/1500], Loss: 0.002805\n",
      "Epoch [480/1500], Loss: 0.003332\n",
      "Epoch [500/1500], Loss: 0.002849\n",
      "Epoch [520/1500], Loss: 0.003157\n",
      "Epoch [540/1500], Loss: 0.004040\n",
      "Epoch [560/1500], Loss: 0.003038\n",
      "Epoch [580/1500], Loss: 0.004356\n",
      "Epoch [600/1500], Loss: 0.002863\n",
      "Epoch [620/1500], Loss: 0.004845\n",
      "Epoch [640/1500], Loss: 0.003237\n",
      "Epoch [660/1500], Loss: 0.002556\n",
      "Epoch [680/1500], Loss: 0.003681\n",
      "Epoch [700/1500], Loss: 0.002739\n",
      "Epoch [720/1500], Loss: 0.004006\n",
      "Epoch [740/1500], Loss: 0.002743\n",
      "Epoch [760/1500], Loss: 0.003648\n",
      "Epoch [780/1500], Loss: 0.002913\n",
      "Epoch [800/1500], Loss: 0.004515\n",
      "Epoch [820/1500], Loss: 0.003193\n",
      "Epoch [840/1500], Loss: 0.002590\n",
      "Epoch [860/1500], Loss: 0.003704\n",
      "Epoch [880/1500], Loss: 0.002660\n",
      "Epoch [900/1500], Loss: 0.003983\n",
      "Epoch [920/1500], Loss: 0.002921\n",
      "Epoch [940/1500], Loss: 0.003196\n",
      "Epoch [960/1500], Loss: 0.003431\n",
      "Epoch [980/1500], Loss: 0.002734\n",
      "Epoch [1000/1500], Loss: 0.004203\n",
      "Epoch [1020/1500], Loss: 0.002906\n",
      "Epoch [1040/1500], Loss: 0.003077\n",
      "Epoch [1060/1500], Loss: 0.003650\n",
      "Epoch [1080/1500], Loss: 0.002812\n",
      "Epoch [1100/1500], Loss: 0.004097\n",
      "Epoch [1120/1500], Loss: 0.002747\n",
      "Epoch [1140/1500], Loss: 0.002723\n",
      "Epoch [1160/1500], Loss: 0.002721\n",
      "Epoch [1180/1500], Loss: 0.002720\n",
      "Epoch [1200/1500], Loss: 0.002720\n",
      "Epoch [1220/1500], Loss: 0.002720\n",
      "Epoch [1240/1500], Loss: 0.002720\n",
      "Epoch [1260/1500], Loss: 0.002720\n",
      "Epoch [1280/1500], Loss: 0.002720\n",
      "Epoch [1300/1500], Loss: 0.002720\n",
      "Epoch [1320/1500], Loss: 0.002720\n",
      "Epoch [1340/1500], Loss: 0.002721\n",
      "Epoch [1360/1500], Loss: 0.002721\n",
      "Epoch [1380/1500], Loss: 0.002721\n",
      "Epoch [1400/1500], Loss: 0.002721\n",
      "Epoch [1420/1500], Loss: 0.002721\n",
      "Epoch [1440/1500], Loss: 0.002721\n",
      "Epoch [1460/1500], Loss: 0.002721\n",
      "Epoch [1480/1500], Loss: 0.002721\n",
      "Epoch [1500/1500], Loss: 0.002721\n",
      "tensor(0.0360, device='cuda:0')\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.529248 for selected strength\n",
      "We have a total strength of 1.842966 for all the columns\n",
      "Epoch [20/1500], Loss: 2.045354\n",
      "Epoch [40/1500], Loss: 1.368712\n",
      "Epoch [60/1500], Loss: 0.901475\n",
      "Epoch [80/1500], Loss: 0.562187\n",
      "Epoch [100/1500], Loss: 0.324071\n",
      "Epoch [120/1500], Loss: 0.176952\n",
      "Epoch [140/1500], Loss: 0.096864\n",
      "Epoch [160/1500], Loss: 0.053424\n",
      "Epoch [180/1500], Loss: 0.029772\n",
      "Epoch [200/1500], Loss: 0.016810\n",
      "Epoch [220/1500], Loss: 0.009985\n",
      "Epoch [240/1500], Loss: 0.006478\n",
      "Epoch [260/1500], Loss: 0.005052\n",
      "Epoch [280/1500], Loss: 0.004732\n",
      "Epoch [300/1500], Loss: 0.003535\n",
      "Epoch [320/1500], Loss: 0.003551\n",
      "Epoch [340/1500], Loss: 0.004205\n",
      "Epoch [360/1500], Loss: 0.003342\n",
      "Epoch [380/1500], Loss: 0.003500\n",
      "Epoch [400/1500], Loss: 0.004876\n",
      "Epoch [420/1500], Loss: 0.003397\n",
      "Epoch [440/1500], Loss: 0.004342\n",
      "Epoch [460/1500], Loss: 0.003308\n",
      "Epoch [480/1500], Loss: 0.003686\n",
      "Epoch [500/1500], Loss: 0.003837\n",
      "Epoch [520/1500], Loss: 0.003524\n",
      "Epoch [540/1500], Loss: 0.003435\n",
      "Epoch [560/1500], Loss: 0.003570\n",
      "Epoch [580/1500], Loss: 0.005447\n",
      "Epoch [600/1500], Loss: 0.003523\n",
      "Epoch [620/1500], Loss: 0.004269\n",
      "Epoch [640/1500], Loss: 0.003694\n",
      "Epoch [660/1500], Loss: 0.003277\n",
      "Epoch [680/1500], Loss: 0.003923\n",
      "Epoch [700/1500], Loss: 0.003289\n",
      "Epoch [720/1500], Loss: 0.004229\n",
      "Epoch [740/1500], Loss: 0.003460\n",
      "Epoch [760/1500], Loss: 0.004489\n",
      "Epoch [780/1500], Loss: 0.003477\n",
      "Epoch [800/1500], Loss: 0.003362\n",
      "Epoch [820/1500], Loss: 0.004101\n",
      "Epoch [840/1500], Loss: 0.003284\n",
      "Epoch [860/1500], Loss: 0.004116\n",
      "Epoch [880/1500], Loss: 0.003466\n",
      "Epoch [900/1500], Loss: 0.003615\n",
      "Epoch [920/1500], Loss: 0.004007\n",
      "Epoch [940/1500], Loss: 0.003315\n",
      "Epoch [960/1500], Loss: 0.004742\n",
      "Epoch [980/1500], Loss: 0.003679\n",
      "Epoch [1000/1500], Loss: 0.003359\n",
      "Epoch [1020/1500], Loss: 0.004286\n",
      "Epoch [1040/1500], Loss: 0.003473\n",
      "Epoch [1060/1500], Loss: 0.003565\n",
      "Epoch [1080/1500], Loss: 0.004108\n",
      "Epoch [1100/1500], Loss: 0.003399\n",
      "Epoch [1120/1500], Loss: 0.003689\n",
      "Epoch [1140/1500], Loss: 0.003667\n",
      "Epoch [1160/1500], Loss: 0.003657\n",
      "Epoch [1180/1500], Loss: 0.003655\n",
      "Epoch [1200/1500], Loss: 0.003652\n",
      "Epoch [1220/1500], Loss: 0.003652\n",
      "Epoch [1240/1500], Loss: 0.003652\n",
      "Epoch [1260/1500], Loss: 0.003651\n",
      "Epoch [1280/1500], Loss: 0.003652\n",
      "Epoch [1300/1500], Loss: 0.003651\n",
      "Epoch [1320/1500], Loss: 0.003650\n",
      "Epoch [1340/1500], Loss: 0.003651\n",
      "Epoch [1360/1500], Loss: 0.003651\n",
      "Epoch [1380/1500], Loss: 0.003650\n",
      "Epoch [1400/1500], Loss: 0.003649\n",
      "Epoch [1420/1500], Loss: 0.003649\n",
      "Epoch [1440/1500], Loss: 0.003649\n",
      "Epoch [1460/1500], Loss: 0.003649\n",
      "Epoch [1480/1500], Loss: 0.003649\n",
      "Epoch [1500/1500], Loss: 0.003649\n",
      "tensor(0.0470, device='cuda:0')\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.672809 for selected strength\n",
      "We have a total strength of 2.927828 for all the columns\n",
      "Epoch [20/1500], Loss: 2.100701\n",
      "Epoch [40/1500], Loss: 1.453936\n",
      "Epoch [60/1500], Loss: 0.997834\n",
      "Epoch [80/1500], Loss: 0.658151\n",
      "Epoch [100/1500], Loss: 0.405504\n",
      "Epoch [120/1500], Loss: 0.232484\n",
      "Epoch [140/1500], Loss: 0.128886\n",
      "Epoch [160/1500], Loss: 0.070024\n",
      "Epoch [180/1500], Loss: 0.037607\n",
      "Epoch [200/1500], Loss: 0.020121\n",
      "Epoch [220/1500], Loss: 0.010945\n",
      "Epoch [240/1500], Loss: 0.006515\n",
      "Epoch [260/1500], Loss: 0.004515\n",
      "Epoch [280/1500], Loss: 0.003664\n",
      "Epoch [300/1500], Loss: 0.003485\n",
      "Epoch [320/1500], Loss: 0.003995\n",
      "Epoch [340/1500], Loss: 0.003237\n",
      "Epoch [360/1500], Loss: 0.003108\n",
      "Epoch [380/1500], Loss: 0.003653\n",
      "Epoch [400/1500], Loss: 0.003533\n",
      "Epoch [420/1500], Loss: 0.003083\n",
      "Epoch [440/1500], Loss: 0.004037\n",
      "Epoch [460/1500], Loss: 0.003130\n",
      "Epoch [480/1500], Loss: 0.003366\n",
      "Epoch [500/1500], Loss: 0.003232\n",
      "Epoch [520/1500], Loss: 0.003425\n",
      "Epoch [540/1500], Loss: 0.004753\n",
      "Epoch [560/1500], Loss: 0.003494\n",
      "Epoch [580/1500], Loss: 0.003459\n",
      "Epoch [600/1500], Loss: 0.003288\n",
      "Epoch [620/1500], Loss: 0.004393\n",
      "Epoch [640/1500], Loss: 0.003447\n",
      "Epoch [660/1500], Loss: 0.002992\n",
      "Epoch [680/1500], Loss: 0.003529\n",
      "Epoch [700/1500], Loss: 0.003130\n",
      "Epoch [720/1500], Loss: 0.003656\n",
      "Epoch [740/1500], Loss: 0.002980\n",
      "Epoch [760/1500], Loss: 0.003813\n",
      "Epoch [780/1500], Loss: 0.003119\n",
      "Epoch [800/1500], Loss: 0.004231\n",
      "Epoch [820/1500], Loss: 0.003167\n",
      "Epoch [840/1500], Loss: 0.003553\n",
      "Epoch [860/1500], Loss: 0.003723\n",
      "Epoch [880/1500], Loss: 0.003096\n",
      "Epoch [900/1500], Loss: 0.004130\n",
      "Epoch [920/1500], Loss: 0.003249\n",
      "Epoch [940/1500], Loss: 0.003442\n",
      "Epoch [960/1500], Loss: 0.003636\n",
      "Epoch [980/1500], Loss: 0.002934\n",
      "Epoch [1000/1500], Loss: 0.004282\n",
      "Epoch [1020/1500], Loss: 0.002993\n",
      "Epoch [1040/1500], Loss: 0.004160\n",
      "Epoch [1060/1500], Loss: 0.003431\n",
      "Epoch [1080/1500], Loss: 0.002961\n",
      "Epoch [1100/1500], Loss: 0.004288\n",
      "Epoch [1120/1500], Loss: 0.003181\n",
      "Epoch [1140/1500], Loss: 0.003154\n",
      "Epoch [1160/1500], Loss: 0.003149\n",
      "Epoch [1180/1500], Loss: 0.003147\n",
      "Epoch [1200/1500], Loss: 0.003147\n",
      "Epoch [1220/1500], Loss: 0.003147\n",
      "Epoch [1240/1500], Loss: 0.003147\n",
      "Epoch [1260/1500], Loss: 0.003147\n",
      "Epoch [1280/1500], Loss: 0.003147\n",
      "Epoch [1300/1500], Loss: 0.003147\n",
      "Epoch [1320/1500], Loss: 0.003147\n",
      "Epoch [1340/1500], Loss: 0.003147\n",
      "Epoch [1360/1500], Loss: 0.003147\n",
      "Epoch [1380/1500], Loss: 0.003147\n",
      "Epoch [1400/1500], Loss: 0.003147\n",
      "Epoch [1420/1500], Loss: 0.003147\n",
      "Epoch [1440/1500], Loss: 0.003148\n",
      "Epoch [1460/1500], Loss: 0.003148\n",
      "Epoch [1480/1500], Loss: 0.003148\n",
      "Epoch [1500/1500], Loss: 0.003148\n",
      "tensor(0.0468, device='cuda:0')\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.621077 for selected strength\n",
      "We have a total strength of 2.206841 for all the columns\n",
      "Epoch [20/1500], Loss: 2.087992\n",
      "Epoch [40/1500], Loss: 1.377832\n",
      "Epoch [60/1500], Loss: 0.887384\n",
      "Epoch [80/1500], Loss: 0.547075\n",
      "Epoch [100/1500], Loss: 0.309547\n",
      "Epoch [120/1500], Loss: 0.162054\n",
      "Epoch [140/1500], Loss: 0.082755\n",
      "Epoch [160/1500], Loss: 0.042645\n",
      "Epoch [180/1500], Loss: 0.020959\n",
      "Epoch [200/1500], Loss: 0.010972\n",
      "Epoch [220/1500], Loss: 0.006760\n",
      "Epoch [240/1500], Loss: 0.005930\n",
      "Epoch [260/1500], Loss: 0.003270\n",
      "Epoch [280/1500], Loss: 0.003720\n",
      "Epoch [300/1500], Loss: 0.002471\n",
      "Epoch [320/1500], Loss: 0.003704\n",
      "Epoch [340/1500], Loss: 0.002472\n",
      "Epoch [360/1500], Loss: 0.003791\n",
      "Epoch [380/1500], Loss: 0.002386\n",
      "Epoch [400/1500], Loss: 0.004504\n",
      "Epoch [420/1500], Loss: 0.002751\n",
      "Epoch [440/1500], Loss: 0.003745\n",
      "Epoch [460/1500], Loss: 0.003342\n",
      "Epoch [480/1500], Loss: 0.002379\n",
      "Epoch [500/1500], Loss: 0.004433\n",
      "Epoch [520/1500], Loss: 0.002735\n",
      "Epoch [540/1500], Loss: 0.002669\n",
      "Epoch [560/1500], Loss: 0.003790\n",
      "Epoch [580/1500], Loss: 0.002713\n",
      "Epoch [600/1500], Loss: 0.003301\n",
      "Epoch [620/1500], Loss: 0.003802\n",
      "Epoch [640/1500], Loss: 0.002818\n",
      "Epoch [660/1500], Loss: 0.002278\n",
      "Epoch [680/1500], Loss: 0.004850\n",
      "Epoch [700/1500], Loss: 0.002673\n",
      "Epoch [720/1500], Loss: 0.002321\n",
      "Epoch [740/1500], Loss: 0.004396\n",
      "Epoch [760/1500], Loss: 0.002812\n",
      "Epoch [780/1500], Loss: 0.002438\n",
      "Epoch [800/1500], Loss: 0.002549\n",
      "Epoch [820/1500], Loss: 0.003988\n",
      "Epoch [840/1500], Loss: 0.003465\n",
      "Epoch [860/1500], Loss: 0.002337\n",
      "Epoch [880/1500], Loss: 0.004387\n",
      "Epoch [900/1500], Loss: 0.003172\n",
      "Epoch [920/1500], Loss: 0.002801\n",
      "Epoch [940/1500], Loss: 0.002405\n",
      "Epoch [960/1500], Loss: 0.005606\n",
      "Epoch [980/1500], Loss: 0.003645\n",
      "Epoch [1000/1500], Loss: 0.002966\n",
      "Epoch [1020/1500], Loss: 0.002620\n",
      "Epoch [1040/1500], Loss: 0.002290\n",
      "Epoch [1060/1500], Loss: 0.004339\n",
      "Epoch [1080/1500], Loss: 0.003918\n",
      "Epoch [1100/1500], Loss: 0.003329\n",
      "Epoch [1120/1500], Loss: 0.002170\n",
      "Epoch [1140/1500], Loss: 0.002163\n",
      "Epoch [1160/1500], Loss: 0.002160\n",
      "Epoch [1180/1500], Loss: 0.002159\n",
      "Epoch [1200/1500], Loss: 0.002158\n",
      "Epoch [1220/1500], Loss: 0.002157\n",
      "Epoch [1240/1500], Loss: 0.002157\n",
      "Epoch [1260/1500], Loss: 0.002157\n",
      "Epoch [1280/1500], Loss: 0.002157\n",
      "Epoch [1300/1500], Loss: 0.002157\n",
      "Epoch [1320/1500], Loss: 0.002157\n",
      "Epoch [1340/1500], Loss: 0.002157\n",
      "Epoch [1360/1500], Loss: 0.002158\n",
      "Epoch [1380/1500], Loss: 0.002158\n",
      "Epoch [1400/1500], Loss: 0.002158\n",
      "Epoch [1420/1500], Loss: 0.002158\n",
      "Epoch [1440/1500], Loss: 0.002157\n",
      "Epoch [1460/1500], Loss: 0.002158\n",
      "Epoch [1480/1500], Loss: 0.002158\n",
      "Epoch [1500/1500], Loss: 0.002158\n",
      "tensor(0.0527, device='cuda:0')\n",
      "tensor(0.0447, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.200760 for selected strength\n",
      "We have a total strength of 1.092572 for all the columns\n",
      "Epoch [20/1500], Loss: 2.045545\n",
      "Epoch [40/1500], Loss: 1.373405\n",
      "Epoch [60/1500], Loss: 0.904068\n",
      "Epoch [80/1500], Loss: 0.562226\n",
      "Epoch [100/1500], Loss: 0.321209\n",
      "Epoch [120/1500], Loss: 0.172211\n",
      "Epoch [140/1500], Loss: 0.092348\n",
      "Epoch [160/1500], Loss: 0.049752\n",
      "Epoch [180/1500], Loss: 0.027772\n",
      "Epoch [200/1500], Loss: 0.016641\n",
      "Epoch [220/1500], Loss: 0.008958\n",
      "Epoch [240/1500], Loss: 0.005337\n",
      "Epoch [260/1500], Loss: 0.003834\n",
      "Epoch [280/1500], Loss: 0.003335\n",
      "Epoch [300/1500], Loss: 0.003434\n",
      "Epoch [320/1500], Loss: 0.004830\n",
      "Epoch [340/1500], Loss: 0.002803\n",
      "Epoch [360/1500], Loss: 0.003061\n",
      "Epoch [380/1500], Loss: 0.004382\n",
      "Epoch [400/1500], Loss: 0.002753\n",
      "Epoch [420/1500], Loss: 0.003347\n",
      "Epoch [440/1500], Loss: 0.002816\n",
      "Epoch [460/1500], Loss: 0.003082\n",
      "Epoch [480/1500], Loss: 0.004129\n",
      "Epoch [500/1500], Loss: 0.002896\n",
      "Epoch [520/1500], Loss: 0.003675\n",
      "Epoch [540/1500], Loss: 0.002875\n",
      "Epoch [560/1500], Loss: 0.003670\n",
      "Epoch [580/1500], Loss: 0.002938\n",
      "Epoch [600/1500], Loss: 0.003554\n",
      "Epoch [620/1500], Loss: 0.002679\n",
      "Epoch [640/1500], Loss: 0.003570\n",
      "Epoch [660/1500], Loss: 0.002877\n",
      "Epoch [680/1500], Loss: 0.003680\n",
      "Epoch [700/1500], Loss: 0.002941\n",
      "Epoch [720/1500], Loss: 0.004014\n",
      "Epoch [740/1500], Loss: 0.002943\n",
      "Epoch [760/1500], Loss: 0.003053\n",
      "Epoch [780/1500], Loss: 0.003167\n",
      "Epoch [800/1500], Loss: 0.002748\n",
      "Epoch [820/1500], Loss: 0.003820\n",
      "Epoch [840/1500], Loss: 0.003062\n",
      "Epoch [860/1500], Loss: 0.002737\n",
      "Epoch [880/1500], Loss: 0.003441\n",
      "Epoch [900/1500], Loss: 0.002817\n",
      "Epoch [920/1500], Loss: 0.004056\n",
      "Epoch [940/1500], Loss: 0.002877\n",
      "Epoch [960/1500], Loss: 0.003787\n",
      "Epoch [980/1500], Loss: 0.003106\n",
      "Epoch [1000/1500], Loss: 0.002626\n",
      "Epoch [1020/1500], Loss: 0.003428\n",
      "Epoch [1040/1500], Loss: 0.002818\n",
      "Epoch [1060/1500], Loss: 0.004056\n",
      "Epoch [1080/1500], Loss: 0.003128\n",
      "Epoch [1100/1500], Loss: 0.002823\n",
      "Epoch [1120/1500], Loss: 0.002898\n",
      "Epoch [1140/1500], Loss: 0.002882\n",
      "Epoch [1160/1500], Loss: 0.002880\n",
      "Epoch [1180/1500], Loss: 0.002878\n",
      "Epoch [1200/1500], Loss: 0.002879\n",
      "Epoch [1220/1500], Loss: 0.002875\n",
      "Epoch [1240/1500], Loss: 0.002874\n",
      "Epoch [1260/1500], Loss: 0.002873\n",
      "Epoch [1280/1500], Loss: 0.002873\n",
      "Epoch [1300/1500], Loss: 0.002873\n",
      "Epoch [1320/1500], Loss: 0.002873\n",
      "Epoch [1340/1500], Loss: 0.002873\n",
      "Epoch [1360/1500], Loss: 0.002873\n",
      "Epoch [1380/1500], Loss: 0.002873\n",
      "Epoch [1400/1500], Loss: 0.002873\n",
      "Epoch [1420/1500], Loss: 0.002873\n",
      "Epoch [1440/1500], Loss: 0.002873\n",
      "Epoch [1460/1500], Loss: 0.002873\n",
      "Epoch [1480/1500], Loss: 0.002873\n",
      "Epoch [1500/1500], Loss: 0.002873\n",
      "tensor(0.0313, device='cuda:0')\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.526736 for selected strength\n",
      "We have a total strength of 3.307301 for all the columns\n",
      "Epoch [20/1500], Loss: 2.031561\n",
      "Epoch [40/1500], Loss: 1.346672\n",
      "Epoch [60/1500], Loss: 0.872328\n",
      "Epoch [80/1500], Loss: 0.529567\n",
      "Epoch [100/1500], Loss: 0.292050\n",
      "Epoch [120/1500], Loss: 0.149439\n",
      "Epoch [140/1500], Loss: 0.076208\n",
      "Epoch [160/1500], Loss: 0.039187\n",
      "Epoch [180/1500], Loss: 0.021473\n",
      "Epoch [200/1500], Loss: 0.011424\n",
      "Epoch [220/1500], Loss: 0.006049\n",
      "Epoch [240/1500], Loss: 0.003870\n",
      "Epoch [260/1500], Loss: 0.003188\n",
      "Epoch [280/1500], Loss: 0.003025\n",
      "Epoch [300/1500], Loss: 0.003972\n",
      "Epoch [320/1500], Loss: 0.002335\n",
      "Epoch [340/1500], Loss: 0.002723\n",
      "Epoch [360/1500], Loss: 0.003210\n",
      "Epoch [380/1500], Loss: 0.002269\n",
      "Epoch [400/1500], Loss: 0.002548\n",
      "Epoch [420/1500], Loss: 0.003256\n",
      "Epoch [440/1500], Loss: 0.002355\n",
      "Epoch [460/1500], Loss: 0.002807\n",
      "Epoch [480/1500], Loss: 0.002534\n",
      "Epoch [500/1500], Loss: 0.002608\n",
      "Epoch [520/1500], Loss: 0.003985\n",
      "Epoch [540/1500], Loss: 0.002444\n",
      "Epoch [560/1500], Loss: 0.004111\n",
      "Epoch [580/1500], Loss: 0.002536\n",
      "Epoch [600/1500], Loss: 0.003877\n",
      "Epoch [620/1500], Loss: 0.002559\n",
      "Epoch [640/1500], Loss: 0.004235\n",
      "Epoch [660/1500], Loss: 0.002460\n",
      "Epoch [680/1500], Loss: 0.004116\n",
      "Epoch [700/1500], Loss: 0.002618\n",
      "Epoch [720/1500], Loss: 0.004108\n",
      "Epoch [740/1500], Loss: 0.002556\n",
      "Epoch [760/1500], Loss: 0.004455\n",
      "Epoch [780/1500], Loss: 0.002809\n",
      "Epoch [800/1500], Loss: 0.002337\n",
      "Epoch [820/1500], Loss: 0.002900\n",
      "Epoch [840/1500], Loss: 0.002420\n",
      "Epoch [860/1500], Loss: 0.003492\n",
      "Epoch [880/1500], Loss: 0.002567\n",
      "Epoch [900/1500], Loss: 0.004549\n",
      "Epoch [920/1500], Loss: 0.003074\n",
      "Epoch [940/1500], Loss: 0.002655\n",
      "Epoch [960/1500], Loss: 0.004619\n",
      "Epoch [980/1500], Loss: 0.002960\n",
      "Epoch [1000/1500], Loss: 0.002231\n",
      "Epoch [1020/1500], Loss: 0.003776\n",
      "Epoch [1040/1500], Loss: 0.002531\n",
      "Epoch [1060/1500], Loss: 0.002806\n",
      "Epoch [1080/1500], Loss: 0.003062\n",
      "Epoch [1100/1500], Loss: 0.002523\n",
      "Epoch [1120/1500], Loss: 0.002339\n",
      "Epoch [1140/1500], Loss: 0.002325\n",
      "Epoch [1160/1500], Loss: 0.002323\n",
      "Epoch [1180/1500], Loss: 0.002324\n",
      "Epoch [1200/1500], Loss: 0.002323\n",
      "Epoch [1220/1500], Loss: 0.002323\n",
      "Epoch [1240/1500], Loss: 0.002323\n",
      "Epoch [1260/1500], Loss: 0.002322\n",
      "Epoch [1280/1500], Loss: 0.002322\n",
      "Epoch [1300/1500], Loss: 0.002322\n",
      "Epoch [1320/1500], Loss: 0.002323\n",
      "Epoch [1340/1500], Loss: 0.002323\n",
      "Epoch [1360/1500], Loss: 0.002322\n",
      "Epoch [1380/1500], Loss: 0.002323\n",
      "Epoch [1400/1500], Loss: 0.002325\n",
      "Epoch [1420/1500], Loss: 0.002322\n",
      "Epoch [1440/1500], Loss: 0.002322\n",
      "Epoch [1460/1500], Loss: 0.002322\n",
      "Epoch [1480/1500], Loss: 0.002322\n",
      "Epoch [1500/1500], Loss: 0.002322\n",
      "tensor(0.0365, device='cuda:0')\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.418221 for selected strength\n",
      "We have a total strength of 1.805611 for all the columns\n",
      "Epoch [20/1500], Loss: 2.042571\n",
      "Epoch [40/1500], Loss: 1.359171\n",
      "Epoch [60/1500], Loss: 0.885648\n",
      "Epoch [80/1500], Loss: 0.543279\n",
      "Epoch [100/1500], Loss: 0.304326\n",
      "Epoch [120/1500], Loss: 0.160092\n",
      "Epoch [140/1500], Loss: 0.082955\n",
      "Epoch [160/1500], Loss: 0.043425\n",
      "Epoch [180/1500], Loss: 0.023597\n",
      "Epoch [200/1500], Loss: 0.013141\n",
      "Epoch [220/1500], Loss: 0.008395\n",
      "Epoch [240/1500], Loss: 0.004961\n",
      "Epoch [260/1500], Loss: 0.003215\n",
      "Epoch [280/1500], Loss: 0.002879\n",
      "Epoch [300/1500], Loss: 0.002904\n",
      "Epoch [320/1500], Loss: 0.003454\n",
      "Epoch [340/1500], Loss: 0.004485\n",
      "Epoch [360/1500], Loss: 0.002640\n",
      "Epoch [380/1500], Loss: 0.003185\n",
      "Epoch [400/1500], Loss: 0.002571\n",
      "Epoch [420/1500], Loss: 0.002670\n",
      "Epoch [440/1500], Loss: 0.003579\n",
      "Epoch [460/1500], Loss: 0.002636\n",
      "Epoch [480/1500], Loss: 0.003147\n",
      "Epoch [500/1500], Loss: 0.002725\n",
      "Epoch [520/1500], Loss: 0.002896\n",
      "Epoch [540/1500], Loss: 0.002630\n",
      "Epoch [560/1500], Loss: 0.002820\n",
      "Epoch [580/1500], Loss: 0.004102\n",
      "Epoch [600/1500], Loss: 0.002712\n",
      "Epoch [620/1500], Loss: 0.003747\n",
      "Epoch [640/1500], Loss: 0.002586\n",
      "Epoch [660/1500], Loss: 0.003648\n",
      "Epoch [680/1500], Loss: 0.002522\n",
      "Epoch [700/1500], Loss: 0.003404\n",
      "Epoch [720/1500], Loss: 0.002781\n",
      "Epoch [740/1500], Loss: 0.004556\n",
      "Epoch [760/1500], Loss: 0.002954\n",
      "Epoch [780/1500], Loss: 0.002692\n",
      "Epoch [800/1500], Loss: 0.003162\n",
      "Epoch [820/1500], Loss: 0.002527\n",
      "Epoch [840/1500], Loss: 0.003722\n",
      "Epoch [860/1500], Loss: 0.003026\n",
      "Epoch [880/1500], Loss: 0.002578\n",
      "Epoch [900/1500], Loss: 0.003575\n",
      "Epoch [920/1500], Loss: 0.002814\n",
      "Epoch [940/1500], Loss: 0.002526\n",
      "Epoch [960/1500], Loss: 0.003513\n",
      "Epoch [980/1500], Loss: 0.002879\n",
      "Epoch [1000/1500], Loss: 0.002605\n",
      "Epoch [1020/1500], Loss: 0.003479\n",
      "Epoch [1040/1500], Loss: 0.002565\n",
      "Epoch [1060/1500], Loss: 0.003831\n",
      "Epoch [1080/1500], Loss: 0.002807\n",
      "Epoch [1100/1500], Loss: 0.004131\n",
      "Epoch [1120/1500], Loss: 0.002658\n",
      "Epoch [1140/1500], Loss: 0.002643\n",
      "Epoch [1160/1500], Loss: 0.002641\n",
      "Epoch [1180/1500], Loss: 0.002641\n",
      "Epoch [1200/1500], Loss: 0.002641\n",
      "Epoch [1220/1500], Loss: 0.002641\n",
      "Epoch [1240/1500], Loss: 0.002641\n",
      "Epoch [1260/1500], Loss: 0.002641\n",
      "Epoch [1280/1500], Loss: 0.002641\n",
      "Epoch [1300/1500], Loss: 0.002641\n",
      "Epoch [1320/1500], Loss: 0.002641\n",
      "Epoch [1340/1500], Loss: 0.002641\n",
      "Epoch [1360/1500], Loss: 0.002641\n",
      "Epoch [1380/1500], Loss: 0.002641\n",
      "Epoch [1400/1500], Loss: 0.002641\n",
      "Epoch [1420/1500], Loss: 0.002641\n",
      "Epoch [1440/1500], Loss: 0.002641\n",
      "Epoch [1460/1500], Loss: 0.002641\n",
      "Epoch [1480/1500], Loss: 0.002641\n",
      "Epoch [1500/1500], Loss: 0.002641\n",
      "tensor(0.0328, device='cuda:0')\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.418410 for selected strength\n",
      "We have a total strength of 1.773810 for all the columns\n",
      " 75%|█████████████████████████████████▊           | 3/4 [04:24<01:27, 87.92s/it]Epoch [20/1500], Loss: 2.094718\n",
      "Epoch [40/1500], Loss: 1.405608\n",
      "Epoch [60/1500], Loss: 0.939557\n",
      "Epoch [80/1500], Loss: 0.603890\n",
      "Epoch [100/1500], Loss: 0.363968\n",
      "Epoch [120/1500], Loss: 0.208771\n",
      "Epoch [140/1500], Loss: 0.116944\n",
      "Epoch [160/1500], Loss: 0.065023\n",
      "Epoch [180/1500], Loss: 0.036309\n",
      "Epoch [200/1500], Loss: 0.021293\n",
      "Epoch [220/1500], Loss: 0.011183\n",
      "Epoch [240/1500], Loss: 0.006757\n",
      "Epoch [260/1500], Loss: 0.005276\n",
      "Epoch [280/1500], Loss: 0.004276\n",
      "Epoch [300/1500], Loss: 0.003528\n",
      "Epoch [320/1500], Loss: 0.005032\n",
      "Epoch [340/1500], Loss: 0.003235\n",
      "Epoch [360/1500], Loss: 0.005549\n",
      "Epoch [380/1500], Loss: 0.003193\n",
      "Epoch [400/1500], Loss: 0.005499\n",
      "Epoch [420/1500], Loss: 0.003347\n",
      "Epoch [440/1500], Loss: 0.003434\n",
      "Epoch [460/1500], Loss: 0.003580\n",
      "Epoch [480/1500], Loss: 0.003093\n",
      "Epoch [500/1500], Loss: 0.004445\n",
      "Epoch [520/1500], Loss: 0.003132\n",
      "Epoch [540/1500], Loss: 0.005435\n",
      "Epoch [560/1500], Loss: 0.003433\n",
      "Epoch [580/1500], Loss: 0.003045\n",
      "Epoch [600/1500], Loss: 0.004452\n",
      "Epoch [620/1500], Loss: 0.003366\n",
      "Epoch [640/1500], Loss: 0.003093\n",
      "Epoch [660/1500], Loss: 0.004420\n",
      "Epoch [680/1500], Loss: 0.003240\n",
      "Epoch [700/1500], Loss: 0.003111\n",
      "Epoch [720/1500], Loss: 0.004525\n",
      "Epoch [740/1500], Loss: 0.003417\n",
      "Epoch [760/1500], Loss: 0.003165\n",
      "Epoch [780/1500], Loss: 0.003305\n",
      "Epoch [800/1500], Loss: 0.004452\n",
      "Epoch [820/1500], Loss: 0.003628\n",
      "Epoch [840/1500], Loss: 0.003096\n",
      "Epoch [860/1500], Loss: 0.005718\n",
      "Epoch [880/1500], Loss: 0.003793\n",
      "Epoch [900/1500], Loss: 0.003128\n",
      "Epoch [920/1500], Loss: 0.003463\n",
      "Epoch [940/1500], Loss: 0.004498\n",
      "Epoch [960/1500], Loss: 0.003597\n",
      "Epoch [980/1500], Loss: 0.003217\n",
      "Epoch [1000/1500], Loss: 0.003201\n",
      "Epoch [1020/1500], Loss: 0.004252\n",
      "Epoch [1040/1500], Loss: 0.003370\n",
      "Epoch [1060/1500], Loss: 0.003342\n",
      "Epoch [1080/1500], Loss: 0.003085\n",
      "Epoch [1100/1500], Loss: 0.005509\n",
      "Epoch [1120/1500], Loss: 0.003127\n",
      "Epoch [1140/1500], Loss: 0.003113\n",
      "Epoch [1160/1500], Loss: 0.003113\n",
      "Epoch [1180/1500], Loss: 0.003111\n",
      "Epoch [1200/1500], Loss: 0.003111\n",
      "Epoch [1220/1500], Loss: 0.003111\n",
      "Epoch [1240/1500], Loss: 0.003111\n",
      "Epoch [1260/1500], Loss: 0.003111\n",
      "Epoch [1280/1500], Loss: 0.003111\n",
      "Epoch [1300/1500], Loss: 0.003111\n",
      "Epoch [1320/1500], Loss: 0.003111\n",
      "Epoch [1340/1500], Loss: 0.003111\n",
      "Epoch [1360/1500], Loss: 0.003111\n",
      "Epoch [1380/1500], Loss: 0.003111\n",
      "Epoch [1400/1500], Loss: 0.003111\n",
      "Epoch [1420/1500], Loss: 0.003111\n",
      "Epoch [1440/1500], Loss: 0.003112\n",
      "Epoch [1460/1500], Loss: 0.003112\n",
      "Epoch [1480/1500], Loss: 0.003112\n",
      "Epoch [1500/1500], Loss: 0.003112\n",
      "tensor(0.0524, device='cuda:0')\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.372418 for selected strength\n",
      "We have a total strength of 1.829270 for all the columns\n",
      "Epoch [20/1500], Loss: 2.080803\n",
      "Epoch [40/1500], Loss: 1.421380\n",
      "Epoch [60/1500], Loss: 0.971166\n",
      "Epoch [80/1500], Loss: 0.641036\n",
      "Epoch [100/1500], Loss: 0.402792\n",
      "Epoch [120/1500], Loss: 0.246203\n",
      "Epoch [140/1500], Loss: 0.150549\n",
      "Epoch [160/1500], Loss: 0.093479\n",
      "Epoch [180/1500], Loss: 0.057939\n",
      "Epoch [200/1500], Loss: 0.035882\n",
      "Epoch [220/1500], Loss: 0.022516\n",
      "Epoch [240/1500], Loss: 0.014575\n",
      "Epoch [260/1500], Loss: 0.010603\n",
      "Epoch [280/1500], Loss: 0.007464\n",
      "Epoch [300/1500], Loss: 0.005316\n",
      "Epoch [320/1500], Loss: 0.005083\n",
      "Epoch [340/1500], Loss: 0.004007\n",
      "Epoch [360/1500], Loss: 0.004073\n",
      "Epoch [380/1500], Loss: 0.006192\n",
      "Epoch [400/1500], Loss: 0.003783\n",
      "Epoch [420/1500], Loss: 0.004640\n",
      "Epoch [440/1500], Loss: 0.003564\n",
      "Epoch [460/1500], Loss: 0.004520\n",
      "Epoch [480/1500], Loss: 0.003616\n",
      "Epoch [500/1500], Loss: 0.004456\n",
      "Epoch [520/1500], Loss: 0.003678\n",
      "Epoch [540/1500], Loss: 0.005020\n",
      "Epoch [560/1500], Loss: 0.003595\n",
      "Epoch [580/1500], Loss: 0.004754\n",
      "Epoch [600/1500], Loss: 0.003845\n",
      "Epoch [620/1500], Loss: 0.004032\n",
      "Epoch [640/1500], Loss: 0.004078\n",
      "Epoch [660/1500], Loss: 0.003596\n",
      "Epoch [680/1500], Loss: 0.004786\n",
      "Epoch [700/1500], Loss: 0.003680\n",
      "Epoch [720/1500], Loss: 0.005621\n",
      "Epoch [740/1500], Loss: 0.004176\n",
      "Epoch [760/1500], Loss: 0.003529\n",
      "Epoch [780/1500], Loss: 0.004987\n",
      "Epoch [800/1500], Loss: 0.003905\n",
      "Epoch [820/1500], Loss: 0.003630\n",
      "Epoch [840/1500], Loss: 0.004497\n",
      "Epoch [860/1500], Loss: 0.003696\n",
      "Epoch [880/1500], Loss: 0.006082\n",
      "Epoch [900/1500], Loss: 0.004392\n",
      "Epoch [920/1500], Loss: 0.003675\n",
      "Epoch [940/1500], Loss: 0.003969\n",
      "Epoch [960/1500], Loss: 0.004753\n",
      "Epoch [980/1500], Loss: 0.003836\n",
      "Epoch [1000/1500], Loss: 0.004320\n",
      "Epoch [1020/1500], Loss: 0.004285\n",
      "Epoch [1040/1500], Loss: 0.003702\n",
      "Epoch [1060/1500], Loss: 0.006396\n",
      "Epoch [1080/1500], Loss: 0.004359\n",
      "Epoch [1100/1500], Loss: 0.003778\n",
      "Epoch [1120/1500], Loss: 0.003896\n",
      "Epoch [1140/1500], Loss: 0.003868\n",
      "Epoch [1160/1500], Loss: 0.003863\n",
      "Epoch [1180/1500], Loss: 0.003861\n",
      "Epoch [1200/1500], Loss: 0.003861\n",
      "Epoch [1220/1500], Loss: 0.003861\n",
      "Epoch [1240/1500], Loss: 0.003861\n",
      "Epoch [1260/1500], Loss: 0.003861\n",
      "Epoch [1280/1500], Loss: 0.003861\n",
      "Epoch [1300/1500], Loss: 0.003861\n",
      "Epoch [1320/1500], Loss: 0.003861\n",
      "Epoch [1340/1500], Loss: 0.003861\n",
      "Epoch [1360/1500], Loss: 0.003861\n",
      "Epoch [1380/1500], Loss: 0.003861\n",
      "Epoch [1400/1500], Loss: 0.003861\n",
      "Epoch [1420/1500], Loss: 0.003861\n",
      "Epoch [1440/1500], Loss: 0.003861\n",
      "Epoch [1460/1500], Loss: 0.003861\n",
      "Epoch [1480/1500], Loss: 0.003862\n",
      "Epoch [1500/1500], Loss: 0.003862\n",
      "tensor(0.0569, device='cuda:0')\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.638592 for selected strength\n",
      "We have a total strength of 2.478839 for all the columns\n",
      "Epoch [20/1500], Loss: 2.087300\n",
      "Epoch [40/1500], Loss: 1.420732\n",
      "Epoch [60/1500], Loss: 0.964621\n",
      "Epoch [80/1500], Loss: 0.629562\n",
      "Epoch [100/1500], Loss: 0.386681\n",
      "Epoch [120/1500], Loss: 0.226978\n",
      "Epoch [140/1500], Loss: 0.131737\n",
      "Epoch [160/1500], Loss: 0.078023\n",
      "Epoch [180/1500], Loss: 0.046769\n",
      "Epoch [200/1500], Loss: 0.027840\n",
      "Epoch [220/1500], Loss: 0.017034\n",
      "Epoch [240/1500], Loss: 0.011436\n",
      "Epoch [260/1500], Loss: 0.009071\n",
      "Epoch [280/1500], Loss: 0.006710\n",
      "Epoch [300/1500], Loss: 0.005755\n",
      "Epoch [320/1500], Loss: 0.006385\n",
      "Epoch [340/1500], Loss: 0.005168\n",
      "Epoch [360/1500], Loss: 0.006137\n",
      "Epoch [380/1500], Loss: 0.005039\n",
      "Epoch [400/1500], Loss: 0.005097\n",
      "Epoch [420/1500], Loss: 0.005216\n",
      "Epoch [440/1500], Loss: 0.004857\n",
      "Epoch [460/1500], Loss: 0.006272\n",
      "Epoch [480/1500], Loss: 0.004945\n",
      "Epoch [500/1500], Loss: 0.005133\n",
      "Epoch [520/1500], Loss: 0.005562\n",
      "Epoch [540/1500], Loss: 0.004854\n",
      "Epoch [560/1500], Loss: 0.006578\n",
      "Epoch [580/1500], Loss: 0.005064\n",
      "Epoch [600/1500], Loss: 0.004912\n",
      "Epoch [620/1500], Loss: 0.005964\n",
      "Epoch [640/1500], Loss: 0.004961\n",
      "Epoch [660/1500], Loss: 0.005056\n",
      "Epoch [680/1500], Loss: 0.005884\n",
      "Epoch [700/1500], Loss: 0.005070\n",
      "Epoch [720/1500], Loss: 0.004888\n",
      "Epoch [740/1500], Loss: 0.006104\n",
      "Epoch [760/1500], Loss: 0.005035\n",
      "Epoch [780/1500], Loss: 0.004892\n",
      "Epoch [800/1500], Loss: 0.006103\n",
      "Epoch [820/1500], Loss: 0.005045\n",
      "Epoch [840/1500], Loss: 0.004926\n",
      "Epoch [860/1500], Loss: 0.005858\n",
      "Epoch [880/1500], Loss: 0.005099\n",
      "Epoch [900/1500], Loss: 0.004872\n",
      "Epoch [920/1500], Loss: 0.006051\n",
      "Epoch [940/1500], Loss: 0.005483\n",
      "Epoch [960/1500], Loss: 0.005007\n",
      "Epoch [980/1500], Loss: 0.004889\n",
      "Epoch [1000/1500], Loss: 0.006853\n",
      "Epoch [1020/1500], Loss: 0.005373\n",
      "Epoch [1040/1500], Loss: 0.004959\n",
      "Epoch [1060/1500], Loss: 0.004918\n",
      "Epoch [1080/1500], Loss: 0.006506\n",
      "Epoch [1100/1500], Loss: 0.005442\n",
      "Epoch [1120/1500], Loss: 0.005455\n",
      "Epoch [1140/1500], Loss: 0.005407\n",
      "Epoch [1160/1500], Loss: 0.005401\n",
      "Epoch [1180/1500], Loss: 0.005399\n",
      "Epoch [1200/1500], Loss: 0.005397\n",
      "Epoch [1220/1500], Loss: 0.005397\n",
      "Epoch [1240/1500], Loss: 0.005395\n",
      "Epoch [1260/1500], Loss: 0.005393\n",
      "Epoch [1280/1500], Loss: 0.005393\n",
      "Epoch [1300/1500], Loss: 0.005393\n",
      "Epoch [1320/1500], Loss: 0.005393\n",
      "Epoch [1340/1500], Loss: 0.005393\n",
      "Epoch [1360/1500], Loss: 0.005393\n",
      "Epoch [1380/1500], Loss: 0.005393\n",
      "Epoch [1400/1500], Loss: 0.005393\n",
      "Epoch [1420/1500], Loss: 0.005393\n",
      "Epoch [1440/1500], Loss: 0.005393\n",
      "Epoch [1460/1500], Loss: 0.005394\n",
      "Epoch [1480/1500], Loss: 0.005394\n",
      "Epoch [1500/1500], Loss: 0.005394\n",
      "tensor(0.0976, device='cuda:0')\n",
      "tensor(0.0963, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.037780 for selected strength\n",
      "We have a total strength of 3.080841 for all the columns\n",
      "Epoch [20/1500], Loss: 2.083205\n",
      "Epoch [40/1500], Loss: 1.440481\n",
      "Epoch [60/1500], Loss: 0.990525\n",
      "Epoch [80/1500], Loss: 0.656104\n",
      "Epoch [100/1500], Loss: 0.411587\n",
      "Epoch [120/1500], Loss: 0.249603\n",
      "Epoch [140/1500], Loss: 0.151217\n",
      "Epoch [160/1500], Loss: 0.092216\n",
      "Epoch [180/1500], Loss: 0.056468\n",
      "Epoch [200/1500], Loss: 0.034534\n",
      "Epoch [220/1500], Loss: 0.021178\n",
      "Epoch [240/1500], Loss: 0.013305\n",
      "Epoch [260/1500], Loss: 0.008983\n",
      "Epoch [280/1500], Loss: 0.006573\n",
      "Epoch [300/1500], Loss: 0.006189\n",
      "Epoch [320/1500], Loss: 0.004034\n",
      "Epoch [340/1500], Loss: 0.003997\n",
      "Epoch [360/1500], Loss: 0.004647\n",
      "Epoch [380/1500], Loss: 0.003644\n",
      "Epoch [400/1500], Loss: 0.003721\n",
      "Epoch [420/1500], Loss: 0.005217\n",
      "Epoch [440/1500], Loss: 0.003475\n",
      "Epoch [460/1500], Loss: 0.004058\n",
      "Epoch [480/1500], Loss: 0.003255\n",
      "Epoch [500/1500], Loss: 0.003851\n",
      "Epoch [520/1500], Loss: 0.004735\n",
      "Epoch [540/1500], Loss: 0.003729\n",
      "Epoch [560/1500], Loss: 0.005726\n",
      "Epoch [580/1500], Loss: 0.003527\n",
      "Epoch [600/1500], Loss: 0.004640\n",
      "Epoch [620/1500], Loss: 0.003645\n",
      "Epoch [640/1500], Loss: 0.004857\n",
      "Epoch [660/1500], Loss: 0.003643\n",
      "Epoch [680/1500], Loss: 0.005455\n",
      "Epoch [700/1500], Loss: 0.003924\n",
      "Epoch [720/1500], Loss: 0.003526\n",
      "Epoch [740/1500], Loss: 0.005007\n",
      "Epoch [760/1500], Loss: 0.003668\n",
      "Epoch [780/1500], Loss: 0.004055\n",
      "Epoch [800/1500], Loss: 0.003999\n",
      "Epoch [820/1500], Loss: 0.003390\n",
      "Epoch [840/1500], Loss: 0.004636\n",
      "Epoch [860/1500], Loss: 0.003621\n",
      "Epoch [880/1500], Loss: 0.004775\n",
      "Epoch [900/1500], Loss: 0.003848\n",
      "Epoch [920/1500], Loss: 0.003538\n",
      "Epoch [940/1500], Loss: 0.004982\n",
      "Epoch [960/1500], Loss: 0.003612\n",
      "Epoch [980/1500], Loss: 0.003813\n",
      "Epoch [1000/1500], Loss: 0.004343\n",
      "Epoch [1020/1500], Loss: 0.003561\n",
      "Epoch [1040/1500], Loss: 0.004754\n",
      "Epoch [1060/1500], Loss: 0.003954\n",
      "Epoch [1080/1500], Loss: 0.003574\n",
      "Epoch [1100/1500], Loss: 0.004520\n",
      "Epoch [1120/1500], Loss: 0.003813\n",
      "Epoch [1140/1500], Loss: 0.003755\n",
      "Epoch [1160/1500], Loss: 0.003747\n",
      "Epoch [1180/1500], Loss: 0.003745\n",
      "Epoch [1200/1500], Loss: 0.003745\n",
      "Epoch [1220/1500], Loss: 0.003745\n",
      "Epoch [1240/1500], Loss: 0.003745\n",
      "Epoch [1260/1500], Loss: 0.003745\n",
      "Epoch [1280/1500], Loss: 0.003745\n",
      "Epoch [1300/1500], Loss: 0.003745\n",
      "Epoch [1320/1500], Loss: 0.003745\n",
      "Epoch [1340/1500], Loss: 0.003745\n",
      "Epoch [1360/1500], Loss: 0.003745\n",
      "Epoch [1380/1500], Loss: 0.003745\n",
      "Epoch [1400/1500], Loss: 0.003745\n",
      "Epoch [1420/1500], Loss: 0.003745\n",
      "Epoch [1440/1500], Loss: 0.003745\n",
      "Epoch [1460/1500], Loss: 0.003745\n",
      "Epoch [1480/1500], Loss: 0.003745\n",
      "Epoch [1500/1500], Loss: 0.003745\n",
      "tensor(0.0778, device='cuda:0')\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.795538 for selected strength\n",
      "We have a total strength of 2.622035 for all the columns\n",
      "Epoch [20/1500], Loss: 2.052710\n",
      "Epoch [40/1500], Loss: 1.387657\n",
      "Epoch [60/1500], Loss: 0.928311\n",
      "Epoch [80/1500], Loss: 0.595701\n",
      "Epoch [100/1500], Loss: 0.360962\n",
      "Epoch [120/1500], Loss: 0.212317\n",
      "Epoch [140/1500], Loss: 0.127281\n",
      "Epoch [160/1500], Loss: 0.076779\n",
      "Epoch [180/1500], Loss: 0.046789\n",
      "Epoch [200/1500], Loss: 0.028920\n",
      "Epoch [220/1500], Loss: 0.019032\n",
      "Epoch [240/1500], Loss: 0.010847\n",
      "Epoch [260/1500], Loss: 0.007097\n",
      "Epoch [280/1500], Loss: 0.005540\n",
      "Epoch [300/1500], Loss: 0.005706\n",
      "Epoch [320/1500], Loss: 0.003721\n",
      "Epoch [340/1500], Loss: 0.004239\n",
      "Epoch [360/1500], Loss: 0.003395\n",
      "Epoch [380/1500], Loss: 0.003761\n",
      "Epoch [400/1500], Loss: 0.003181\n",
      "Epoch [420/1500], Loss: 0.003658\n",
      "Epoch [440/1500], Loss: 0.003376\n",
      "Epoch [460/1500], Loss: 0.003763\n",
      "Epoch [480/1500], Loss: 0.003385\n",
      "Epoch [500/1500], Loss: 0.003908\n",
      "Epoch [520/1500], Loss: 0.003221\n",
      "Epoch [540/1500], Loss: 0.004347\n",
      "Epoch [560/1500], Loss: 0.003323\n",
      "Epoch [580/1500], Loss: 0.005079\n",
      "Epoch [600/1500], Loss: 0.003454\n",
      "Epoch [620/1500], Loss: 0.004185\n",
      "Epoch [640/1500], Loss: 0.003708\n",
      "Epoch [660/1500], Loss: 0.003148\n",
      "Epoch [680/1500], Loss: 0.004249\n",
      "Epoch [700/1500], Loss: 0.003324\n",
      "Epoch [720/1500], Loss: 0.005701\n",
      "Epoch [740/1500], Loss: 0.003706\n",
      "Epoch [760/1500], Loss: 0.003312\n",
      "Epoch [780/1500], Loss: 0.004639\n",
      "Epoch [800/1500], Loss: 0.003264\n",
      "Epoch [820/1500], Loss: 0.005806\n",
      "Epoch [840/1500], Loss: 0.003536\n",
      "Epoch [860/1500], Loss: 0.003255\n",
      "Epoch [880/1500], Loss: 0.004632\n",
      "Epoch [900/1500], Loss: 0.003478\n",
      "Epoch [920/1500], Loss: 0.003517\n",
      "Epoch [940/1500], Loss: 0.005141\n",
      "Epoch [960/1500], Loss: 0.003863\n",
      "Epoch [980/1500], Loss: 0.003363\n",
      "Epoch [1000/1500], Loss: 0.003513\n",
      "Epoch [1020/1500], Loss: 0.004394\n",
      "Epoch [1040/1500], Loss: 0.003671\n",
      "Epoch [1060/1500], Loss: 0.003356\n",
      "Epoch [1080/1500], Loss: 0.004122\n",
      "Epoch [1100/1500], Loss: 0.004246\n",
      "Epoch [1120/1500], Loss: 0.003448\n",
      "Epoch [1140/1500], Loss: 0.003414\n",
      "Epoch [1160/1500], Loss: 0.003409\n",
      "Epoch [1180/1500], Loss: 0.003408\n",
      "Epoch [1200/1500], Loss: 0.003408\n",
      "Epoch [1220/1500], Loss: 0.003408\n",
      "Epoch [1240/1500], Loss: 0.003408\n",
      "Epoch [1260/1500], Loss: 0.003408\n",
      "Epoch [1280/1500], Loss: 0.003408\n",
      "Epoch [1300/1500], Loss: 0.003408\n",
      "Epoch [1320/1500], Loss: 0.003408\n",
      "Epoch [1340/1500], Loss: 0.003408\n",
      "Epoch [1360/1500], Loss: 0.003408\n",
      "Epoch [1380/1500], Loss: 0.003408\n",
      "Epoch [1400/1500], Loss: 0.003408\n",
      "Epoch [1420/1500], Loss: 0.003408\n",
      "Epoch [1440/1500], Loss: 0.003408\n",
      "Epoch [1460/1500], Loss: 0.003409\n",
      "Epoch [1480/1500], Loss: 0.003409\n",
      "Epoch [1500/1500], Loss: 0.003409\n",
      "tensor(0.0602, device='cuda:0')\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.632253 for selected strength\n",
      "We have a total strength of 2.189417 for all the columns\n",
      "Epoch [20/1500], Loss: 2.086817\n",
      "Epoch [40/1500], Loss: 1.424325\n",
      "Epoch [60/1500], Loss: 0.977146\n",
      "Epoch [80/1500], Loss: 0.650393\n",
      "Epoch [100/1500], Loss: 0.412374\n",
      "Epoch [120/1500], Loss: 0.253061\n",
      "Epoch [140/1500], Loss: 0.154380\n",
      "Epoch [160/1500], Loss: 0.094644\n",
      "Epoch [180/1500], Loss: 0.057423\n",
      "Epoch [200/1500], Loss: 0.033600\n",
      "Epoch [220/1500], Loss: 0.020221\n",
      "Epoch [240/1500], Loss: 0.012720\n",
      "Epoch [260/1500], Loss: 0.008908\n",
      "Epoch [280/1500], Loss: 0.007157\n",
      "Epoch [300/1500], Loss: 0.005407\n",
      "Epoch [320/1500], Loss: 0.004908\n",
      "Epoch [340/1500], Loss: 0.005651\n",
      "Epoch [360/1500], Loss: 0.004298\n",
      "Epoch [380/1500], Loss: 0.004966\n",
      "Epoch [400/1500], Loss: 0.004224\n",
      "Epoch [420/1500], Loss: 0.004953\n",
      "Epoch [440/1500], Loss: 0.004237\n",
      "Epoch [460/1500], Loss: 0.004700\n",
      "Epoch [480/1500], Loss: 0.004276\n",
      "Epoch [500/1500], Loss: 0.004852\n",
      "Epoch [520/1500], Loss: 0.004171\n",
      "Epoch [540/1500], Loss: 0.005018\n",
      "Epoch [560/1500], Loss: 0.004168\n",
      "Epoch [580/1500], Loss: 0.005378\n",
      "Epoch [600/1500], Loss: 0.004263\n",
      "Epoch [620/1500], Loss: 0.005987\n",
      "Epoch [640/1500], Loss: 0.004462\n",
      "Epoch [660/1500], Loss: 0.005149\n",
      "Epoch [680/1500], Loss: 0.004994\n",
      "Epoch [700/1500], Loss: 0.004198\n",
      "Epoch [720/1500], Loss: 0.005575\n",
      "Epoch [740/1500], Loss: 0.004431\n",
      "Epoch [760/1500], Loss: 0.004300\n",
      "Epoch [780/1500], Loss: 0.005111\n",
      "Epoch [800/1500], Loss: 0.004247\n",
      "Epoch [820/1500], Loss: 0.006231\n",
      "Epoch [840/1500], Loss: 0.004524\n",
      "Epoch [860/1500], Loss: 0.004192\n",
      "Epoch [880/1500], Loss: 0.005646\n",
      "Epoch [900/1500], Loss: 0.004556\n",
      "Epoch [920/1500], Loss: 0.004232\n",
      "Epoch [940/1500], Loss: 0.005549\n",
      "Epoch [960/1500], Loss: 0.004430\n",
      "Epoch [980/1500], Loss: 0.004467\n",
      "Epoch [1000/1500], Loss: 0.005086\n",
      "Epoch [1020/1500], Loss: 0.004355\n",
      "Epoch [1040/1500], Loss: 0.005550\n",
      "Epoch [1060/1500], Loss: 0.004976\n",
      "Epoch [1080/1500], Loss: 0.004283\n",
      "Epoch [1100/1500], Loss: 0.005268\n",
      "Epoch [1120/1500], Loss: 0.004624\n",
      "Epoch [1140/1500], Loss: 0.004586\n",
      "Epoch [1160/1500], Loss: 0.004580\n",
      "Epoch [1180/1500], Loss: 0.004579\n",
      "Epoch [1200/1500], Loss: 0.004579\n",
      "Epoch [1220/1500], Loss: 0.004579\n",
      "Epoch [1240/1500], Loss: 0.004578\n",
      "Epoch [1260/1500], Loss: 0.004579\n",
      "Epoch [1280/1500], Loss: 0.004579\n",
      "Epoch [1300/1500], Loss: 0.004579\n",
      "Epoch [1320/1500], Loss: 0.004579\n",
      "Epoch [1340/1500], Loss: 0.004579\n",
      "Epoch [1360/1500], Loss: 0.004579\n",
      "Epoch [1380/1500], Loss: 0.004579\n",
      "Epoch [1400/1500], Loss: 0.004579\n",
      "Epoch [1420/1500], Loss: 0.004579\n",
      "Epoch [1440/1500], Loss: 0.004579\n",
      "Epoch [1460/1500], Loss: 0.004579\n",
      "Epoch [1480/1500], Loss: 0.004579\n",
      "Epoch [1500/1500], Loss: 0.004579\n",
      "tensor(0.2305, device='cuda:0')\n",
      "tensor(0.1365, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.771623 for selected strength\n",
      "We have a total strength of 2.843114 for all the columns\n",
      "Epoch [20/1500], Loss: 2.055980\n",
      "Epoch [40/1500], Loss: 1.381842\n",
      "Epoch [60/1500], Loss: 0.923067\n",
      "Epoch [80/1500], Loss: 0.591982\n",
      "Epoch [100/1500], Loss: 0.357945\n",
      "Epoch [120/1500], Loss: 0.209289\n",
      "Epoch [140/1500], Loss: 0.124088\n",
      "Epoch [160/1500], Loss: 0.074176\n",
      "Epoch [180/1500], Loss: 0.044631\n",
      "Epoch [200/1500], Loss: 0.026964\n",
      "Epoch [220/1500], Loss: 0.015224\n",
      "Epoch [240/1500], Loss: 0.009782\n",
      "Epoch [260/1500], Loss: 0.006910\n",
      "Epoch [280/1500], Loss: 0.005846\n",
      "Epoch [300/1500], Loss: 0.004190\n",
      "Epoch [320/1500], Loss: 0.004049\n",
      "Epoch [340/1500], Loss: 0.004925\n",
      "Epoch [360/1500], Loss: 0.003598\n",
      "Epoch [380/1500], Loss: 0.003940\n",
      "Epoch [400/1500], Loss: 0.006494\n",
      "Epoch [420/1500], Loss: 0.003614\n",
      "Epoch [440/1500], Loss: 0.004726\n",
      "Epoch [460/1500], Loss: 0.003708\n",
      "Epoch [480/1500], Loss: 0.005359\n",
      "Epoch [500/1500], Loss: 0.003677\n",
      "Epoch [520/1500], Loss: 0.004847\n",
      "Epoch [540/1500], Loss: 0.003743\n",
      "Epoch [560/1500], Loss: 0.005811\n",
      "Epoch [580/1500], Loss: 0.003900\n",
      "Epoch [600/1500], Loss: 0.003833\n",
      "Epoch [620/1500], Loss: 0.004087\n",
      "Epoch [640/1500], Loss: 0.003523\n",
      "Epoch [660/1500], Loss: 0.004677\n",
      "Epoch [680/1500], Loss: 0.003641\n",
      "Epoch [700/1500], Loss: 0.006071\n",
      "Epoch [720/1500], Loss: 0.004011\n",
      "Epoch [740/1500], Loss: 0.003578\n",
      "Epoch [760/1500], Loss: 0.004520\n",
      "Epoch [780/1500], Loss: 0.003669\n",
      "Epoch [800/1500], Loss: 0.006231\n",
      "Epoch [820/1500], Loss: 0.004220\n",
      "Epoch [840/1500], Loss: 0.003610\n",
      "Epoch [860/1500], Loss: 0.005012\n",
      "Epoch [880/1500], Loss: 0.004198\n",
      "Epoch [900/1500], Loss: 0.003644\n",
      "Epoch [920/1500], Loss: 0.006418\n",
      "Epoch [940/1500], Loss: 0.004232\n",
      "Epoch [960/1500], Loss: 0.003619\n",
      "Epoch [980/1500], Loss: 0.004239\n",
      "Epoch [1000/1500], Loss: 0.004642\n",
      "Epoch [1020/1500], Loss: 0.003732\n",
      "Epoch [1040/1500], Loss: 0.003444\n",
      "Epoch [1060/1500], Loss: 0.005529\n",
      "Epoch [1080/1500], Loss: 0.004066\n",
      "Epoch [1100/1500], Loss: 0.003484\n",
      "Epoch [1120/1500], Loss: 0.003859\n",
      "Epoch [1140/1500], Loss: 0.003822\n",
      "Epoch [1160/1500], Loss: 0.003813\n",
      "Epoch [1180/1500], Loss: 0.003810\n",
      "Epoch [1200/1500], Loss: 0.003802\n",
      "Epoch [1220/1500], Loss: 0.003795\n",
      "Epoch [1240/1500], Loss: 0.003792\n",
      "Epoch [1260/1500], Loss: 0.003795\n",
      "Epoch [1280/1500], Loss: 0.003794\n",
      "Epoch [1300/1500], Loss: 0.003791\n",
      "Epoch [1320/1500], Loss: 0.003791\n",
      "Epoch [1340/1500], Loss: 0.003791\n",
      "Epoch [1360/1500], Loss: 0.003791\n",
      "Epoch [1380/1500], Loss: 0.003791\n",
      "Epoch [1400/1500], Loss: 0.003791\n",
      "Epoch [1420/1500], Loss: 0.003791\n",
      "Epoch [1440/1500], Loss: 0.003791\n",
      "Epoch [1460/1500], Loss: 0.003791\n",
      "Epoch [1480/1500], Loss: 0.003791\n",
      "Epoch [1500/1500], Loss: 0.003791\n",
      "tensor(0.0583, device='cuda:0')\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.729760 for selected strength\n",
      "We have a total strength of 5.032159 for all the columns\n",
      "Epoch [20/1500], Loss: 2.041096\n",
      "Epoch [40/1500], Loss: 1.337017\n",
      "Epoch [60/1500], Loss: 0.868201\n",
      "Epoch [80/1500], Loss: 0.536529\n",
      "Epoch [100/1500], Loss: 0.310424\n",
      "Epoch [120/1500], Loss: 0.176601\n",
      "Epoch [140/1500], Loss: 0.102887\n",
      "Epoch [160/1500], Loss: 0.061992\n",
      "Epoch [180/1500], Loss: 0.037600\n",
      "Epoch [200/1500], Loss: 0.024508\n",
      "Epoch [220/1500], Loss: 0.017022\n",
      "Epoch [240/1500], Loss: 0.013052\n",
      "Epoch [260/1500], Loss: 0.010946\n",
      "Epoch [280/1500], Loss: 0.009843\n",
      "Epoch [300/1500], Loss: 0.009269\n",
      "Epoch [320/1500], Loss: 0.008974\n",
      "Epoch [340/1500], Loss: 0.008822\n",
      "Epoch [360/1500], Loss: 0.008743\n",
      "Epoch [380/1500], Loss: 0.008692\n",
      "Epoch [400/1500], Loss: 0.008675\n",
      "Epoch [420/1500], Loss: 0.008668\n",
      "Epoch [440/1500], Loss: 0.008652\n",
      "Epoch [460/1500], Loss: 0.008663\n",
      "Epoch [480/1500], Loss: 0.008668\n",
      "Epoch [500/1500], Loss: 0.008644\n",
      "Epoch [520/1500], Loss: 0.008655\n",
      "Epoch [540/1500], Loss: 0.008663\n",
      "Epoch [560/1500], Loss: 0.008652\n",
      "Epoch [580/1500], Loss: 0.008639\n",
      "Epoch [600/1500], Loss: 0.008644\n",
      "Epoch [620/1500], Loss: 0.008702\n",
      "Epoch [640/1500], Loss: 0.008660\n",
      "Epoch [660/1500], Loss: 0.008644\n",
      "Epoch [680/1500], Loss: 0.008642\n",
      "Epoch [700/1500], Loss: 0.008668\n",
      "Epoch [720/1500], Loss: 0.008645\n",
      "Epoch [740/1500], Loss: 0.008648\n",
      "Epoch [760/1500], Loss: 0.008729\n",
      "Epoch [780/1500], Loss: 0.008683\n",
      "Epoch [800/1500], Loss: 0.008678\n",
      "Epoch [820/1500], Loss: 0.008706\n",
      "Epoch [840/1500], Loss: 0.008677\n",
      "Epoch [860/1500], Loss: 0.008759\n",
      "Epoch [880/1500], Loss: 0.008713\n",
      "Epoch [900/1500], Loss: 0.008670\n",
      "Epoch [920/1500], Loss: 0.008663\n",
      "Epoch [940/1500], Loss: 0.008663\n",
      "Epoch [960/1500], Loss: 0.008749\n",
      "Epoch [980/1500], Loss: 0.008775\n",
      "Epoch [1000/1500], Loss: 0.008761\n",
      "Epoch [1020/1500], Loss: 0.008738\n",
      "Epoch [1040/1500], Loss: 0.008679\n",
      "Epoch [1060/1500], Loss: 0.008681\n",
      "Epoch [1080/1500], Loss: 0.008679\n",
      "Epoch [1100/1500], Loss: 0.008670\n",
      "Epoch [1120/1500], Loss: 0.009682\n",
      "Epoch [1140/1500], Loss: 0.009600\n",
      "Epoch [1160/1500], Loss: 0.009584\n",
      "Epoch [1180/1500], Loss: 0.009580\n",
      "Epoch [1200/1500], Loss: 0.009579\n",
      "Epoch [1220/1500], Loss: 0.009578\n",
      "Epoch [1240/1500], Loss: 0.009578\n",
      "Epoch [1260/1500], Loss: 0.009578\n",
      "Epoch [1280/1500], Loss: 0.009578\n",
      "Epoch [1300/1500], Loss: 0.009578\n",
      "Epoch [1320/1500], Loss: 0.009578\n",
      "Epoch [1340/1500], Loss: 0.009578\n",
      "Epoch [1360/1500], Loss: 0.009578\n",
      "Epoch [1380/1500], Loss: 0.009578\n",
      "Epoch [1400/1500], Loss: 0.009578\n",
      "Epoch [1420/1500], Loss: 0.009578\n",
      "Epoch [1440/1500], Loss: 0.009578\n",
      "Epoch [1460/1500], Loss: 0.009578\n",
      "Epoch [1480/1500], Loss: 0.009578\n",
      "Epoch [1500/1500], Loss: 0.009578\n",
      "tensor(0.0858, device='cuda:0')\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.510320 for selected strength\n",
      "We have a total strength of 5.140050 for all the columns\n",
      "Epoch [20/1500], Loss: 2.085122\n",
      "Epoch [40/1500], Loss: 1.422939\n",
      "Epoch [60/1500], Loss: 0.966439\n",
      "Epoch [80/1500], Loss: 0.633714\n",
      "Epoch [100/1500], Loss: 0.393112\n",
      "Epoch [120/1500], Loss: 0.234398\n",
      "Epoch [140/1500], Loss: 0.140396\n",
      "Epoch [160/1500], Loss: 0.084526\n",
      "Epoch [180/1500], Loss: 0.050831\n",
      "Epoch [200/1500], Loss: 0.030861\n",
      "Epoch [220/1500], Loss: 0.019646\n",
      "Epoch [240/1500], Loss: 0.013113\n",
      "Epoch [260/1500], Loss: 0.008447\n",
      "Epoch [280/1500], Loss: 0.006131\n",
      "Epoch [300/1500], Loss: 0.005478\n",
      "Epoch [320/1500], Loss: 0.005793\n",
      "Epoch [340/1500], Loss: 0.004436\n",
      "Epoch [360/1500], Loss: 0.005442\n",
      "Epoch [380/1500], Loss: 0.004147\n",
      "Epoch [400/1500], Loss: 0.005227\n",
      "Epoch [420/1500], Loss: 0.004139\n",
      "Epoch [440/1500], Loss: 0.005130\n",
      "Epoch [460/1500], Loss: 0.004307\n",
      "Epoch [480/1500], Loss: 0.005322\n",
      "Epoch [500/1500], Loss: 0.004296\n",
      "Epoch [520/1500], Loss: 0.005459\n",
      "Epoch [540/1500], Loss: 0.004210\n",
      "Epoch [560/1500], Loss: 0.005849\n",
      "Epoch [580/1500], Loss: 0.004260\n",
      "Epoch [600/1500], Loss: 0.005599\n",
      "Epoch [620/1500], Loss: 0.004405\n",
      "Epoch [640/1500], Loss: 0.004061\n",
      "Epoch [660/1500], Loss: 0.004947\n",
      "Epoch [680/1500], Loss: 0.004122\n",
      "Epoch [700/1500], Loss: 0.005549\n",
      "Epoch [720/1500], Loss: 0.004447\n",
      "Epoch [740/1500], Loss: 0.004575\n",
      "Epoch [760/1500], Loss: 0.004935\n",
      "Epoch [780/1500], Loss: 0.004211\n",
      "Epoch [800/1500], Loss: 0.005940\n",
      "Epoch [820/1500], Loss: 0.004458\n",
      "Epoch [840/1500], Loss: 0.004155\n",
      "Epoch [860/1500], Loss: 0.005710\n",
      "Epoch [880/1500], Loss: 0.004536\n",
      "Epoch [900/1500], Loss: 0.004300\n",
      "Epoch [920/1500], Loss: 0.005277\n",
      "Epoch [940/1500], Loss: 0.004516\n",
      "Epoch [960/1500], Loss: 0.004107\n",
      "Epoch [980/1500], Loss: 0.005357\n",
      "Epoch [1000/1500], Loss: 0.004181\n",
      "Epoch [1020/1500], Loss: 0.006142\n",
      "Epoch [1040/1500], Loss: 0.005005\n",
      "Epoch [1060/1500], Loss: 0.004321\n",
      "Epoch [1080/1500], Loss: 0.004210\n",
      "Epoch [1100/1500], Loss: 0.006373\n",
      "Epoch [1120/1500], Loss: 0.004695\n",
      "Epoch [1140/1500], Loss: 0.004648\n",
      "Epoch [1160/1500], Loss: 0.004642\n",
      "Epoch [1180/1500], Loss: 0.004641\n",
      "Epoch [1200/1500], Loss: 0.004641\n",
      "Epoch [1220/1500], Loss: 0.004641\n",
      "Epoch [1240/1500], Loss: 0.004641\n",
      "Epoch [1260/1500], Loss: 0.004641\n",
      "Epoch [1280/1500], Loss: 0.004641\n",
      "Epoch [1300/1500], Loss: 0.004641\n",
      "Epoch [1320/1500], Loss: 0.004641\n",
      "Epoch [1340/1500], Loss: 0.004641\n",
      "Epoch [1360/1500], Loss: 0.004641\n",
      "Epoch [1380/1500], Loss: 0.004641\n",
      "Epoch [1400/1500], Loss: 0.004641\n",
      "Epoch [1420/1500], Loss: 0.004641\n",
      "Epoch [1440/1500], Loss: 0.004641\n",
      "Epoch [1460/1500], Loss: 0.004641\n",
      "Epoch [1480/1500], Loss: 0.004641\n",
      "Epoch [1500/1500], Loss: 0.004641\n",
      "tensor(0.0435, device='cuda:0')\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.817848 for selected strength\n",
      "We have a total strength of 2.686869 for all the columns\n",
      "Epoch [20/1500], Loss: 2.125070\n",
      "Epoch [40/1500], Loss: 1.481371\n",
      "Epoch [60/1500], Loss: 1.034799\n",
      "Epoch [80/1500], Loss: 0.702380\n",
      "Epoch [100/1500], Loss: 0.453968\n",
      "Epoch [120/1500], Loss: 0.280331\n",
      "Epoch [140/1500], Loss: 0.170632\n",
      "Epoch [160/1500], Loss: 0.102979\n",
      "Epoch [180/1500], Loss: 0.061800\n",
      "Epoch [200/1500], Loss: 0.036918\n",
      "Epoch [220/1500], Loss: 0.022429\n",
      "Epoch [240/1500], Loss: 0.014575\n",
      "Epoch [260/1500], Loss: 0.010882\n",
      "Epoch [280/1500], Loss: 0.006629\n",
      "Epoch [300/1500], Loss: 0.005569\n",
      "Epoch [320/1500], Loss: 0.005898\n",
      "Epoch [340/1500], Loss: 0.004372\n",
      "Epoch [360/1500], Loss: 0.004818\n",
      "Epoch [380/1500], Loss: 0.004957\n",
      "Epoch [400/1500], Loss: 0.004455\n",
      "Epoch [420/1500], Loss: 0.006203\n",
      "Epoch [440/1500], Loss: 0.004316\n",
      "Epoch [460/1500], Loss: 0.005535\n",
      "Epoch [480/1500], Loss: 0.004406\n",
      "Epoch [500/1500], Loss: 0.005346\n",
      "Epoch [520/1500], Loss: 0.004537\n",
      "Epoch [540/1500], Loss: 0.004711\n",
      "Epoch [560/1500], Loss: 0.004722\n",
      "Epoch [580/1500], Loss: 0.004283\n",
      "Epoch [600/1500], Loss: 0.005879\n",
      "Epoch [620/1500], Loss: 0.004463\n",
      "Epoch [640/1500], Loss: 0.005466\n",
      "Epoch [660/1500], Loss: 0.004760\n",
      "Epoch [680/1500], Loss: 0.004147\n",
      "Epoch [700/1500], Loss: 0.006136\n",
      "Epoch [720/1500], Loss: 0.004593\n",
      "Epoch [740/1500], Loss: 0.004325\n",
      "Epoch [760/1500], Loss: 0.005166\n",
      "Epoch [780/1500], Loss: 0.004235\n",
      "Epoch [800/1500], Loss: 0.006172\n",
      "Epoch [820/1500], Loss: 0.004788\n",
      "Epoch [840/1500], Loss: 0.004313\n",
      "Epoch [860/1500], Loss: 0.006274\n",
      "Epoch [880/1500], Loss: 0.005226\n",
      "Epoch [900/1500], Loss: 0.004470\n",
      "Epoch [920/1500], Loss: 0.004389\n",
      "Epoch [940/1500], Loss: 0.005390\n",
      "Epoch [960/1500], Loss: 0.004571\n",
      "Epoch [980/1500], Loss: 0.004205\n",
      "Epoch [1000/1500], Loss: 0.006047\n",
      "Epoch [1020/1500], Loss: 0.004958\n",
      "Epoch [1040/1500], Loss: 0.004261\n",
      "Epoch [1060/1500], Loss: 0.006034\n",
      "Epoch [1080/1500], Loss: 0.005258\n",
      "Epoch [1100/1500], Loss: 0.004464\n",
      "Epoch [1120/1500], Loss: 0.004784\n",
      "Epoch [1140/1500], Loss: 0.004736\n",
      "Epoch [1160/1500], Loss: 0.004729\n",
      "Epoch [1180/1500], Loss: 0.004727\n",
      "Epoch [1200/1500], Loss: 0.004726\n",
      "Epoch [1220/1500], Loss: 0.004726\n",
      "Epoch [1240/1500], Loss: 0.004726\n",
      "Epoch [1260/1500], Loss: 0.004726\n",
      "Epoch [1280/1500], Loss: 0.004726\n",
      "Epoch [1300/1500], Loss: 0.004726\n",
      "Epoch [1320/1500], Loss: 0.004726\n",
      "Epoch [1340/1500], Loss: 0.004726\n",
      "Epoch [1360/1500], Loss: 0.004726\n",
      "Epoch [1380/1500], Loss: 0.004726\n",
      "Epoch [1400/1500], Loss: 0.004726\n",
      "Epoch [1420/1500], Loss: 0.004727\n",
      "Epoch [1440/1500], Loss: 0.004727\n",
      "Epoch [1460/1500], Loss: 0.004727\n",
      "Epoch [1480/1500], Loss: 0.004727\n",
      "Epoch [1500/1500], Loss: 0.004727\n",
      "tensor(0.1135, device='cuda:0')\n",
      "tensor(0.0696, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.889334 for selected strength\n",
      "We have a total strength of 2.948322 for all the columns\n",
      "Epoch [20/1500], Loss: 2.057881\n",
      "Epoch [40/1500], Loss: 1.383239\n",
      "Epoch [60/1500], Loss: 0.920875\n",
      "Epoch [80/1500], Loss: 0.586329\n",
      "Epoch [100/1500], Loss: 0.350649\n",
      "Epoch [120/1500], Loss: 0.203641\n",
      "Epoch [140/1500], Loss: 0.118732\n",
      "Epoch [160/1500], Loss: 0.070507\n",
      "Epoch [180/1500], Loss: 0.042062\n",
      "Epoch [200/1500], Loss: 0.025341\n",
      "Epoch [220/1500], Loss: 0.015691\n",
      "Epoch [240/1500], Loss: 0.010209\n",
      "Epoch [260/1500], Loss: 0.007254\n",
      "Epoch [280/1500], Loss: 0.006086\n",
      "Epoch [300/1500], Loss: 0.004339\n",
      "Epoch [320/1500], Loss: 0.004056\n",
      "Epoch [340/1500], Loss: 0.004773\n",
      "Epoch [360/1500], Loss: 0.003725\n",
      "Epoch [380/1500], Loss: 0.003711\n",
      "Epoch [400/1500], Loss: 0.005227\n",
      "Epoch [420/1500], Loss: 0.003415\n",
      "Epoch [440/1500], Loss: 0.004453\n",
      "Epoch [460/1500], Loss: 0.003409\n",
      "Epoch [480/1500], Loss: 0.003939\n",
      "Epoch [500/1500], Loss: 0.003719\n",
      "Epoch [520/1500], Loss: 0.003642\n",
      "Epoch [540/1500], Loss: 0.005705\n",
      "Epoch [560/1500], Loss: 0.003740\n",
      "Epoch [580/1500], Loss: 0.004847\n",
      "Epoch [600/1500], Loss: 0.003836\n",
      "Epoch [620/1500], Loss: 0.004507\n",
      "Epoch [640/1500], Loss: 0.004050\n",
      "Epoch [660/1500], Loss: 0.003547\n",
      "Epoch [680/1500], Loss: 0.004191\n",
      "Epoch [700/1500], Loss: 0.003556\n",
      "Epoch [720/1500], Loss: 0.004739\n",
      "Epoch [740/1500], Loss: 0.003748\n",
      "Epoch [760/1500], Loss: 0.003523\n",
      "Epoch [780/1500], Loss: 0.004222\n",
      "Epoch [800/1500], Loss: 0.003411\n",
      "Epoch [820/1500], Loss: 0.004878\n",
      "Epoch [840/1500], Loss: 0.003738\n",
      "Epoch [860/1500], Loss: 0.003835\n",
      "Epoch [880/1500], Loss: 0.004205\n",
      "Epoch [900/1500], Loss: 0.003738\n",
      "Epoch [920/1500], Loss: 0.004861\n",
      "Epoch [940/1500], Loss: 0.003683\n",
      "Epoch [960/1500], Loss: 0.003635\n",
      "Epoch [980/1500], Loss: 0.003981\n",
      "Epoch [1000/1500], Loss: 0.003545\n",
      "Epoch [1020/1500], Loss: 0.004895\n",
      "Epoch [1040/1500], Loss: 0.003765\n",
      "Epoch [1060/1500], Loss: 0.003371\n",
      "Epoch [1080/1500], Loss: 0.004600\n",
      "Epoch [1100/1500], Loss: 0.003844\n",
      "Epoch [1120/1500], Loss: 0.003870\n",
      "Epoch [1140/1500], Loss: 0.003821\n",
      "Epoch [1160/1500], Loss: 0.003809\n",
      "Epoch [1180/1500], Loss: 0.003807\n",
      "Epoch [1200/1500], Loss: 0.003806\n",
      "Epoch [1220/1500], Loss: 0.003805\n",
      "Epoch [1240/1500], Loss: 0.003805\n",
      "Epoch [1260/1500], Loss: 0.003805\n",
      "Epoch [1280/1500], Loss: 0.003805\n",
      "Epoch [1300/1500], Loss: 0.003805\n",
      "Epoch [1320/1500], Loss: 0.003805\n",
      "Epoch [1340/1500], Loss: 0.003805\n",
      "Epoch [1360/1500], Loss: 0.003805\n",
      "Epoch [1380/1500], Loss: 0.003805\n",
      "Epoch [1400/1500], Loss: 0.003805\n",
      "Epoch [1420/1500], Loss: 0.003805\n",
      "Epoch [1440/1500], Loss: 0.003805\n",
      "Epoch [1460/1500], Loss: 0.003805\n",
      "Epoch [1480/1500], Loss: 0.003805\n",
      "Epoch [1500/1500], Loss: 0.003805\n",
      "tensor(0.0765, device='cuda:0')\n",
      "tensor(0.0647, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 0.705974 for selected strength\n",
      "We have a total strength of 2.492229 for all the columns\n",
      "Epoch [20/1500], Loss: 2.070415\n",
      "Epoch [40/1500], Loss: 1.405784\n",
      "Epoch [60/1500], Loss: 0.944487\n",
      "Epoch [80/1500], Loss: 0.608403\n",
      "Epoch [100/1500], Loss: 0.369246\n",
      "Epoch [120/1500], Loss: 0.215967\n",
      "Epoch [140/1500], Loss: 0.128331\n",
      "Epoch [160/1500], Loss: 0.077306\n",
      "Epoch [180/1500], Loss: 0.047140\n",
      "Epoch [200/1500], Loss: 0.029159\n",
      "Epoch [220/1500], Loss: 0.018457\n",
      "Epoch [240/1500], Loss: 0.012908\n",
      "Epoch [260/1500], Loss: 0.010060\n",
      "Epoch [280/1500], Loss: 0.006592\n",
      "Epoch [300/1500], Loss: 0.006003\n",
      "Epoch [320/1500], Loss: 0.007171\n",
      "Epoch [340/1500], Loss: 0.004924\n",
      "Epoch [360/1500], Loss: 0.005192\n",
      "Epoch [380/1500], Loss: 0.004898\n",
      "Epoch [400/1500], Loss: 0.004933\n",
      "Epoch [420/1500], Loss: 0.004916\n",
      "Epoch [440/1500], Loss: 0.004782\n",
      "Epoch [460/1500], Loss: 0.005888\n",
      "Epoch [480/1500], Loss: 0.004765\n",
      "Epoch [500/1500], Loss: 0.005826\n",
      "Epoch [520/1500], Loss: 0.004734\n",
      "Epoch [540/1500], Loss: 0.005767\n",
      "Epoch [560/1500], Loss: 0.004806\n",
      "Epoch [580/1500], Loss: 0.006692\n",
      "Epoch [600/1500], Loss: 0.004903\n",
      "Epoch [620/1500], Loss: 0.007071\n",
      "Epoch [640/1500], Loss: 0.004999\n",
      "Epoch [660/1500], Loss: 0.006505\n",
      "Epoch [680/1500], Loss: 0.005020\n",
      "Epoch [700/1500], Loss: 0.004696\n",
      "Epoch [720/1500], Loss: 0.005687\n",
      "Epoch [740/1500], Loss: 0.004809\n",
      "Epoch [760/1500], Loss: 0.006927\n",
      "Epoch [780/1500], Loss: 0.004914\n",
      "Epoch [800/1500], Loss: 0.004671\n",
      "Epoch [820/1500], Loss: 0.005715\n",
      "Epoch [840/1500], Loss: 0.004907\n",
      "Epoch [860/1500], Loss: 0.006327\n",
      "Epoch [880/1500], Loss: 0.005187\n",
      "Epoch [900/1500], Loss: 0.004676\n",
      "Epoch [920/1500], Loss: 0.005352\n",
      "Epoch [940/1500], Loss: 0.004797\n",
      "Epoch [960/1500], Loss: 0.005038\n",
      "Epoch [980/1500], Loss: 0.005356\n",
      "Epoch [1000/1500], Loss: 0.004627\n",
      "Epoch [1020/1500], Loss: 0.006227\n",
      "Epoch [1040/1500], Loss: 0.004912\n",
      "Epoch [1060/1500], Loss: 0.004765\n",
      "Epoch [1080/1500], Loss: 0.005963\n",
      "Epoch [1100/1500], Loss: 0.004766\n",
      "Epoch [1120/1500], Loss: 0.005621\n",
      "Epoch [1140/1500], Loss: 0.005559\n",
      "Epoch [1160/1500], Loss: 0.005551\n",
      "Epoch [1180/1500], Loss: 0.005550\n",
      "Epoch [1200/1500], Loss: 0.005550\n",
      "Epoch [1220/1500], Loss: 0.005550\n",
      "Epoch [1240/1500], Loss: 0.005550\n",
      "Epoch [1260/1500], Loss: 0.005550\n",
      "Epoch [1280/1500], Loss: 0.005550\n",
      "Epoch [1300/1500], Loss: 0.005550\n",
      "Epoch [1320/1500], Loss: 0.005550\n",
      "Epoch [1340/1500], Loss: 0.005550\n",
      "Epoch [1360/1500], Loss: 0.005550\n",
      "Epoch [1380/1500], Loss: 0.005550\n",
      "Epoch [1400/1500], Loss: 0.005550\n",
      "Epoch [1420/1500], Loss: 0.005550\n",
      "Epoch [1440/1500], Loss: 0.005550\n",
      "Epoch [1460/1500], Loss: 0.005550\n",
      "Epoch [1480/1500], Loss: 0.005550\n",
      "Epoch [1500/1500], Loss: 0.005550\n",
      "tensor(0.0720, device='cuda:0')\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "We have a value of 1.103024 for selected strength\n",
      "We have a total strength of 3.910676 for all the columns\n",
      "100%|█████████████████████████████████████████████| 4/4 [05:52<00:00, 88.01s/it]\n",
      "Current accuracy: 49.568 \n",
      "Number of texts: 9600\n"
     ]
    }
   ],
   "source": [
    "!python compute_complete_text_set.py --device cuda:0 --model ViT-B-32 --texts_per_head 200 --num_of_last_layers 4 --text_descriptions image_descriptions_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
