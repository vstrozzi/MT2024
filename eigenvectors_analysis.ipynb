{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce479d0c-554a-42ee-b365-84a4d9ab81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import heapq\n",
    "import json\n",
    "import gc\n",
    "from sortedcontainers import SortedList\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.factory import create_model_and_transforms, get_tokenizer\n",
    "from utils.visualization import image_grid, visualization_preprocess\n",
    "from prs_hook import hook_prs_logger\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.imagenet_classes import imagenet_classes\n",
    "from compute_complete_text_set import svd_data_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee675770-3be8-40bf-8659-31e2d2a811ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "\n",
    "device = 'cpu'\n",
    "pretrained = 'laion2b_s34b_b79k' # 'laion2b_s32b_b79k'\n",
    "model_name = 'ViT-B-32' # 'ViT-H-14'\n",
    "seed = 42\n",
    "dataset_text_name = \"image_descriptions_general\"\n",
    "datataset_image_name = \"imagenet\"\n",
    "algorithm = \"svd_data_approx\"\n",
    "batch_size = 16 # only needed for the nn search\n",
    "imagenet_path = './datasets/imagenet/' # only needed for the nn search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db3598-0d7d-47a4-b6c6-8d02f4902e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Model\n",
    "\n",
    "model, _, preprocess = create_model_and_transforms(model_name, pretrained=pretrained)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Len of res:\", len(model.visual.transformer.resblocks))\n",
    "\n",
    "prs = hook_prs_logger(model, device, spatial=False) # This attach hook to get the residual stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f51611-710d-45b9-a797-85a958cc047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run algorithm on a dataset to derive eigenvectors \n",
    "command = f\"python compute_complete_text_set.py --device {device} --model {model_name} --algorithm {algorithm} --seed {seed} --num_of_last_layers 4 --text_descriptions {dataset_text_name}\"\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef211e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new created attention datasets\n",
    "attention_dataset = f\"output_dir/{datataset_image_name}_completeness_{dataset_text_name}_{model_name}_algo_{algorithm}_seed_{seed}.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea667e63",
   "metadata": {},
   "source": [
    "# Strongest Contributions per Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top entries to retrieve\n",
    "top_k = 40\n",
    "min_heap = []\n",
    "# Read JSON lines\n",
    "with open(attention_dataset, \"r\") as json_file:\n",
    "    for line in json_file:\n",
    "        entry = json.loads(line)  # Parse each line as a JSON object\n",
    "\n",
    "        if entry[\"head\"] == -1: # Skip the last entry\n",
    "            continue\n",
    "        # Analyze each eigenvector    \n",
    "        for i, eigenvector_data in enumerate(entry[\"embeddings_sort\"]):\n",
    "            strength_abs = eigenvector_data[\"strength_abs\"]\n",
    "            if len(min_heap) < top_k:\n",
    "                heapq.heappush(min_heap, (strength_abs, i, entry))\n",
    "            else:\n",
    "                heapq.heappushpop(min_heap, (strength_abs, i, entry))\n",
    "\n",
    "        \n",
    "# Extract relevant details from the top k entries\n",
    "top_k_entries = sorted(min_heap, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "top_k_details = [{\n",
    "    \"layer\": entry[\"layer\"],\n",
    "    \"head\": entry[\"head\"],\n",
    "    \"eigenvector\": i,\n",
    "    \"strength_abs\": entry[\"embeddings_sort\"][i][\"strength_abs\"],\n",
    "    \"texts\": entry[\"embeddings_sort\"][i][\"text\"]\n",
    "} for _, i, entry in top_k_entries]\n",
    "\n",
    "# Display the results\n",
    "top_k_df = pd.DataFrame(top_k_details)\n",
    "\n",
    "for row in top_k_df.itertuples():\n",
    "    output_rows = []\n",
    "    texts = row.texts\n",
    "    half_length = len(texts) // 2\n",
    "    \n",
    "    # Check if the first half is positive\n",
    "    is_positive_first = list(texts[0].values())[1] > 0\n",
    "    \n",
    "    # Split into positive and negative based on the order\n",
    "    positive_texts = texts[:half_length]\n",
    "    negative_texts = texts[half_length:]\n",
    "    \n",
    "    for pos, neg in zip(positive_texts, negative_texts):\n",
    "        pos_text = list(pos.values())[0]\n",
    "        pos_val  = list(pos.values())[1]\n",
    "        neg_text = list(neg.values())[0]\n",
    "        neg_val  = list(neg.values())[1]    \n",
    "        \n",
    "        output_rows.append([pos_text, pos_val, neg_text, neg_val])\n",
    "\n",
    "    print(f\"Layer {row.layer}, Head {row.head}, Eigenvector {row.eigenvector}, Strength {row.strength_abs}\")\n",
    "    # Create a DataFrame for the output\n",
    "    if is_positive_first:\n",
    "        columns = [\"Positive\", \"Positive_Strength\", \"Negative\", \"Negative_Strength\"]    \n",
    "    else:\n",
    "        columns = [\"Negative\", \"Negative_Strength\", \"Positive\", \"Positive_Strength\"]    \n",
    "    output_df = pd.DataFrame(output_rows, columns=columns)\n",
    "\n",
    "    print(tabulate(output_df, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f25a1a4",
   "metadata": {},
   "source": [
    "# Query a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b8153-73a3-4f30-bc1d-eddef413df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top entries to retrieve\n",
    "top_k = 10\n",
    "text_query = \"An image of a woman\"\n",
    "\n",
    "# Evaluate clip embedding for the given text\n",
    "text_query_token = tokenizer(text_query).to(device)  # tokenize\n",
    "topic_emb = model.encode_text(text_query_token)\n",
    "topic_emb /= topic_emb.norm(dim=-1, keepdim=True)  # normalize\n",
    "\n",
    "top_entries = SortedList()\n",
    "# Read JSON lines\n",
    "with open(attention_dataset, \"r\") as json_file:\n",
    "    for line in json_file:\n",
    "        entry = json.loads(line)  # Parse each line as a JSON object\n",
    "\n",
    "        if entry[\"head\"] == -1:  # Skip the final embedding entry\n",
    "            continue\n",
    "        # Get necessary reconstruction data\n",
    "        mean_text = torch.tensor(entry[\"mean_values_text\"])\n",
    "        vh = torch.tensor(entry[\"vh\"])\n",
    "        project_matrix = torch.tensor(entry[\"project_matrix\"])\n",
    "\n",
    "        # Get projection of text on the head\n",
    "        topic_emb_proj = (topic_emb - mean_text) @ vh.T\n",
    "        # Analyze each eigenvectors\n",
    "        top_k_eigv = 20\n",
    "        for i, eigenvector_data in enumerate(entry[\"embeddings_sort\"]):\n",
    "            if i == top_k_eigv:\n",
    "                break\n",
    "\n",
    "            # Get the eigenvector direction\n",
    "            eigen_v_emb = torch.tensor(eigenvector_data[\"eigen_v_emb\"]) @ vh.T\n",
    "            \n",
    "            # Build correlation matrix\n",
    "            text_corr = eigen_v_emb @ topic_emb_proj.T\n",
    "\n",
    "            # Evaluate correlation as the maximum value\n",
    "            corr_sign = text_corr > 0\n",
    "            correlation = torch.abs(text_corr).item()\n",
    "\n",
    "            top_entries.add((correlation, (i, corr_sign, entry)))\n",
    "\n",
    "            if len(top_entries) > top_k:\n",
    "                top_entries.pop(0)  # Remove the smallest correlation\n",
    "\n",
    "# Extract relevant details from the top k entries\n",
    "top_k_entries = list(top_entries)[::-1]  # Reverse to have largest first\n",
    "top_k_details = []\n",
    "for (correlation, (i, corr_sign, entry)) in top_k_entries:\n",
    "    texts = entry[\"embeddings_sort\"][i][\"text\"]\n",
    "    length = len(texts) // 2\n",
    "    first_text_pos = (list(entry[\"embeddings_sort\"][i][\"text\"][0].values())[1] > 0)\n",
    "    # Sort texts based on the correlation sign\n",
    "    texts = sorted(texts[:length], key=lambda x: list(x.values())[1], reverse= first_text_pos) + \\\n",
    "            sorted(texts[length:], key=lambda x: list(x.values())[1], reverse= not first_text_pos)\n",
    "\n",
    "        \n",
    "    top_k_details.append({\n",
    "        \"layer\": entry[\"layer\"],\n",
    "        \"head\": entry[\"head\"],\n",
    "        \"eigenvector\": i,\n",
    "        \"eigenvector_strength\": entry[\"embeddings_sort\"][i][\"strength_abs\"],\n",
    "        \"correlation\": correlation if corr_sign else -correlation,\n",
    "        \"texts\": texts\n",
    "    })\n",
    "\n",
    "top_k_df = pd.DataFrame(top_k_details)\n",
    "# Display the results\n",
    "for row in top_k_df.itertuples():\n",
    "    output_rows = []\n",
    "    texts = row.texts\n",
    "    half_length = len(texts) // 2\n",
    "    \n",
    "    # Check if the first half is positive\n",
    "    is_positive_corr = row.correlation > 0\n",
    "    is_positive_first = list(texts[0].values())[1] > 0\n",
    "\n",
    "    # Create a DataFrame for the output\n",
    "    if is_positive_corr:\n",
    "        columns = [\"Positive\", \"Positive_Strength\", \"Negative\", \"Negative_Strength\"] \n",
    "        first = texts[:half_length] if is_positive_first else texts[half_length:]\n",
    "        second = texts[half_length:] if is_positive_first else texts[:half_length] \n",
    "    else:\n",
    "        columns = [\"Negative\", \"Negative_Strength\", \"Positive\", \"Positive_Strength\"]   \n",
    "        first = texts[half_length:] if is_positive_first else texts[:half_length]\n",
    "        second = texts[:half_length] if is_positive_first else texts[half_length:]\n",
    "        \n",
    "    for pos, neg in zip(first, second):\n",
    "        pos_text = list(pos.values())[0]\n",
    "        pos_val  = list(pos.values())[1]\n",
    "        neg_text = list(neg.values())[0]\n",
    "        neg_val  = list(neg.values())[1]    \n",
    "        \n",
    "        output_rows.append([pos_text, pos_val, neg_text, neg_val])\n",
    "\n",
    "    print(f\"Layer {row.layer}, Head {row.head}, Eigenvector {row.eigenvector}, Eigenvector Strength {row.eigenvector_strength}, Correlation {row.correlation}\")\n",
    "     \n",
    "    output_df = pd.DataFrame(output_rows, columns=columns)\n",
    "\n",
    "\n",
    "    print(tabulate(output_df, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d7841",
   "metadata": {},
   "source": [
    "# Test accuracy of reconstruction using only basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e915effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top entries to retrieve\n",
    "top_k = 20\n",
    "min_heap = []\n",
    "\n",
    "# Prepare both text and image for the query\n",
    "\n",
    "# Image\n",
    "image = preprocess(Image.open('images/woman.png'))[np.newaxis, :, :, :]\n",
    "## Run the image:\n",
    "prs.reinit() # Reinitialize the residual stream hook\n",
    "with torch.no_grad():\n",
    "    representation = model.encode_image(image.to(device), \n",
    "                                        attn_method='head_no_spatial', \n",
    "                                        normalize=False)\n",
    "    attentions, mlps = prs.finalize(representation)  # attentions: [1, 16, 16, 512], [b, l, h, d] & mlps: [1, 17, 1024], [b, l + 1 (class), d]\n",
    "\n",
    "image_emb = representation / representation.norm(dim=-1, keepdim=True)  # normalize\n",
    "\n",
    "# Text\n",
    "text_query = \"A beautiful woman.\"\n",
    "text_query_token = tokenizer(text_query).to(device)  # tokenize\n",
    "topic_emb = model.encode_text(text_query_token)\n",
    "topic_emb /= topic_emb.norm(dim=-1, keepdim=True)  # normalize\n",
    "\n",
    "# Reconstructions\n",
    "image_emb_rec = torch.zeros_like(topic_emb)\n",
    "topic_emb_rec = torch.zeros_like(topic_emb)\n",
    "# Read JSON lines\n",
    "with open(attention_dataset, \"r\") as json_file:\n",
    "    for line in json_file:\n",
    "\n",
    "        \n",
    "        entry = json.loads(line)  # Parse each line as a JSON object\n",
    "        if entry[\"head\"] == -1:  # Skip the final embedding entry\n",
    "            last_line = entry\n",
    "            continue\n",
    "\n",
    "        project_matrix = torch.tensor(entry[\"project_matrix\"])\n",
    "        vh = torch.tensor(entry[\"vh\"])\n",
    "        # Get projection of text on the head\n",
    "        topic_emb_rec += (topic_emb - torch.tensor(entry[\"mean_values_text\"])) @ vh.T @ project_matrix @ vh+ torch.tensor(entry[\"mean_values_text\"])\n",
    "        image_emb_rec += (image_emb - torch.tensor(entry[\"mean_values_att\"])) @ vh.T @ project_matrix @ vh + torch.tensor(entry[\"mean_values_att\"])\n",
    "\n",
    "print(topic_emb_rec.norm()) \n",
    "print(image_emb_rec.norm())\n",
    "topic_emb_rec /= topic_emb_rec.norm(dim=-1, keepdim=True)  # normalize\n",
    "image_emb_rec /= image_emb_rec.norm(dim=-1, keepdim=True)  # normalize  \n",
    "print(topic_emb @ topic_emb_rec.T)\n",
    "print(image_emb @ image_emb_rec.T)\n",
    "\n",
    "print(topic_emb @ image_emb.T)\n",
    "print(topic_emb @ image_emb_rec.T)\n",
    "print(topic_emb_rec @ image_emb.T)\n",
    "print(topic_emb_rec @ image_emb_rec.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00ac60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
